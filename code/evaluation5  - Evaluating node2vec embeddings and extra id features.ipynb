{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90634bf5",
   "metadata": {},
   "source": [
    "# ABOUT: \n",
    "- this code evaluates the node2vec embeddings on all node2vec embeddings generated\n",
    "- findings: \n",
    "    - using card_id embeddings appear to cause overfitting\n",
    "        \n",
    "- details:       \n",
    "    - i.e compared to baseline, performance on training set is better but performance on validation set is worse\n",
    "    - baseline - using just feature_2 as feature\n",
    "    - model used is Histogram Gradient boosting\n",
    "    - metrics used are r2 and rmse\n",
    "    - 3 fold cross validated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "469228eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import nodevectors\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b49ee368",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_id_column = \"merchant_id\"\n",
    "node2vec_path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CZ4041 - Machine Learning\\Team Project\\model\\node2vec_card_id_merchant_id.zip\"\n",
    "embedding_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f019543",
   "metadata": {},
   "source": [
    "### prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aee90f24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>merchant_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>M_ID_e020e9b302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>M_ID_86ec983688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>M_ID_979ed661fc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>M_ID_e6d5ae8ea6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>M_ID_e020e9b302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id      merchant_id\n",
       "0  C_ID_4e6213e9bc  M_ID_e020e9b302\n",
       "1  C_ID_4e6213e9bc  M_ID_86ec983688\n",
       "2  C_ID_4e6213e9bc  M_ID_979ed661fc\n",
       "3  C_ID_4e6213e9bc  M_ID_e6d5ae8ea6\n",
       "4  C_ID_4e6213e9bc  M_ID_e020e9b302"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CZ4041 - Machine Learning\\Team Project\\data\\id_columns_processed.csv\"\n",
    "id_columns = pd.read_csv(path, usecols = [\"card_id\", target_id_column])\n",
    "id_columns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d616a231",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>nunique_merchant_id</th>\n",
       "      <th>count_merchant_id</th>\n",
       "      <th>nunique_count_frac_merchant_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_00007093c1</td>\n",
       "      <td>31</td>\n",
       "      <td>151</td>\n",
       "      <td>0.205298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_0001238066</td>\n",
       "      <td>90</td>\n",
       "      <td>149</td>\n",
       "      <td>0.604027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_0001506ef0</td>\n",
       "      <td>29</td>\n",
       "      <td>68</td>\n",
       "      <td>0.426471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_0001793786</td>\n",
       "      <td>150</td>\n",
       "      <td>247</td>\n",
       "      <td>0.607287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_000183fdda</td>\n",
       "      <td>84</td>\n",
       "      <td>155</td>\n",
       "      <td>0.541935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325535</th>\n",
       "      <td>C_ID_ffff1d9928</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325536</th>\n",
       "      <td>C_ID_ffff579d3a</td>\n",
       "      <td>63</td>\n",
       "      <td>115</td>\n",
       "      <td>0.547826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325537</th>\n",
       "      <td>C_ID_ffff756266</td>\n",
       "      <td>14</td>\n",
       "      <td>25</td>\n",
       "      <td>0.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325538</th>\n",
       "      <td>C_ID_ffff828181</td>\n",
       "      <td>97</td>\n",
       "      <td>198</td>\n",
       "      <td>0.489899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325539</th>\n",
       "      <td>C_ID_fffffd5772</td>\n",
       "      <td>22</td>\n",
       "      <td>87</td>\n",
       "      <td>0.252874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>325540 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                card_id  nunique_merchant_id  count_merchant_id  \\\n",
       "0       C_ID_00007093c1                   31                151   \n",
       "1       C_ID_0001238066                   90                149   \n",
       "2       C_ID_0001506ef0                   29                 68   \n",
       "3       C_ID_0001793786                  150                247   \n",
       "4       C_ID_000183fdda                   84                155   \n",
       "...                 ...                  ...                ...   \n",
       "325535  C_ID_ffff1d9928                   12                 16   \n",
       "325536  C_ID_ffff579d3a                   63                115   \n",
       "325537  C_ID_ffff756266                   14                 25   \n",
       "325538  C_ID_ffff828181                   97                198   \n",
       "325539  C_ID_fffffd5772                   22                 87   \n",
       "\n",
       "        nunique_count_frac_merchant_id  \n",
       "0                             0.205298  \n",
       "1                             0.604027  \n",
       "2                             0.426471  \n",
       "3                             0.607287  \n",
       "4                             0.541935  \n",
       "...                                ...  \n",
       "325535                        0.750000  \n",
       "325536                        0.547826  \n",
       "325537                        0.560000  \n",
       "325538                        0.489899  \n",
       "325539                        0.252874  \n",
       "\n",
       "[325540 rows x 4 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by card_id, then acquire nunique_merchant_id, count_merchant_id, nunique_count_frac_merchant_id\n",
    "id_features = id_columns.groupby(\"card_id\").agg([\"nunique\", \"count\"])\n",
    "id_features = id_features.reset_index()\n",
    "id_features.columns = [\"card_id\", \"nunique_merchant_id\", \"count_merchant_id\"]\n",
    "id_features[\"nunique_count_frac_merchant_id\"] = id_features[\"nunique_merchant_id\"]/id_features[\"count_merchant_id\"]\n",
    "id_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "07bab95e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.820283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>1</td>\n",
       "      <td>0.392913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>2</td>\n",
       "      <td>0.688056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_186d6a6901</td>\n",
       "      <td>3</td>\n",
       "      <td>0.142495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_cdbd2c0db2</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.159749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id  feature_2    target\n",
       "0  C_ID_92a2005557          2 -0.820283\n",
       "1  C_ID_3d0044924f          1  0.392913\n",
       "2  C_ID_d639edf6cd          2  0.688056\n",
       "3  C_ID_186d6a6901          3  0.142495\n",
       "4  C_ID_cdbd2c0db2          3 -0.159749"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load train target variable\n",
    "train_file = pd.read_csv(train_path, usecols = [\"card_id\",\"target\", \"feature_2\"])\n",
    "train_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "95744be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_00007093c1</td>\n",
       "      <td>-0.072682</td>\n",
       "      <td>0.059939</td>\n",
       "      <td>-0.035718</td>\n",
       "      <td>-0.507144</td>\n",
       "      <td>0.484537</td>\n",
       "      <td>-0.163634</td>\n",
       "      <td>-0.141885</td>\n",
       "      <td>0.232800</td>\n",
       "      <td>-0.473599</td>\n",
       "      <td>-0.359012</td>\n",
       "      <td>0.381937</td>\n",
       "      <td>-0.194508</td>\n",
       "      <td>-0.131536</td>\n",
       "      <td>0.179893</td>\n",
       "      <td>0.409616</td>\n",
       "      <td>0.088422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_0001238066</td>\n",
       "      <td>0.210722</td>\n",
       "      <td>0.312669</td>\n",
       "      <td>-0.520883</td>\n",
       "      <td>-0.249812</td>\n",
       "      <td>-0.363242</td>\n",
       "      <td>-0.132117</td>\n",
       "      <td>0.139158</td>\n",
       "      <td>-0.225415</td>\n",
       "      <td>0.262967</td>\n",
       "      <td>-0.052613</td>\n",
       "      <td>0.148577</td>\n",
       "      <td>0.350702</td>\n",
       "      <td>0.354733</td>\n",
       "      <td>-0.658745</td>\n",
       "      <td>-0.308656</td>\n",
       "      <td>-0.518378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_0001506ef0</td>\n",
       "      <td>0.071951</td>\n",
       "      <td>0.600783</td>\n",
       "      <td>-0.074211</td>\n",
       "      <td>-0.010603</td>\n",
       "      <td>0.465303</td>\n",
       "      <td>-0.063733</td>\n",
       "      <td>-0.164648</td>\n",
       "      <td>0.350252</td>\n",
       "      <td>-0.126781</td>\n",
       "      <td>-0.301627</td>\n",
       "      <td>-0.181813</td>\n",
       "      <td>-0.407964</td>\n",
       "      <td>-0.104659</td>\n",
       "      <td>0.197382</td>\n",
       "      <td>-0.202232</td>\n",
       "      <td>-0.058480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_0001793786</td>\n",
       "      <td>-0.461036</td>\n",
       "      <td>-0.118778</td>\n",
       "      <td>0.298193</td>\n",
       "      <td>0.425997</td>\n",
       "      <td>0.096633</td>\n",
       "      <td>0.125535</td>\n",
       "      <td>-0.083261</td>\n",
       "      <td>-0.238686</td>\n",
       "      <td>-0.250503</td>\n",
       "      <td>0.225745</td>\n",
       "      <td>0.006093</td>\n",
       "      <td>-0.146210</td>\n",
       "      <td>-0.776158</td>\n",
       "      <td>0.388017</td>\n",
       "      <td>0.514659</td>\n",
       "      <td>-0.037183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_000183fdda</td>\n",
       "      <td>-0.236855</td>\n",
       "      <td>-0.031561</td>\n",
       "      <td>-0.334673</td>\n",
       "      <td>-0.366431</td>\n",
       "      <td>0.450655</td>\n",
       "      <td>0.069693</td>\n",
       "      <td>0.139591</td>\n",
       "      <td>-0.513259</td>\n",
       "      <td>-0.161989</td>\n",
       "      <td>0.178157</td>\n",
       "      <td>-0.115979</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.134345</td>\n",
       "      <td>-0.327235</td>\n",
       "      <td>0.351243</td>\n",
       "      <td>0.172792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660168</th>\n",
       "      <td>M_ID_fffeeb852d</td>\n",
       "      <td>-0.495755</td>\n",
       "      <td>0.083156</td>\n",
       "      <td>0.145200</td>\n",
       "      <td>-0.403701</td>\n",
       "      <td>-0.486243</td>\n",
       "      <td>0.028347</td>\n",
       "      <td>-0.211832</td>\n",
       "      <td>-0.101902</td>\n",
       "      <td>-0.044037</td>\n",
       "      <td>0.375575</td>\n",
       "      <td>0.158479</td>\n",
       "      <td>0.115163</td>\n",
       "      <td>-0.157367</td>\n",
       "      <td>0.307679</td>\n",
       "      <td>-0.306738</td>\n",
       "      <td>-0.063962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660169</th>\n",
       "      <td>M_ID_fffef87522</td>\n",
       "      <td>-0.075561</td>\n",
       "      <td>0.239505</td>\n",
       "      <td>0.303652</td>\n",
       "      <td>0.341309</td>\n",
       "      <td>-0.443319</td>\n",
       "      <td>0.204595</td>\n",
       "      <td>0.049358</td>\n",
       "      <td>-0.102069</td>\n",
       "      <td>-0.148860</td>\n",
       "      <td>-0.070825</td>\n",
       "      <td>0.116723</td>\n",
       "      <td>0.345221</td>\n",
       "      <td>-0.191478</td>\n",
       "      <td>-0.058667</td>\n",
       "      <td>-0.156204</td>\n",
       "      <td>0.213919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660170</th>\n",
       "      <td>M_ID_ffff0af8e7</td>\n",
       "      <td>-0.192354</td>\n",
       "      <td>-0.089260</td>\n",
       "      <td>-0.363378</td>\n",
       "      <td>0.192582</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.121182</td>\n",
       "      <td>0.260083</td>\n",
       "      <td>-0.410028</td>\n",
       "      <td>-0.064522</td>\n",
       "      <td>0.365527</td>\n",
       "      <td>0.458633</td>\n",
       "      <td>-0.163760</td>\n",
       "      <td>-0.045048</td>\n",
       "      <td>0.445095</td>\n",
       "      <td>-0.217569</td>\n",
       "      <td>-0.140139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660171</th>\n",
       "      <td>M_ID_ffff655e2c</td>\n",
       "      <td>-0.097225</td>\n",
       "      <td>0.034523</td>\n",
       "      <td>-0.285844</td>\n",
       "      <td>-0.197016</td>\n",
       "      <td>0.052762</td>\n",
       "      <td>0.005846</td>\n",
       "      <td>-0.072529</td>\n",
       "      <td>0.152449</td>\n",
       "      <td>-0.063171</td>\n",
       "      <td>0.255264</td>\n",
       "      <td>0.610611</td>\n",
       "      <td>0.269365</td>\n",
       "      <td>-0.080027</td>\n",
       "      <td>0.109693</td>\n",
       "      <td>0.096002</td>\n",
       "      <td>0.326257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660172</th>\n",
       "      <td>M_ID_ffffc28eaa</td>\n",
       "      <td>0.276066</td>\n",
       "      <td>-0.436840</td>\n",
       "      <td>-0.099993</td>\n",
       "      <td>0.201276</td>\n",
       "      <td>-0.188435</td>\n",
       "      <td>0.408157</td>\n",
       "      <td>0.137390</td>\n",
       "      <td>-0.258055</td>\n",
       "      <td>0.121476</td>\n",
       "      <td>-0.080996</td>\n",
       "      <td>0.360855</td>\n",
       "      <td>0.170439</td>\n",
       "      <td>-0.065800</td>\n",
       "      <td>0.149205</td>\n",
       "      <td>-0.335688</td>\n",
       "      <td>-0.204235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>660173 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  index         0         1         2         3         4  \\\n",
       "0       C_ID_00007093c1 -0.072682  0.059939 -0.035718 -0.507144  0.484537   \n",
       "1       C_ID_0001238066  0.210722  0.312669 -0.520883 -0.249812 -0.363242   \n",
       "2       C_ID_0001506ef0  0.071951  0.600783 -0.074211 -0.010603  0.465303   \n",
       "3       C_ID_0001793786 -0.461036 -0.118778  0.298193  0.425997  0.096633   \n",
       "4       C_ID_000183fdda -0.236855 -0.031561 -0.334673 -0.366431  0.450655   \n",
       "...                 ...       ...       ...       ...       ...       ...   \n",
       "660168  M_ID_fffeeb852d -0.495755  0.083156  0.145200 -0.403701 -0.486243   \n",
       "660169  M_ID_fffef87522 -0.075561  0.239505  0.303652  0.341309 -0.443319   \n",
       "660170  M_ID_ffff0af8e7 -0.192354 -0.089260 -0.363378  0.192582  0.001293   \n",
       "660171  M_ID_ffff655e2c -0.097225  0.034523 -0.285844 -0.197016  0.052762   \n",
       "660172  M_ID_ffffc28eaa  0.276066 -0.436840 -0.099993  0.201276 -0.188435   \n",
       "\n",
       "               5         6         7         8         9        10        11  \\\n",
       "0      -0.163634 -0.141885  0.232800 -0.473599 -0.359012  0.381937 -0.194508   \n",
       "1      -0.132117  0.139158 -0.225415  0.262967 -0.052613  0.148577  0.350702   \n",
       "2      -0.063733 -0.164648  0.350252 -0.126781 -0.301627 -0.181813 -0.407964   \n",
       "3       0.125535 -0.083261 -0.238686 -0.250503  0.225745  0.006093 -0.146210   \n",
       "4       0.069693  0.139591 -0.513259 -0.161989  0.178157 -0.115979  0.082836   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "660168  0.028347 -0.211832 -0.101902 -0.044037  0.375575  0.158479  0.115163   \n",
       "660169  0.204595  0.049358 -0.102069 -0.148860 -0.070825  0.116723  0.345221   \n",
       "660170  0.121182  0.260083 -0.410028 -0.064522  0.365527  0.458633 -0.163760   \n",
       "660171  0.005846 -0.072529  0.152449 -0.063171  0.255264  0.610611  0.269365   \n",
       "660172  0.408157  0.137390 -0.258055  0.121476 -0.080996  0.360855  0.170439   \n",
       "\n",
       "              12        13        14        15  \n",
       "0      -0.131536  0.179893  0.409616  0.088422  \n",
       "1       0.354733 -0.658745 -0.308656 -0.518378  \n",
       "2      -0.104659  0.197382 -0.202232 -0.058480  \n",
       "3      -0.776158  0.388017  0.514659 -0.037183  \n",
       "4       0.134345 -0.327235  0.351243  0.172792  \n",
       "...          ...       ...       ...       ...  \n",
       "660168 -0.157367  0.307679 -0.306738 -0.063962  \n",
       "660169 -0.191478 -0.058667 -0.156204  0.213919  \n",
       "660170 -0.045048  0.445095 -0.217569 -0.140139  \n",
       "660171 -0.080027  0.109693  0.096002  0.326257  \n",
       "660172 -0.065800  0.149205 -0.335688 -0.204235  \n",
       "\n",
       "[660173 rows x 17 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load trained node2vec\n",
    "node2vec = nodevectors.GGVec.load(node2vec_path)\n",
    "# convert embeddings to dataframe\n",
    "node2vec_embeddings = pd.DataFrame.from_dict(node2vec.model, orient = \"index\")\n",
    "node2vec_embeddings = node2vec_embeddings.reset_index()\n",
    "node2vec_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "36ef9ddc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# group and aggregate the id embeddings (e.g city_id embeddings) by the \"card_id\"\n",
    "node2vec_embeddings = id_columns.merge(node2vec_embeddings, how = \"left\", left_on = \"merchant_id\", right_on = \"index\")\n",
    "node2vec_embeddings = node2vec_embeddings.drop(\"index\", axis = 1)\n",
    "node2vec_embeddings = node2vec_embeddings.groupby(\"card_id\").mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d04882b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_00007093c1</td>\n",
       "      <td>0.240035</td>\n",
       "      <td>-0.008940</td>\n",
       "      <td>0.183486</td>\n",
       "      <td>-0.068755</td>\n",
       "      <td>0.287280</td>\n",
       "      <td>-0.110511</td>\n",
       "      <td>0.030815</td>\n",
       "      <td>0.237155</td>\n",
       "      <td>-0.077973</td>\n",
       "      <td>-0.017793</td>\n",
       "      <td>0.196873</td>\n",
       "      <td>-0.014195</td>\n",
       "      <td>0.050116</td>\n",
       "      <td>0.156852</td>\n",
       "      <td>0.239943</td>\n",
       "      <td>0.019909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_0001238066</td>\n",
       "      <td>-0.082188</td>\n",
       "      <td>0.118378</td>\n",
       "      <td>-0.151136</td>\n",
       "      <td>-0.147830</td>\n",
       "      <td>-0.084432</td>\n",
       "      <td>-0.058462</td>\n",
       "      <td>0.084593</td>\n",
       "      <td>-0.173836</td>\n",
       "      <td>-0.039412</td>\n",
       "      <td>-0.019465</td>\n",
       "      <td>0.068317</td>\n",
       "      <td>0.152736</td>\n",
       "      <td>-0.060022</td>\n",
       "      <td>0.012707</td>\n",
       "      <td>-0.156633</td>\n",
       "      <td>-0.037209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_0001506ef0</td>\n",
       "      <td>-0.293739</td>\n",
       "      <td>0.142979</td>\n",
       "      <td>0.132453</td>\n",
       "      <td>-0.004983</td>\n",
       "      <td>0.308517</td>\n",
       "      <td>0.032882</td>\n",
       "      <td>-0.119018</td>\n",
       "      <td>0.154300</td>\n",
       "      <td>-0.092480</td>\n",
       "      <td>0.007875</td>\n",
       "      <td>-0.014443</td>\n",
       "      <td>-0.308194</td>\n",
       "      <td>0.049957</td>\n",
       "      <td>0.084944</td>\n",
       "      <td>-0.132957</td>\n",
       "      <td>-0.128737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_0001793786</td>\n",
       "      <td>-0.054674</td>\n",
       "      <td>-0.025724</td>\n",
       "      <td>0.116930</td>\n",
       "      <td>-0.032562</td>\n",
       "      <td>0.027127</td>\n",
       "      <td>-0.065237</td>\n",
       "      <td>-0.008518</td>\n",
       "      <td>-0.000088</td>\n",
       "      <td>0.294138</td>\n",
       "      <td>0.168495</td>\n",
       "      <td>0.084863</td>\n",
       "      <td>-0.158215</td>\n",
       "      <td>-0.330049</td>\n",
       "      <td>0.159620</td>\n",
       "      <td>0.195890</td>\n",
       "      <td>-0.133651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_000183fdda</td>\n",
       "      <td>-0.080465</td>\n",
       "      <td>-0.016296</td>\n",
       "      <td>-0.017469</td>\n",
       "      <td>-0.095927</td>\n",
       "      <td>0.149595</td>\n",
       "      <td>0.084041</td>\n",
       "      <td>-0.248820</td>\n",
       "      <td>-0.357927</td>\n",
       "      <td>-0.229567</td>\n",
       "      <td>0.004561</td>\n",
       "      <td>-0.202657</td>\n",
       "      <td>-0.186313</td>\n",
       "      <td>-0.073885</td>\n",
       "      <td>-0.003096</td>\n",
       "      <td>0.378063</td>\n",
       "      <td>0.056127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325535</th>\n",
       "      <td>C_ID_ffff1d9928</td>\n",
       "      <td>-0.229091</td>\n",
       "      <td>-0.055329</td>\n",
       "      <td>-0.027627</td>\n",
       "      <td>0.157519</td>\n",
       "      <td>-0.174935</td>\n",
       "      <td>0.006241</td>\n",
       "      <td>-0.146883</td>\n",
       "      <td>0.218513</td>\n",
       "      <td>0.094355</td>\n",
       "      <td>-0.073220</td>\n",
       "      <td>-0.086454</td>\n",
       "      <td>-0.076887</td>\n",
       "      <td>-0.134116</td>\n",
       "      <td>0.106109</td>\n",
       "      <td>0.046940</td>\n",
       "      <td>0.192442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325536</th>\n",
       "      <td>C_ID_ffff579d3a</td>\n",
       "      <td>-0.053132</td>\n",
       "      <td>0.034465</td>\n",
       "      <td>-0.186854</td>\n",
       "      <td>0.116715</td>\n",
       "      <td>0.076655</td>\n",
       "      <td>-0.112643</td>\n",
       "      <td>0.019383</td>\n",
       "      <td>-0.043747</td>\n",
       "      <td>-0.073184</td>\n",
       "      <td>-0.016171</td>\n",
       "      <td>0.206581</td>\n",
       "      <td>0.133093</td>\n",
       "      <td>-0.003764</td>\n",
       "      <td>0.128234</td>\n",
       "      <td>-0.098478</td>\n",
       "      <td>-0.160164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325537</th>\n",
       "      <td>C_ID_ffff756266</td>\n",
       "      <td>-0.169659</td>\n",
       "      <td>0.031127</td>\n",
       "      <td>-0.240533</td>\n",
       "      <td>0.025183</td>\n",
       "      <td>-0.071948</td>\n",
       "      <td>0.145484</td>\n",
       "      <td>0.031459</td>\n",
       "      <td>-0.185838</td>\n",
       "      <td>-0.032465</td>\n",
       "      <td>0.270487</td>\n",
       "      <td>0.184604</td>\n",
       "      <td>0.013366</td>\n",
       "      <td>0.021627</td>\n",
       "      <td>0.221125</td>\n",
       "      <td>-0.061121</td>\n",
       "      <td>-0.066230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325538</th>\n",
       "      <td>C_ID_ffff828181</td>\n",
       "      <td>0.051835</td>\n",
       "      <td>-0.136970</td>\n",
       "      <td>-0.092602</td>\n",
       "      <td>0.086033</td>\n",
       "      <td>0.058512</td>\n",
       "      <td>-0.266178</td>\n",
       "      <td>-0.045897</td>\n",
       "      <td>0.068876</td>\n",
       "      <td>0.344665</td>\n",
       "      <td>-0.077493</td>\n",
       "      <td>-0.006768</td>\n",
       "      <td>-0.084037</td>\n",
       "      <td>-0.151741</td>\n",
       "      <td>0.057403</td>\n",
       "      <td>0.127205</td>\n",
       "      <td>-0.114236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325539</th>\n",
       "      <td>C_ID_fffffd5772</td>\n",
       "      <td>-0.074418</td>\n",
       "      <td>0.156258</td>\n",
       "      <td>0.037602</td>\n",
       "      <td>0.034117</td>\n",
       "      <td>0.060192</td>\n",
       "      <td>-0.048720</td>\n",
       "      <td>0.024657</td>\n",
       "      <td>-0.026653</td>\n",
       "      <td>-0.004466</td>\n",
       "      <td>-0.144949</td>\n",
       "      <td>0.056713</td>\n",
       "      <td>-0.230624</td>\n",
       "      <td>-0.002989</td>\n",
       "      <td>-0.001587</td>\n",
       "      <td>-0.167314</td>\n",
       "      <td>0.107935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>325540 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                card_id         0         1         2         3         4  \\\n",
       "0       C_ID_00007093c1  0.240035 -0.008940  0.183486 -0.068755  0.287280   \n",
       "1       C_ID_0001238066 -0.082188  0.118378 -0.151136 -0.147830 -0.084432   \n",
       "2       C_ID_0001506ef0 -0.293739  0.142979  0.132453 -0.004983  0.308517   \n",
       "3       C_ID_0001793786 -0.054674 -0.025724  0.116930 -0.032562  0.027127   \n",
       "4       C_ID_000183fdda -0.080465 -0.016296 -0.017469 -0.095927  0.149595   \n",
       "...                 ...       ...       ...       ...       ...       ...   \n",
       "325535  C_ID_ffff1d9928 -0.229091 -0.055329 -0.027627  0.157519 -0.174935   \n",
       "325536  C_ID_ffff579d3a -0.053132  0.034465 -0.186854  0.116715  0.076655   \n",
       "325537  C_ID_ffff756266 -0.169659  0.031127 -0.240533  0.025183 -0.071948   \n",
       "325538  C_ID_ffff828181  0.051835 -0.136970 -0.092602  0.086033  0.058512   \n",
       "325539  C_ID_fffffd5772 -0.074418  0.156258  0.037602  0.034117  0.060192   \n",
       "\n",
       "               5         6         7         8         9        10        11  \\\n",
       "0      -0.110511  0.030815  0.237155 -0.077973 -0.017793  0.196873 -0.014195   \n",
       "1      -0.058462  0.084593 -0.173836 -0.039412 -0.019465  0.068317  0.152736   \n",
       "2       0.032882 -0.119018  0.154300 -0.092480  0.007875 -0.014443 -0.308194   \n",
       "3      -0.065237 -0.008518 -0.000088  0.294138  0.168495  0.084863 -0.158215   \n",
       "4       0.084041 -0.248820 -0.357927 -0.229567  0.004561 -0.202657 -0.186313   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "325535  0.006241 -0.146883  0.218513  0.094355 -0.073220 -0.086454 -0.076887   \n",
       "325536 -0.112643  0.019383 -0.043747 -0.073184 -0.016171  0.206581  0.133093   \n",
       "325537  0.145484  0.031459 -0.185838 -0.032465  0.270487  0.184604  0.013366   \n",
       "325538 -0.266178 -0.045897  0.068876  0.344665 -0.077493 -0.006768 -0.084037   \n",
       "325539 -0.048720  0.024657 -0.026653 -0.004466 -0.144949  0.056713 -0.230624   \n",
       "\n",
       "              12        13        14        15  \n",
       "0       0.050116  0.156852  0.239943  0.019909  \n",
       "1      -0.060022  0.012707 -0.156633 -0.037209  \n",
       "2       0.049957  0.084944 -0.132957 -0.128737  \n",
       "3      -0.330049  0.159620  0.195890 -0.133651  \n",
       "4      -0.073885 -0.003096  0.378063  0.056127  \n",
       "...          ...       ...       ...       ...  \n",
       "325535 -0.134116  0.106109  0.046940  0.192442  \n",
       "325536 -0.003764  0.128234 -0.098478 -0.160164  \n",
       "325537  0.021627  0.221125 -0.061121 -0.066230  \n",
       "325538 -0.151741  0.057403  0.127205 -0.114236  \n",
       "325539 -0.002989 -0.001587 -0.167314  0.107935  \n",
       "\n",
       "[325540 rows x 17 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node2vec_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "798db446",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.820283</td>\n",
       "      <td>-0.055851</td>\n",
       "      <td>0.147994</td>\n",
       "      <td>-0.030757</td>\n",
       "      <td>-0.073910</td>\n",
       "      <td>-0.010504</td>\n",
       "      <td>-0.063806</td>\n",
       "      <td>0.180107</td>\n",
       "      <td>-0.113234</td>\n",
       "      <td>-0.076563</td>\n",
       "      <td>-0.022222</td>\n",
       "      <td>-0.083477</td>\n",
       "      <td>0.082931</td>\n",
       "      <td>0.088083</td>\n",
       "      <td>0.074731</td>\n",
       "      <td>-0.004401</td>\n",
       "      <td>-0.057365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>1</td>\n",
       "      <td>0.392913</td>\n",
       "      <td>-0.055640</td>\n",
       "      <td>0.154444</td>\n",
       "      <td>-0.048635</td>\n",
       "      <td>-0.070090</td>\n",
       "      <td>0.017265</td>\n",
       "      <td>-0.042851</td>\n",
       "      <td>0.134029</td>\n",
       "      <td>-0.033346</td>\n",
       "      <td>-0.042521</td>\n",
       "      <td>-0.006478</td>\n",
       "      <td>-0.073879</td>\n",
       "      <td>0.012347</td>\n",
       "      <td>0.064042</td>\n",
       "      <td>0.055082</td>\n",
       "      <td>0.043727</td>\n",
       "      <td>-0.019014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>2</td>\n",
       "      <td>0.688056</td>\n",
       "      <td>0.038449</td>\n",
       "      <td>0.033729</td>\n",
       "      <td>-0.036073</td>\n",
       "      <td>-0.118617</td>\n",
       "      <td>0.068142</td>\n",
       "      <td>0.057314</td>\n",
       "      <td>0.033151</td>\n",
       "      <td>0.074983</td>\n",
       "      <td>0.034293</td>\n",
       "      <td>-0.042218</td>\n",
       "      <td>-0.002832</td>\n",
       "      <td>-0.039617</td>\n",
       "      <td>0.017628</td>\n",
       "      <td>0.014782</td>\n",
       "      <td>-0.065753</td>\n",
       "      <td>0.084333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_186d6a6901</td>\n",
       "      <td>3</td>\n",
       "      <td>0.142495</td>\n",
       "      <td>0.044003</td>\n",
       "      <td>-0.005825</td>\n",
       "      <td>-0.096572</td>\n",
       "      <td>-0.053282</td>\n",
       "      <td>-0.207161</td>\n",
       "      <td>-0.088515</td>\n",
       "      <td>-0.118196</td>\n",
       "      <td>-0.038728</td>\n",
       "      <td>0.108079</td>\n",
       "      <td>0.132761</td>\n",
       "      <td>-0.082925</td>\n",
       "      <td>-0.112086</td>\n",
       "      <td>0.094630</td>\n",
       "      <td>-0.015612</td>\n",
       "      <td>0.019117</td>\n",
       "      <td>0.214415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_cdbd2c0db2</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.159749</td>\n",
       "      <td>0.078187</td>\n",
       "      <td>-0.054140</td>\n",
       "      <td>-0.079138</td>\n",
       "      <td>-0.052407</td>\n",
       "      <td>-0.314112</td>\n",
       "      <td>-0.103714</td>\n",
       "      <td>-0.183939</td>\n",
       "      <td>-0.040985</td>\n",
       "      <td>0.119379</td>\n",
       "      <td>0.190108</td>\n",
       "      <td>-0.083095</td>\n",
       "      <td>-0.125474</td>\n",
       "      <td>0.122729</td>\n",
       "      <td>-0.010624</td>\n",
       "      <td>0.031643</td>\n",
       "      <td>0.291460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id  feature_2    target         0         1         2  \\\n",
       "0  C_ID_92a2005557          2 -0.820283 -0.055851  0.147994 -0.030757   \n",
       "1  C_ID_3d0044924f          1  0.392913 -0.055640  0.154444 -0.048635   \n",
       "2  C_ID_d639edf6cd          2  0.688056  0.038449  0.033729 -0.036073   \n",
       "3  C_ID_186d6a6901          3  0.142495  0.044003 -0.005825 -0.096572   \n",
       "4  C_ID_cdbd2c0db2          3 -0.159749  0.078187 -0.054140 -0.079138   \n",
       "\n",
       "          3         4         5         6         7         8         9  \\\n",
       "0 -0.073910 -0.010504 -0.063806  0.180107 -0.113234 -0.076563 -0.022222   \n",
       "1 -0.070090  0.017265 -0.042851  0.134029 -0.033346 -0.042521 -0.006478   \n",
       "2 -0.118617  0.068142  0.057314  0.033151  0.074983  0.034293 -0.042218   \n",
       "3 -0.053282 -0.207161 -0.088515 -0.118196 -0.038728  0.108079  0.132761   \n",
       "4 -0.052407 -0.314112 -0.103714 -0.183939 -0.040985  0.119379  0.190108   \n",
       "\n",
       "         10        11        12        13        14        15  \n",
       "0 -0.083477  0.082931  0.088083  0.074731 -0.004401 -0.057365  \n",
       "1 -0.073879  0.012347  0.064042  0.055082  0.043727 -0.019014  \n",
       "2 -0.002832 -0.039617  0.017628  0.014782 -0.065753  0.084333  \n",
       "3 -0.082925 -0.112086  0.094630 -0.015612  0.019117  0.214415  \n",
       "4 -0.083095 -0.125474  0.122729 -0.010624  0.031643  0.291460  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge id embeddings with train.csv \n",
    "dataset = train_file.merge(node2vec_embeddings, on = \"card_id\", how = \"left\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "568022e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.820283</td>\n",
       "      <td>-0.055851</td>\n",
       "      <td>0.147994</td>\n",
       "      <td>-0.030757</td>\n",
       "      <td>-0.073910</td>\n",
       "      <td>-0.010504</td>\n",
       "      <td>-0.063806</td>\n",
       "      <td>0.180107</td>\n",
       "      <td>-0.113234</td>\n",
       "      <td>-0.076563</td>\n",
       "      <td>-0.022222</td>\n",
       "      <td>-0.083477</td>\n",
       "      <td>0.082931</td>\n",
       "      <td>0.088083</td>\n",
       "      <td>0.074731</td>\n",
       "      <td>-0.004401</td>\n",
       "      <td>-0.057365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>1</td>\n",
       "      <td>0.392913</td>\n",
       "      <td>-0.055640</td>\n",
       "      <td>0.154444</td>\n",
       "      <td>-0.048635</td>\n",
       "      <td>-0.070090</td>\n",
       "      <td>0.017265</td>\n",
       "      <td>-0.042851</td>\n",
       "      <td>0.134029</td>\n",
       "      <td>-0.033346</td>\n",
       "      <td>-0.042521</td>\n",
       "      <td>-0.006478</td>\n",
       "      <td>-0.073879</td>\n",
       "      <td>0.012347</td>\n",
       "      <td>0.064042</td>\n",
       "      <td>0.055082</td>\n",
       "      <td>0.043727</td>\n",
       "      <td>-0.019014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>2</td>\n",
       "      <td>0.688056</td>\n",
       "      <td>0.038449</td>\n",
       "      <td>0.033729</td>\n",
       "      <td>-0.036073</td>\n",
       "      <td>-0.118617</td>\n",
       "      <td>0.068142</td>\n",
       "      <td>0.057314</td>\n",
       "      <td>0.033151</td>\n",
       "      <td>0.074983</td>\n",
       "      <td>0.034293</td>\n",
       "      <td>-0.042218</td>\n",
       "      <td>-0.002832</td>\n",
       "      <td>-0.039617</td>\n",
       "      <td>0.017628</td>\n",
       "      <td>0.014782</td>\n",
       "      <td>-0.065753</td>\n",
       "      <td>0.084333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_186d6a6901</td>\n",
       "      <td>3</td>\n",
       "      <td>0.142495</td>\n",
       "      <td>0.044003</td>\n",
       "      <td>-0.005825</td>\n",
       "      <td>-0.096572</td>\n",
       "      <td>-0.053282</td>\n",
       "      <td>-0.207161</td>\n",
       "      <td>-0.088515</td>\n",
       "      <td>-0.118196</td>\n",
       "      <td>-0.038728</td>\n",
       "      <td>0.108079</td>\n",
       "      <td>0.132761</td>\n",
       "      <td>-0.082925</td>\n",
       "      <td>-0.112086</td>\n",
       "      <td>0.094630</td>\n",
       "      <td>-0.015612</td>\n",
       "      <td>0.019117</td>\n",
       "      <td>0.214415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_cdbd2c0db2</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.159749</td>\n",
       "      <td>0.078187</td>\n",
       "      <td>-0.054140</td>\n",
       "      <td>-0.079138</td>\n",
       "      <td>-0.052407</td>\n",
       "      <td>-0.314112</td>\n",
       "      <td>-0.103714</td>\n",
       "      <td>-0.183939</td>\n",
       "      <td>-0.040985</td>\n",
       "      <td>0.119379</td>\n",
       "      <td>0.190108</td>\n",
       "      <td>-0.083095</td>\n",
       "      <td>-0.125474</td>\n",
       "      <td>0.122729</td>\n",
       "      <td>-0.010624</td>\n",
       "      <td>0.031643</td>\n",
       "      <td>0.291460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201912</th>\n",
       "      <td>C_ID_963962de2c</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.740821</td>\n",
       "      <td>-0.013122</td>\n",
       "      <td>0.236870</td>\n",
       "      <td>0.289252</td>\n",
       "      <td>-0.207090</td>\n",
       "      <td>0.117136</td>\n",
       "      <td>0.291800</td>\n",
       "      <td>-0.057458</td>\n",
       "      <td>-0.159941</td>\n",
       "      <td>-0.003747</td>\n",
       "      <td>-0.032952</td>\n",
       "      <td>0.061431</td>\n",
       "      <td>-0.194918</td>\n",
       "      <td>-0.111148</td>\n",
       "      <td>-0.043113</td>\n",
       "      <td>0.226498</td>\n",
       "      <td>0.355421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201913</th>\n",
       "      <td>C_ID_1314773c0b</td>\n",
       "      <td>1</td>\n",
       "      <td>0.312917</td>\n",
       "      <td>0.157420</td>\n",
       "      <td>0.181673</td>\n",
       "      <td>0.014512</td>\n",
       "      <td>0.340475</td>\n",
       "      <td>0.206347</td>\n",
       "      <td>-0.333574</td>\n",
       "      <td>-0.078791</td>\n",
       "      <td>-0.052758</td>\n",
       "      <td>0.221056</td>\n",
       "      <td>0.040981</td>\n",
       "      <td>0.055776</td>\n",
       "      <td>0.065528</td>\n",
       "      <td>0.173127</td>\n",
       "      <td>-0.056813</td>\n",
       "      <td>0.453101</td>\n",
       "      <td>-0.017889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201914</th>\n",
       "      <td>C_ID_7666735b3d</td>\n",
       "      <td>3</td>\n",
       "      <td>0.093494</td>\n",
       "      <td>-0.091114</td>\n",
       "      <td>0.054468</td>\n",
       "      <td>0.209246</td>\n",
       "      <td>0.073199</td>\n",
       "      <td>-0.016835</td>\n",
       "      <td>0.157624</td>\n",
       "      <td>0.065694</td>\n",
       "      <td>-0.256720</td>\n",
       "      <td>0.005213</td>\n",
       "      <td>0.187832</td>\n",
       "      <td>-0.003995</td>\n",
       "      <td>0.051171</td>\n",
       "      <td>-0.050330</td>\n",
       "      <td>-0.070680</td>\n",
       "      <td>0.037467</td>\n",
       "      <td>0.302887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201915</th>\n",
       "      <td>C_ID_73f5a0efd0</td>\n",
       "      <td>2</td>\n",
       "      <td>-4.676589</td>\n",
       "      <td>-0.098452</td>\n",
       "      <td>0.204648</td>\n",
       "      <td>-0.056958</td>\n",
       "      <td>-0.107394</td>\n",
       "      <td>0.025139</td>\n",
       "      <td>-0.055621</td>\n",
       "      <td>0.171532</td>\n",
       "      <td>-0.061262</td>\n",
       "      <td>-0.067451</td>\n",
       "      <td>-0.019096</td>\n",
       "      <td>-0.095742</td>\n",
       "      <td>0.029680</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.026158</td>\n",
       "      <td>0.021642</td>\n",
       "      <td>-0.008106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201916</th>\n",
       "      <td>C_ID_92c9984c58</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.859413</td>\n",
       "      <td>-0.023618</td>\n",
       "      <td>0.124383</td>\n",
       "      <td>0.013698</td>\n",
       "      <td>-0.059738</td>\n",
       "      <td>0.070913</td>\n",
       "      <td>0.055465</td>\n",
       "      <td>0.026387</td>\n",
       "      <td>-0.013415</td>\n",
       "      <td>0.027691</td>\n",
       "      <td>-0.021853</td>\n",
       "      <td>-0.020800</td>\n",
       "      <td>-0.100631</td>\n",
       "      <td>-0.034113</td>\n",
       "      <td>-0.025610</td>\n",
       "      <td>0.062456</td>\n",
       "      <td>0.102763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201917 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                card_id  feature_2    target         0         1         2  \\\n",
       "0       C_ID_92a2005557          2 -0.820283 -0.055851  0.147994 -0.030757   \n",
       "1       C_ID_3d0044924f          1  0.392913 -0.055640  0.154444 -0.048635   \n",
       "2       C_ID_d639edf6cd          2  0.688056  0.038449  0.033729 -0.036073   \n",
       "3       C_ID_186d6a6901          3  0.142495  0.044003 -0.005825 -0.096572   \n",
       "4       C_ID_cdbd2c0db2          3 -0.159749  0.078187 -0.054140 -0.079138   \n",
       "...                 ...        ...       ...       ...       ...       ...   \n",
       "201912  C_ID_963962de2c          2 -2.740821 -0.013122  0.236870  0.289252   \n",
       "201913  C_ID_1314773c0b          1  0.312917  0.157420  0.181673  0.014512   \n",
       "201914  C_ID_7666735b3d          3  0.093494 -0.091114  0.054468  0.209246   \n",
       "201915  C_ID_73f5a0efd0          2 -4.676589 -0.098452  0.204648 -0.056958   \n",
       "201916  C_ID_92c9984c58          1 -1.859413 -0.023618  0.124383  0.013698   \n",
       "\n",
       "               3         4         5         6         7         8         9  \\\n",
       "0      -0.073910 -0.010504 -0.063806  0.180107 -0.113234 -0.076563 -0.022222   \n",
       "1      -0.070090  0.017265 -0.042851  0.134029 -0.033346 -0.042521 -0.006478   \n",
       "2      -0.118617  0.068142  0.057314  0.033151  0.074983  0.034293 -0.042218   \n",
       "3      -0.053282 -0.207161 -0.088515 -0.118196 -0.038728  0.108079  0.132761   \n",
       "4      -0.052407 -0.314112 -0.103714 -0.183939 -0.040985  0.119379  0.190108   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "201912 -0.207090  0.117136  0.291800 -0.057458 -0.159941 -0.003747 -0.032952   \n",
       "201913  0.340475  0.206347 -0.333574 -0.078791 -0.052758  0.221056  0.040981   \n",
       "201914  0.073199 -0.016835  0.157624  0.065694 -0.256720  0.005213  0.187832   \n",
       "201915 -0.107394  0.025139 -0.055621  0.171532 -0.061262 -0.067451 -0.019096   \n",
       "201916 -0.059738  0.070913  0.055465  0.026387 -0.013415  0.027691 -0.021853   \n",
       "\n",
       "              10        11        12        13        14        15  \n",
       "0      -0.083477  0.082931  0.088083  0.074731 -0.004401 -0.057365  \n",
       "1      -0.073879  0.012347  0.064042  0.055082  0.043727 -0.019014  \n",
       "2      -0.002832 -0.039617  0.017628  0.014782 -0.065753  0.084333  \n",
       "3      -0.082925 -0.112086  0.094630 -0.015612  0.019117  0.214415  \n",
       "4      -0.083095 -0.125474  0.122729 -0.010624  0.031643  0.291460  \n",
       "...          ...       ...       ...       ...       ...       ...  \n",
       "201912  0.061431 -0.194918 -0.111148 -0.043113  0.226498  0.355421  \n",
       "201913  0.055776  0.065528  0.173127 -0.056813  0.453101 -0.017889  \n",
       "201914 -0.003995  0.051171 -0.050330 -0.070680  0.037467  0.302887  \n",
       "201915 -0.095742  0.029680  0.049383  0.026158  0.021642 -0.008106  \n",
       "201916 -0.020800 -0.100631 -0.034113 -0.025610  0.062456  0.102763  \n",
       "\n",
       "[201917 rows x 19 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge id mode \n",
    "dataset = dataset.merge(id_features, on = \"card_id\", how = \"left\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "990bc64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([                       'card_id',                      'feature_2',\n",
       "                               'target',                                0,\n",
       "                                      1,                                2,\n",
       "                                      3,                                4,\n",
       "                                      5,                                6,\n",
       "                                      7,                                8,\n",
       "                                      9,                               10,\n",
       "                                     11,                               12,\n",
       "                                     13,                               14,\n",
       "                                     15,            'nunique_merchant_id',\n",
       "                    'count_merchant_id', 'nunique_count_frac_merchant_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7042380e",
   "metadata": {},
   "source": [
    "### evaluate on baseline dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6b0d7e7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define columns for training\n",
    "baseline_feature_names = [\"feature_2\"]\n",
    "embedding_feature_names = list(range(embedding_size))\n",
    "id_feature_feature_names = [\"nunique_merchant_id\",\"count_merchant_id\",\"nunique_count_frac_merchant_id\"]\n",
    "categorical_feature_names = [\"feature_2\"]\n",
    "target_col = \"target\"\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a5575dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = baseline_feature_names\n",
    "X,y = dataset[features], dataset[target_col]\n",
    "cv = 5\n",
    "scoring=('r2', 'neg_root_mean_squared_error')\n",
    "verbose = 1\n",
    "model_params = {\n",
    "    \"learning_rate\":0.01,\n",
    "    \"max_iter\":100,\n",
    "    \"categorical_features\" : X.columns.isin(categorical_feature_names),\n",
    "    \"l2_regularization\":0.005,\n",
    "    \"early_stopping\":True,\n",
    "    \"n_iter_no_change\":5,\n",
    "    \"verbose\":1,\n",
    "    \"random_state\":0,\n",
    "    \"max_depth\":5,\n",
    "    \"max_leaf_nodes\":20\n",
    "}\n",
    "model = HistGradientBoostingRegressor(**model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "471b06ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] START .....................................................................\n",
      "Binning 0.001 GB of training data: 0.001 s\n",
      "Binning 0.000 GB of validation data: 0.001 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34904, val loss: 8.13150, in 0.007s\n",
      "[2/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34900, val loss: 8.13149, in 0.008s\n",
      "[3/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34896, val loss: 8.13148, in 0.009s\n",
      "[4/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34892, val loss: 8.13147, in 0.007s\n",
      "[5/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34888, val loss: 8.13147, in 0.008s\n",
      "[6/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34884, val loss: 8.13146, in 0.007s\n",
      "[7/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34880, val loss: 8.13146, in 0.007s\n",
      "[8/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34877, val loss: 8.13145, in 0.008s\n",
      "[9/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34873, val loss: 8.13144, in 0.008s\n",
      "[10/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34869, val loss: 8.13144, in 0.008s\n",
      "[11/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34866, val loss: 8.13144, in 0.007s\n",
      "[12/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34863, val loss: 8.13143, in 0.008s\n",
      "[13/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34859, val loss: 8.13143, in 0.008s\n",
      "[14/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34856, val loss: 8.13142, in 0.007s\n",
      "[15/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34853, val loss: 8.13142, in 0.008s\n",
      "[16/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34850, val loss: 8.13142, in 0.008s\n",
      "[17/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34847, val loss: 8.13142, in 0.008s\n",
      "[18/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34843, val loss: 8.13141, in 0.008s\n",
      "[19/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34841, val loss: 8.13141, in 0.008s\n",
      "[20/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34838, val loss: 8.13141, in 0.006s\n",
      "[21/100] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tree, 3 leaves, max depth = 2, train loss: 7.34835, val loss: 8.13141, in 0.007s\n",
      "[22/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34832, val loss: 8.13141, in 0.008s\n",
      "[23/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34829, val loss: 8.13141, in 0.009s\n",
      "[24/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34827, val loss: 8.13141, in 0.008s\n",
      "[25/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34824, val loss: 8.13141, in 0.008s\n",
      "[26/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34821, val loss: 8.13141, in 0.007s\n",
      "[27/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34819, val loss: 8.13141, in 0.007s\n",
      "[28/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34816, val loss: 8.13141, in 0.007s\n",
      "[29/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34814, val loss: 8.13141, in 0.007s\n",
      "Fit 29 trees in 0.247 s, (87 total leaves)\n",
      "Time spent computing histograms: 0.018s\n",
      "Time spent finding best splits:  0.005s\n",
      "Time spent applying splits:      0.037s\n",
      "Time spent predicting:           0.006s\n",
      "[CV] END  neg_root_mean_squared_error: (train=-3.854, test=-3.836) r2: (train=0.000, test=0.000) total time=   0.2s\n",
      "[CV] START .....................................................................\n",
      "Binning 0.001 GB of training data: 0.002 s\n",
      "Binning 0.000 GB of validation data: 0.001 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.38733, val loss: 7.81605, in 0.007s\n",
      "[2/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.38730, val loss: 7.81604, in 0.007s\n",
      "[3/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.38726, val loss: 7.81604, in 0.006s\n",
      "[4/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.38723, val loss: 7.81604, in 0.007s\n",
      "[5/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.38719, val loss: 7.81604, in 0.007s\n",
      "[6/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.38716, val loss: 7.81603, in 0.006s\n",
      "[7/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.38712, val loss: 7.81603, in 0.006s\n",
      "[8/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.38709, val loss: 7.81603, in 0.007s\n",
      "[9/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.38706, val loss: 7.81603, in 0.007s\n",
      "[10/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.38703, val loss: 7.81603, in 0.006s\n",
      "[11/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.38700, val loss: 7.81603, in 0.006s\n",
      "[12/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.38697, val loss: 7.81603, in 0.007s\n",
      "[13/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.38694, val loss: 7.81603, in 0.007s\n",
      "[14/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.38691, val loss: 7.81603, in 0.008s\n",
      "[15/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.38688, val loss: 7.81603, in 0.007s\n",
      "[16/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.38685, val loss: 7.81603, in 0.006s\n",
      "[17/100] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tree, 3 leaves, max depth = 2, train loss: 7.38682, val loss: 7.81603, in 0.006s\n",
      "Fit 17 trees in 0.146 s, (51 total leaves)\n",
      "Time spent computing histograms: 0.010s\n",
      "Time spent finding best splits:  0.003s\n",
      "Time spent applying splits:      0.019s\n",
      "Time spent predicting:           0.003s\n",
      "[CV] END  neg_root_mean_squared_error: (train=-3.855, test=-3.833) r2: (train=0.000, test=0.000) total time=   0.1s\n",
      "[CV] START .....................................................................\n",
      "Binning 0.001 GB of training data: 0.002 s\n",
      "Binning 0.000 GB of validation data: 0.000 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46241, val loss: 7.24254, in 0.006s\n",
      "[2/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46237, val loss: 7.24251, in 0.006s\n",
      "[3/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46233, val loss: 7.24248, in 0.006s\n",
      "[4/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46229, val loss: 7.24246, in 0.006s\n",
      "[5/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46225, val loss: 7.24243, in 0.006s\n",
      "[6/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46221, val loss: 7.24241, in 0.006s\n",
      "[7/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46217, val loss: 7.24238, in 0.007s\n",
      "[8/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46214, val loss: 7.24236, in 0.006s\n",
      "[9/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46210, val loss: 7.24233, in 0.007s\n",
      "[10/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46207, val loss: 7.24231, in 0.007s\n",
      "[11/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46203, val loss: 7.24229, in 0.006s\n",
      "[12/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46200, val loss: 7.24227, in 0.006s\n",
      "[13/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46197, val loss: 7.24225, in 0.007s\n",
      "[14/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46193, val loss: 7.24223, in 0.007s\n",
      "[15/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46190, val loss: 7.24221, in 0.006s\n",
      "[16/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46187, val loss: 7.24219, in 0.006s\n",
      "[17/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46184, val loss: 7.24217, in 0.006s\n",
      "[18/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46181, val loss: 7.24215, in 0.015s\n",
      "[19/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46178, val loss: 7.24213, in 0.008s\n",
      "[20/100] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tree, 3 leaves, max depth = 2, train loss: 7.46175, val loss: 7.24212, in 0.008s\n",
      "[21/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46173, val loss: 7.24210, in 0.007s\n",
      "[22/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46170, val loss: 7.24208, in 0.007s\n",
      "[23/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46167, val loss: 7.24207, in 0.006s\n",
      "[24/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46164, val loss: 7.24205, in 0.007s\n",
      "[25/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46162, val loss: 7.24204, in 0.006s\n",
      "[26/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46159, val loss: 7.24202, in 0.007s\n",
      "[27/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46157, val loss: 7.24201, in 0.007s\n",
      "[28/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46154, val loss: 7.24199, in 0.006s\n",
      "[29/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46152, val loss: 7.24198, in 0.006s\n",
      "[30/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46150, val loss: 7.24197, in 0.006s\n",
      "[31/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46147, val loss: 7.24195, in 0.007s\n",
      "[32/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46145, val loss: 7.24194, in 0.007s\n",
      "[33/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46143, val loss: 7.24193, in 0.006s\n",
      "[34/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46141, val loss: 7.24192, in 0.006s\n",
      "[35/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46139, val loss: 7.24191, in 0.007s\n",
      "[36/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46137, val loss: 7.24190, in 0.006s\n",
      "[37/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46135, val loss: 7.24188, in 0.006s\n",
      "[38/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46133, val loss: 7.24187, in 0.006s\n",
      "[39/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46131, val loss: 7.24186, in 0.007s\n",
      "[40/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46129, val loss: 7.24185, in 0.007s\n",
      "[41/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46127, val loss: 7.24184, in 0.006s\n",
      "[42/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46125, val loss: 7.24184, in 0.006s\n",
      "[43/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46123, val loss: 7.24183, in 0.006s\n",
      "[44/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46121, val loss: 7.24182, in 0.007s\n",
      "[45/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46120, val loss: 7.24181, in 0.007s\n",
      "[46/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46118, val loss: 7.24180, in 0.006s\n",
      "[47/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46116, val loss: 7.24179, in 0.006s\n",
      "[48/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46115, val loss: 7.24179, in 0.007s\n",
      "[49/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46113, val loss: 7.24178, in 0.007s\n",
      "[50/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46112, val loss: 7.24177, in 0.006s\n",
      "[51/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46110, val loss: 7.24176, in 0.006s\n",
      "[52/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46109, val loss: 7.24176, in 0.007s\n",
      "[53/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46107, val loss: 7.24175, in 0.007s\n",
      "[54/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46106, val loss: 7.24174, in 0.009s\n",
      "[55/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46104, val loss: 7.24174, in 0.007s\n",
      "[56/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46103, val loss: 7.24173, in 0.008s\n",
      "[57/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46101, val loss: 7.24173, in 0.009s\n",
      "[58/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46100, val loss: 7.24172, in 0.009s\n",
      "[59/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46099, val loss: 7.24171, in 0.008s\n",
      "[60/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46098, val loss: 7.24171, in 0.007s\n",
      "[61/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46096, val loss: 7.24170, in 0.007s\n",
      "[62/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46095, val loss: 7.24170, in 0.009s\n",
      "[63/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46094, val loss: 7.24169, in 0.009s\n",
      "[64/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46093, val loss: 7.24169, in 0.008s\n",
      "[65/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46092, val loss: 7.24169, in 0.009s\n",
      "[66/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46090, val loss: 7.24168, in 0.007s\n",
      "[67/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46089, val loss: 7.24168, in 0.006s\n",
      "[68/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46088, val loss: 7.24167, in 0.007s\n",
      "[69/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46087, val loss: 7.24167, in 0.008s\n",
      "[70/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46086, val loss: 7.24167, in 0.008s\n",
      "[71/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46085, val loss: 7.24166, in 0.007s\n",
      "[72/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46084, val loss: 7.24166, in 0.009s\n",
      "[73/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46083, val loss: 7.24166, in 0.009s\n",
      "[74/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46082, val loss: 7.24165, in 0.008s\n",
      "[75/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46081, val loss: 7.24165, in 0.008s\n",
      "[76/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46080, val loss: 7.24165, in 0.008s\n",
      "[77/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46079, val loss: 7.24164, in 0.009s\n",
      "[78/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46078, val loss: 7.24164, in 0.008s\n",
      "[79/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46078, val loss: 7.24164, in 0.008s\n",
      "[80/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46077, val loss: 7.24164, in 0.007s\n",
      "[81/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46076, val loss: 7.24163, in 0.008s\n",
      "[82/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46075, val loss: 7.24163, in 0.009s\n",
      "[83/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46074, val loss: 7.24163, in 0.009s\n",
      "[84/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46073, val loss: 7.24163, in 0.009s\n",
      "[85/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46073, val loss: 7.24163, in 0.007s\n",
      "[86/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46072, val loss: 7.24163, in 0.007s\n",
      "[87/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46071, val loss: 7.24162, in 0.007s\n",
      "[88/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46070, val loss: 7.24162, in 0.007s\n",
      "[89/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46070, val loss: 7.24162, in 0.007s\n",
      "[90/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46069, val loss: 7.24162, in 0.007s\n",
      "[91/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46068, val loss: 7.24162, in 0.008s\n",
      "[92/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46068, val loss: 7.24162, in 0.008s\n",
      "[93/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46067, val loss: 7.24162, in 0.009s\n",
      "[94/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46066, val loss: 7.24161, in 0.008s\n",
      "[95/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46066, val loss: 7.24161, in 0.007s\n",
      "[96/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46065, val loss: 7.24161, in 0.007s\n",
      "[97/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46064, val loss: 7.24161, in 0.008s\n",
      "[98/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46064, val loss: 7.24161, in 0.007s\n",
      "[99/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46063, val loss: 7.24161, in 0.008s\n",
      "[100/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46063, val loss: 7.24161, in 0.007s\n",
      "Fit 100 trees in 0.766 s, (300 total leaves)\n",
      "Time spent computing histograms: 0.059s\n",
      "Time spent finding best splits:  0.016s\n",
      "Time spent applying splits:      0.121s\n",
      "Time spent predicting:           0.022s\n",
      "[CV] END  neg_root_mean_squared_error: (train=-3.857, test=-3.822) r2: (train=0.000, test=0.000) total time=   0.8s\n",
      "[CV] START .....................................................................\n",
      "Binning 0.001 GB of training data: 0.002 s\n",
      "Binning 0.000 GB of validation data: 0.000 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51086, val loss: 6.62419, in 0.006s\n",
      "[2/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51082, val loss: 6.62417, in 0.007s\n",
      "[3/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51079, val loss: 6.62414, in 0.007s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51075, val loss: 6.62412, in 0.005s\n",
      "[5/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51072, val loss: 6.62410, in 0.007s\n",
      "[6/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51068, val loss: 6.62408, in 0.008s\n",
      "[7/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51065, val loss: 6.62405, in 0.007s\n",
      "[8/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51061, val loss: 6.62403, in 0.006s\n",
      "[9/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51058, val loss: 6.62401, in 0.007s\n",
      "[10/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51055, val loss: 6.62399, in 0.008s\n",
      "[11/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51052, val loss: 6.62397, in 0.007s\n",
      "[12/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51048, val loss: 6.62395, in 0.007s\n",
      "[13/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51045, val loss: 6.62393, in 0.008s\n",
      "[14/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51042, val loss: 6.62392, in 0.008s\n",
      "[15/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51040, val loss: 6.62390, in 0.007s\n",
      "[16/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51037, val loss: 6.62388, in 0.007s\n",
      "[17/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51034, val loss: 6.62386, in 0.008s\n",
      "[18/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51031, val loss: 6.62385, in 0.006s\n",
      "[19/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51028, val loss: 6.62383, in 0.006s\n",
      "[20/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51026, val loss: 6.62382, in 0.007s\n",
      "[21/100] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tree, 3 leaves, max depth = 2, train loss: 7.51023, val loss: 6.62380, in 0.008s\n",
      "[22/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51021, val loss: 6.62379, in 0.007s\n",
      "[23/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51018, val loss: 6.62377, in 0.007s\n",
      "[24/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51016, val loss: 6.62376, in 0.007s\n",
      "[25/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51013, val loss: 6.62375, in 0.006s\n",
      "[26/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51011, val loss: 6.62373, in 0.007s\n",
      "[27/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51009, val loss: 6.62372, in 0.007s\n",
      "[28/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51007, val loss: 6.62371, in 0.007s\n",
      "[29/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51004, val loss: 6.62370, in 0.006s\n",
      "[30/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51002, val loss: 6.62368, in 0.007s\n",
      "[31/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51000, val loss: 6.62367, in 0.007s\n",
      "[32/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50998, val loss: 6.62366, in 0.006s\n",
      "[33/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50996, val loss: 6.62365, in 0.007s\n",
      "[34/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50994, val loss: 6.62364, in 0.007s\n",
      "[35/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50992, val loss: 6.62363, in 0.007s\n",
      "[36/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50990, val loss: 6.62362, in 0.006s\n",
      "[37/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50988, val loss: 6.62361, in 0.006s\n",
      "[38/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50986, val loss: 6.62360, in 0.007s\n",
      "[39/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50985, val loss: 6.62359, in 0.007s\n",
      "[40/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50983, val loss: 6.62358, in 0.007s\n",
      "[41/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50981, val loss: 6.62358, in 0.006s\n",
      "[42/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50979, val loss: 6.62357, in 0.007s\n",
      "[43/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50978, val loss: 6.62356, in 0.007s\n",
      "[44/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50976, val loss: 6.62355, in 0.007s\n",
      "[45/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50975, val loss: 6.62354, in 0.007s\n",
      "[46/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50973, val loss: 6.62354, in 0.006s\n",
      "[47/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50971, val loss: 6.62353, in 0.006s\n",
      "[48/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50970, val loss: 6.62352, in 0.007s\n",
      "[49/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50968, val loss: 6.62352, in 0.007s\n",
      "[50/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50967, val loss: 6.62351, in 0.007s\n",
      "[51/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50966, val loss: 6.62350, in 0.007s\n",
      "[52/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50964, val loss: 6.62350, in 0.006s\n",
      "[53/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50963, val loss: 6.62349, in 0.007s\n",
      "[54/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50962, val loss: 6.62349, in 0.008s\n",
      "[55/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50960, val loss: 6.62348, in 0.008s\n",
      "[56/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50959, val loss: 6.62348, in 0.006s\n",
      "[57/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50958, val loss: 6.62347, in 0.007s\n",
      "[58/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50957, val loss: 6.62347, in 0.007s\n",
      "[59/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50955, val loss: 6.62346, in 0.006s\n",
      "[60/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50954, val loss: 6.62346, in 0.006s\n",
      "[61/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50953, val loss: 6.62345, in 0.008s\n",
      "[62/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50952, val loss: 6.62345, in 0.007s\n",
      "[63/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50951, val loss: 6.62344, in 0.008s\n",
      "[64/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50950, val loss: 6.62344, in 0.007s\n",
      "[65/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50949, val loss: 6.62344, in 0.007s\n",
      "[66/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50948, val loss: 6.62343, in 0.007s\n",
      "[67/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50946, val loss: 6.62343, in 0.007s\n",
      "[68/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50945, val loss: 6.62343, in 0.006s\n",
      "[69/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50945, val loss: 6.62342, in 0.007s\n",
      "[70/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50944, val loss: 6.62342, in 0.008s\n",
      "[71/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50943, val loss: 6.62342, in 0.006s\n",
      "[72/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50942, val loss: 6.62341, in 0.006s\n",
      "[73/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50941, val loss: 6.62341, in 0.006s\n",
      "[74/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50940, val loss: 6.62341, in 0.006s\n",
      "[75/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50939, val loss: 6.62341, in 0.006s\n",
      "[76/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50938, val loss: 6.62340, in 0.006s\n",
      "[77/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50937, val loss: 6.62340, in 0.006s\n",
      "[78/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50936, val loss: 6.62340, in 0.007s\n",
      "[79/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50936, val loss: 6.62340, in 0.007s\n",
      "[80/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50935, val loss: 6.62340, in 0.006s\n",
      "[81/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50934, val loss: 6.62339, in 0.006s\n",
      "[82/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50933, val loss: 6.62339, in 0.007s\n",
      "[83/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50933, val loss: 6.62339, in 0.007s\n",
      "[84/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50932, val loss: 6.62339, in 0.006s\n",
      "[85/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50931, val loss: 6.62339, in 0.006s\n",
      "[86/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50930, val loss: 6.62339, in 0.006s\n",
      "[87/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50930, val loss: 6.62339, in 0.007s\n",
      "[88/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50929, val loss: 6.62338, in 0.007s\n",
      "[89/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50928, val loss: 6.62338, in 0.007s\n",
      "[90/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50928, val loss: 6.62338, in 0.006s\n",
      "[91/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50927, val loss: 6.62338, in 0.007s\n",
      "[92/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50927, val loss: 6.62338, in 0.008s\n",
      "[93/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50926, val loss: 6.62338, in 0.007s\n",
      "[94/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50925, val loss: 6.62338, in 0.006s\n",
      "[95/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50925, val loss: 6.62338, in 0.007s\n",
      "[96/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50924, val loss: 6.62338, in 0.006s\n",
      "[97/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50924, val loss: 6.62338, in 0.006s\n",
      "[98/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50923, val loss: 6.62338, in 0.006s\n",
      "[99/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50923, val loss: 6.62338, in 0.006s\n",
      "[100/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50922, val loss: 6.62338, in 0.006s\n",
      "Fit 100 trees in 0.714 s, (300 total leaves)\n",
      "Time spent computing histograms: 0.057s\n",
      "Time spent finding best splits:  0.014s\n",
      "Time spent applying splits:      0.110s\n",
      "Time spent predicting:           0.021s\n",
      "[CV] END  neg_root_mean_squared_error: (train=-3.852, test=-3.841) r2: (train=0.000, test=0.000) total time=   0.7s\n",
      "[CV] START .....................................................................\n",
      "Binning 0.001 GB of training data: 0.001 s\n",
      "Binning 0.000 GB of validation data: 0.001 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43395, val loss: 6.54928, in 0.008s\n",
      "[2/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43392, val loss: 6.54923, in 0.009s\n",
      "[3/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43389, val loss: 6.54918, in 0.008s\n",
      "[4/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43386, val loss: 6.54912, in 0.008s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43383, val loss: 6.54908, in 0.007s\n",
      "[6/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43380, val loss: 6.54903, in 0.008s\n",
      "[7/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43377, val loss: 6.54898, in 0.008s\n",
      "[8/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43374, val loss: 6.54893, in 0.007s\n",
      "[9/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43371, val loss: 6.54888, in 0.007s\n",
      "[10/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43369, val loss: 6.54884, in 0.008s\n",
      "[11/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43366, val loss: 6.54879, in 0.008s\n",
      "[12/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43364, val loss: 6.54875, in 0.007s\n",
      "[13/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43361, val loss: 6.54870, in 0.007s\n",
      "[14/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43358, val loss: 6.54866, in 0.007s\n",
      "[15/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43356, val loss: 6.54862, in 0.007s\n",
      "[16/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43354, val loss: 6.54858, in 0.008s\n",
      "[17/100] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    2.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tree, 3 leaves, max depth = 2, train loss: 7.43351, val loss: 6.54854, in 0.007s\n",
      "[18/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43349, val loss: 6.54850, in 0.006s\n",
      "[19/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43347, val loss: 6.54846, in 0.006s\n",
      "[20/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43345, val loss: 6.54842, in 0.006s\n",
      "[21/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43342, val loss: 6.54838, in 0.007s\n",
      "[22/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43340, val loss: 6.54834, in 0.007s\n",
      "[23/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43338, val loss: 6.54830, in 0.007s\n",
      "[24/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43336, val loss: 6.54827, in 0.007s\n",
      "[25/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43334, val loss: 6.54823, in 0.006s\n",
      "[26/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43332, val loss: 6.54819, in 0.006s\n",
      "[27/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43330, val loss: 6.54816, in 0.007s\n",
      "[28/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43328, val loss: 6.54812, in 0.006s\n",
      "[29/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43327, val loss: 6.54809, in 0.006s\n",
      "[30/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43325, val loss: 6.54806, in 0.007s\n",
      "[31/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43323, val loss: 6.54802, in 0.007s\n",
      "[32/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43321, val loss: 6.54799, in 0.007s\n",
      "[33/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43319, val loss: 6.54796, in 0.007s\n",
      "[34/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43318, val loss: 6.54793, in 0.006s\n",
      "[35/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43316, val loss: 6.54790, in 0.006s\n",
      "[36/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43315, val loss: 6.54787, in 0.007s\n",
      "[37/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43313, val loss: 6.54784, in 0.007s\n",
      "[38/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43311, val loss: 6.54781, in 0.007s\n",
      "[39/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43310, val loss: 6.54778, in 0.006s\n",
      "[40/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43308, val loss: 6.54775, in 0.007s\n",
      "[41/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43307, val loss: 6.54772, in 0.007s\n",
      "[42/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43306, val loss: 6.54769, in 0.007s\n",
      "[43/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43304, val loss: 6.54767, in 0.008s\n",
      "[44/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43303, val loss: 6.54764, in 0.007s\n",
      "[45/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43302, val loss: 6.54761, in 0.007s\n",
      "[46/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43300, val loss: 6.54759, in 0.006s\n",
      "[47/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43299, val loss: 6.54756, in 0.007s\n",
      "[48/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43298, val loss: 6.54753, in 0.007s\n",
      "[49/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43296, val loss: 6.54751, in 0.007s\n",
      "[50/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43295, val loss: 6.54748, in 0.007s\n",
      "[51/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43294, val loss: 6.54746, in 0.007s\n",
      "[52/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43293, val loss: 6.54744, in 0.007s\n",
      "[53/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43292, val loss: 6.54741, in 0.006s\n",
      "[54/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43291, val loss: 6.54739, in 0.007s\n",
      "[55/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43290, val loss: 6.54737, in 0.007s\n",
      "[56/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43288, val loss: 6.54734, in 0.007s\n",
      "[57/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43287, val loss: 6.54732, in 0.007s\n",
      "[58/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43286, val loss: 6.54730, in 0.006s\n",
      "[59/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43285, val loss: 6.54728, in 0.007s\n",
      "[60/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43284, val loss: 6.54726, in 0.007s\n",
      "[61/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43283, val loss: 6.54724, in 0.007s\n",
      "[62/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43282, val loss: 6.54721, in 0.007s\n",
      "[63/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43282, val loss: 6.54719, in 0.006s\n",
      "[64/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43281, val loss: 6.54717, in 0.006s\n",
      "[65/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43280, val loss: 6.54715, in 0.007s\n",
      "[66/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43279, val loss: 6.54713, in 0.007s\n",
      "[67/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43278, val loss: 6.54712, in 0.007s\n",
      "[68/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43277, val loss: 6.54710, in 0.007s\n",
      "[69/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43276, val loss: 6.54708, in 0.006s\n",
      "[70/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43276, val loss: 6.54706, in 0.006s\n",
      "[71/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43275, val loss: 6.54704, in 0.007s\n",
      "[72/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43274, val loss: 6.54702, in 0.006s\n",
      "[73/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43273, val loss: 6.54701, in 0.007s\n",
      "[74/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43272, val loss: 6.54699, in 0.007s\n",
      "[75/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43272, val loss: 6.54697, in 0.007s\n",
      "[76/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43271, val loss: 6.54695, in 0.006s\n",
      "[77/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43270, val loss: 6.54694, in 0.006s\n",
      "[78/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43270, val loss: 6.54692, in 0.014s\n",
      "[79/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43269, val loss: 6.54691, in 0.008s\n",
      "[80/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43268, val loss: 6.54689, in 0.007s\n",
      "[81/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43268, val loss: 6.54687, in 0.006s\n",
      "[82/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43267, val loss: 6.54686, in 0.009s\n",
      "[83/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43266, val loss: 6.54684, in 0.006s\n",
      "[84/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43266, val loss: 6.54683, in 0.006s\n",
      "[85/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43265, val loss: 6.54681, in 0.006s\n",
      "[86/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43265, val loss: 6.54680, in 0.006s\n",
      "[87/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43264, val loss: 6.54678, in 0.007s\n",
      "[88/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43263, val loss: 6.54677, in 0.006s\n",
      "[89/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43263, val loss: 6.54676, in 0.006s\n",
      "[90/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43262, val loss: 6.54674, in 0.006s\n",
      "[91/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43262, val loss: 6.54673, in 0.007s\n",
      "[92/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43261, val loss: 6.54671, in 0.006s\n",
      "[93/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43261, val loss: 6.54670, in 0.006s\n",
      "[94/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43260, val loss: 6.54669, in 0.006s\n",
      "[95/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43260, val loss: 6.54667, in 0.006s\n",
      "[96/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43259, val loss: 6.54666, in 0.007s\n",
      "[97/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43259, val loss: 6.54665, in 0.007s\n",
      "[98/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43258, val loss: 6.54664, in 0.006s\n",
      "[99/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43258, val loss: 6.54662, in 0.005s\n",
      "[100/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43257, val loss: 6.54661, in 0.007s\n",
      "Fit 100 trees in 0.734 s, (300 total leaves)\n",
      "Time spent computing histograms: 0.059s\n",
      "Time spent finding best splits:  0.014s\n",
      "Time spent applying splits:      0.121s\n",
      "Time spent predicting:           0.022s\n",
      "[CV] END  neg_root_mean_squared_error: (train=-3.832, test=-3.920) r2: (train=0.000, test=0.000) total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    3.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    3.9s finished\n"
     ]
    }
   ],
   "source": [
    "scores = cross_validate(estimator = model, \n",
    "                        X = X, \n",
    "                        y = y, \n",
    "                        cv=cv,\n",
    "                        scoring=scoring,\n",
    "                        verbose = 10,\n",
    "                        return_train_score=True)\n",
    "results[\"baseline\"] = scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae7e0c6",
   "metadata": {},
   "source": [
    "### evaluate on baseline with embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d4cff7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = baseline_feature_names + embedding_feature_names\n",
    "X,y = dataset[features], dataset[target_col]\n",
    "cv = 5\n",
    "scoring=('r2', 'neg_root_mean_squared_error')\n",
    "verbose = 1\n",
    "model_params = {\n",
    "    \"learning_rate\":0.01,\n",
    "    \"max_iter\":100,\n",
    "    \"categorical_features\" : X.columns.isin(categorical_feature_names),\n",
    "    \"l2_regularization\":0.005,\n",
    "    \"early_stopping\":True,\n",
    "    \"n_iter_no_change\":5,\n",
    "    \"verbose\":1,\n",
    "    \"random_state\":0,\n",
    "    \"max_depth\":5,\n",
    "    \"max_leaf_nodes\":20\n",
    "}\n",
    "model = HistGradientBoostingRegressor(**model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f7ea9ab6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.020 GB of training data: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.341 s\n",
      "Binning 0.002 GB of validation data: 0.004 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34880, val loss: 8.13134, in 0.016s\n",
      "[2/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34853, val loss: 8.13120, in 0.016s\n",
      "[3/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34828, val loss: 8.13113, in 0.017s\n",
      "[4/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34804, val loss: 8.13110, in 0.016s\n",
      "[5/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34780, val loss: 8.13102, in 0.016s\n",
      "[6/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34757, val loss: 8.13099, in 0.015s\n",
      "[7/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34734, val loss: 8.13091, in 0.015s\n",
      "[8/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34709, val loss: 8.13083, in 0.015s\n",
      "[9/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34686, val loss: 8.13077, in 0.015s\n",
      "[10/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34664, val loss: 8.13070, in 0.015s\n",
      "[11/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34641, val loss: 8.13067, in 0.015s\n",
      "[12/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34615, val loss: 8.13048, in 0.015s\n",
      "[13/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34588, val loss: 8.13046, in 0.015s\n",
      "[14/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34564, val loss: 8.13037, in 0.015s\n",
      "[15/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34542, val loss: 8.13033, in 0.015s\n",
      "[16/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34519, val loss: 8.13027, in 0.015s\n",
      "[17/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34499, val loss: 8.13023, in 0.014s\n",
      "[18/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34477, val loss: 8.13018, in 0.014s\n",
      "[19/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34457, val loss: 8.13016, in 0.015s\n",
      "[20/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34434, val loss: 8.13010, in 0.014s\n",
      "[21/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34414, val loss: 8.13009, in 0.014s\n",
      "[22/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34394, val loss: 8.13004, in 0.018s\n",
      "[23/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34375, val loss: 8.13005, in 0.018s\n",
      "[24/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34355, val loss: 8.13000, in 0.016s\n",
      "[25/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34335, val loss: 8.12994, in 0.036s\n",
      "[26/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34315, val loss: 8.12994, in 0.017s\n",
      "[27/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34297, val loss: 8.12991, in 0.018s\n",
      "[28/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34276, val loss: 8.12990, in 0.019s\n",
      "[29/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34255, val loss: 8.12986, in 0.019s\n",
      "[30/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34231, val loss: 8.12987, in 0.016s\n",
      "[31/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34212, val loss: 8.12983, in 0.018s\n",
      "[32/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34192, val loss: 8.12980, in 0.017s\n",
      "[33/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34169, val loss: 8.12982, in 0.020s\n",
      "[34/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34146, val loss: 8.12978, in 0.020s\n",
      "[35/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34127, val loss: 8.12982, in 0.021s\n",
      "[36/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34104, val loss: 8.12977, in 0.018s\n",
      "[37/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34083, val loss: 8.12977, in 0.016s\n",
      "[38/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34063, val loss: 8.12977, in 0.015s\n",
      "[39/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34042, val loss: 8.12978, in 0.014s\n",
      "[40/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34022, val loss: 8.12979, in 0.014s\n",
      "[41/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34002, val loss: 8.12979, in 0.014s\n",
      "Fit 41 trees in 1.102 s, (820 total leaves)\n",
      "Time spent computing histograms: 0.148s\n",
      "Time spent finding best splits:  0.048s\n",
      "Time spent applying splits:      0.137s\n",
      "Time spent predicting:           0.014s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.020 GB of training data: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.388 s\n",
      "Binning 0.002 GB of validation data: 0.005 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38709, val loss: 7.81595, in 0.014s\n",
      "[2/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38681, val loss: 7.81583, in 0.013s\n",
      "[3/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38654, val loss: 7.81579, in 0.016s\n",
      "[4/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38627, val loss: 7.81567, in 0.013s\n",
      "[5/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38600, val loss: 7.81559, in 0.014s\n",
      "[6/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38572, val loss: 7.81551, in 0.016s\n",
      "[7/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38548, val loss: 7.81539, in 0.014s\n",
      "[8/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38521, val loss: 7.81531, in 0.013s\n",
      "[9/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38494, val loss: 7.81526, in 0.014s\n",
      "[10/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38468, val loss: 7.81517, in 0.015s\n",
      "[11/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38445, val loss: 7.81509, in 0.015s\n",
      "[12/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38420, val loss: 7.81511, in 0.013s\n",
      "[13/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38396, val loss: 7.81515, in 0.014s\n",
      "[14/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38370, val loss: 7.81513, in 0.015s\n",
      "[15/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38345, val loss: 7.81506, in 0.014s\n",
      "[16/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38321, val loss: 7.81508, in 0.014s\n",
      "[17/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38296, val loss: 7.81509, in 0.015s\n",
      "[18/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38267, val loss: 7.81509, in 0.014s\n",
      "[19/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38244, val loss: 7.81513, in 0.013s\n",
      "[20/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38215, val loss: 7.81517, in 0.012s\n",
      "Fit 20 trees in 0.767 s, (400 total leaves)\n",
      "Time spent computing histograms: 0.060s\n",
      "Time spent finding best splits:  0.017s\n",
      "Time spent applying splits:      0.053s\n",
      "Time spent predicting:           0.005s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.020 GB of training data: 0.342 s\n",
      "Binning 0.002 GB of validation data: 0.005 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.46216, val loss: 7.24252, in 0.015s\n",
      "[2/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.46188, val loss: 7.24250, in 0.015s\n",
      "[3/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.46159, val loss: 7.24240, in 0.015s\n",
      "[4/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.46131, val loss: 7.24235, in 0.012s\n",
      "[5/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.46103, val loss: 7.24229, in 0.015s\n",
      "[6/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.46077, val loss: 7.24224, in 0.014s\n",
      "[7/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.46049, val loss: 7.24217, in 0.014s\n",
      "[8/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.46023, val loss: 7.24212, in 0.013s\n",
      "[9/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45997, val loss: 7.24209, in 0.015s\n",
      "[10/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45969, val loss: 7.24203, in 0.014s\n",
      "[11/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45942, val loss: 7.24199, in 0.014s\n",
      "[12/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45916, val loss: 7.24193, in 0.014s\n",
      "[13/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45892, val loss: 7.24187, in 0.014s\n",
      "[14/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45867, val loss: 7.24186, in 0.013s\n",
      "[15/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45842, val loss: 7.24181, in 0.014s\n",
      "[16/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45816, val loss: 7.24179, in 0.014s\n",
      "[17/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45791, val loss: 7.24174, in 0.015s\n",
      "[18/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45762, val loss: 7.24170, in 0.014s\n",
      "[19/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45739, val loss: 7.24165, in 0.015s\n",
      "[20/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45711, val loss: 7.24161, in 0.014s\n",
      "[21/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45687, val loss: 7.24160, in 0.013s\n",
      "[22/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45663, val loss: 7.24156, in 0.018s\n",
      "[23/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45634, val loss: 7.24155, in 0.018s\n",
      "[24/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45610, val loss: 7.24153, in 0.017s\n",
      "[25/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45587, val loss: 7.24150, in 0.018s\n",
      "[26/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45564, val loss: 7.24152, in 0.017s\n",
      "[27/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45536, val loss: 7.24146, in 0.016s\n",
      "[28/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45513, val loss: 7.24144, in 0.017s\n",
      "[29/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45488, val loss: 7.24141, in 0.016s\n",
      "[30/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45461, val loss: 7.24140, in 0.016s\n",
      "[31/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45440, val loss: 7.24137, in 0.019s\n",
      "[32/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45413, val loss: 7.24139, in 0.019s\n",
      "[33/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45393, val loss: 7.24137, in 0.022s\n",
      "[34/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45370, val loss: 7.24137, in 0.020s\n",
      "[35/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45347, val loss: 7.24135, in 0.017s\n",
      "[36/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45327, val loss: 7.24133, in 0.020s\n",
      "[37/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45304, val loss: 7.24134, in 0.016s\n",
      "[38/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45285, val loss: 7.24132, in 0.016s\n",
      "[39/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45261, val loss: 7.24136, in 0.015s\n",
      "[40/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45242, val loss: 7.24136, in 0.013s\n",
      "[41/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45222, val loss: 7.24134, in 0.016s\n",
      "[42/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45199, val loss: 7.24138, in 0.013s\n",
      "[43/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45178, val loss: 7.24134, in 0.017s\n",
      "Fit 43 trees in 1.111 s, (860 total leaves)\n",
      "Time spent computing histograms: 0.149s\n",
      "Time spent finding best splits:  0.046s\n",
      "Time spent applying splits:      0.137s\n",
      "Time spent predicting:           0.013s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.020 GB of training data: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.339 s\n",
      "Binning 0.002 GB of validation data: 0.005 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.51064, val loss: 6.62420, in 0.015s\n",
      "[2/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.51039, val loss: 6.62417, in 0.015s\n",
      "[3/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.51015, val loss: 6.62412, in 0.015s\n",
      "[4/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50990, val loss: 6.62407, in 0.013s\n",
      "[5/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50966, val loss: 6.62403, in 0.014s\n",
      "[6/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50943, val loss: 6.62397, in 0.015s\n",
      "[7/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50920, val loss: 6.62395, in 0.015s\n",
      "[8/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50897, val loss: 6.62388, in 0.014s\n",
      "[9/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50872, val loss: 6.62386, in 0.014s\n",
      "[10/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50848, val loss: 6.62382, in 0.014s\n",
      "[11/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50826, val loss: 6.62380, in 0.015s\n",
      "[12/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50803, val loss: 6.62376, in 0.013s\n",
      "[13/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50778, val loss: 6.62371, in 0.017s\n",
      "[14/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50757, val loss: 6.62369, in 0.015s\n",
      "[15/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50734, val loss: 6.62368, in 0.015s\n",
      "[16/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50712, val loss: 6.62365, in 0.014s\n",
      "[17/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50687, val loss: 6.62361, in 0.013s\n",
      "[18/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50667, val loss: 6.62362, in 0.015s\n",
      "[19/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50646, val loss: 6.62360, in 0.013s\n",
      "[20/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50623, val loss: 6.62357, in 0.013s\n",
      "[21/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50601, val loss: 6.62357, in 0.015s\n",
      "[22/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50580, val loss: 6.62357, in 0.013s\n",
      "[23/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50560, val loss: 6.62362, in 0.013s\n",
      "[24/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50541, val loss: 6.62363, in 0.015s\n",
      "[25/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50520, val loss: 6.62366, in 0.014s\n",
      "[26/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50502, val loss: 6.62367, in 0.013s\n",
      "Fit 26 trees in 0.804 s, (520 total leaves)\n",
      "Time spent computing histograms: 0.082s\n",
      "Time spent finding best splits:  0.023s\n",
      "Time spent applying splits:      0.073s\n",
      "Time spent predicting:           0.007s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.020 GB of training data: 0.337 s\n",
      "Binning 0.002 GB of validation data: 0.005 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43367, val loss: 6.54931, in 0.015s\n",
      "[2/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43336, val loss: 6.54929, in 0.015s\n",
      "[3/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43301, val loss: 6.54929, in 0.014s\n",
      "[4/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43270, val loss: 6.54930, in 0.013s\n",
      "[5/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43241, val loss: 6.54930, in 0.015s\n",
      "[6/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43212, val loss: 6.54930, in 0.014s\n",
      "[7/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43182, val loss: 6.54931, in 0.014s\n",
      "[8/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43154, val loss: 6.54932, in 0.013s\n",
      "Fit 8 trees in 0.546 s, (160 total leaves)\n",
      "Time spent computing histograms: 0.022s\n",
      "Time spent finding best splits:  0.007s\n",
      "Time spent applying splits:      0.021s\n",
      "Time spent predicting:           0.002s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    5.2s finished\n"
     ]
    }
   ],
   "source": [
    "scores = cross_validate(estimator = model, \n",
    "                        X = X, \n",
    "                        y = y, \n",
    "                        cv=cv,\n",
    "                        scoring=scoring,\n",
    "                        verbose = verbose,\n",
    "                        return_train_score=True)\n",
    "results[\"baseline_with_embeddings\"] = scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2812a714",
   "metadata": {},
   "source": [
    "### evaluate on baseline with id features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6c23023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = baseline_feature_names + id_feature_feature_names\n",
    "X,y = dataset[features], dataset[target_col]\n",
    "cv = 5\n",
    "scoring=('r2', 'neg_root_mean_squared_error')\n",
    "verbose = 1\n",
    "model_params = {\n",
    "    \"learning_rate\":0.01,\n",
    "    \"max_iter\":100,\n",
    "    \"categorical_features\" : X.columns.isin(categorical_feature_names),\n",
    "    \"l2_regularization\":0.005,\n",
    "    \"early_stopping\":True,\n",
    "    \"n_iter_no_change\":5,\n",
    "    \"verbose\":1,\n",
    "    \"random_state\":0,\n",
    "    \"max_depth\":5,\n",
    "    \"max_leaf_nodes\":20\n",
    "}\n",
    "model = HistGradientBoostingRegressor(**model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "50548591",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.005 GB of training data: 0.051 s\n",
      "Binning 0.001 GB of validation data: 0.001 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34852, val loss: 8.13119, in 0.013s\n",
      "[2/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34796, val loss: 8.13088, in 0.013s\n",
      "[3/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34742, val loss: 8.13058, in 0.012s\n",
      "[4/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34688, val loss: 8.13028, in 0.012s\n",
      "[5/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34636, val loss: 8.12999, in 0.012s\n",
      "[6/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34585, val loss: 8.12972, in 0.013s\n",
      "[7/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34533, val loss: 8.12945, in 0.012s\n",
      "[8/100] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tree, 20 leaves, max depth = 5, train loss: 7.34484, val loss: 8.12919, in 0.013s\n",
      "[9/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34435, val loss: 8.12893, in 0.014s\n",
      "[10/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34387, val loss: 8.12869, in 0.014s\n",
      "[11/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34341, val loss: 8.12843, in 0.014s\n",
      "[12/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34295, val loss: 8.12820, in 0.012s\n",
      "[13/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34251, val loss: 8.12796, in 0.012s\n",
      "[14/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34206, val loss: 8.12779, in 0.012s\n",
      "[15/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34159, val loss: 8.12757, in 0.013s\n",
      "[16/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34116, val loss: 8.12738, in 0.013s\n",
      "[17/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34074, val loss: 8.12719, in 0.012s\n",
      "[18/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34029, val loss: 8.12699, in 0.012s\n",
      "[19/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33989, val loss: 8.12682, in 0.012s\n",
      "[20/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33946, val loss: 8.12663, in 0.011s\n",
      "[21/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33906, val loss: 8.12647, in 0.012s\n",
      "[22/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33867, val loss: 8.12626, in 0.012s\n",
      "[23/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33828, val loss: 8.12613, in 0.012s\n",
      "[24/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33789, val loss: 8.12603, in 0.012s\n",
      "[25/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33751, val loss: 8.12585, in 0.012s\n",
      "[26/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33713, val loss: 8.12573, in 0.011s\n",
      "[27/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33677, val loss: 8.12555, in 0.014s\n",
      "[28/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33640, val loss: 8.12545, in 0.011s\n",
      "[29/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33601, val loss: 8.12528, in 0.013s\n",
      "[30/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33566, val loss: 8.12516, in 0.012s\n",
      "[31/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33532, val loss: 8.12499, in 0.013s\n",
      "[32/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33498, val loss: 8.12489, in 0.014s\n",
      "[33/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33462, val loss: 8.12473, in 0.013s\n",
      "[34/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33426, val loss: 8.12457, in 0.011s\n",
      "[35/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33394, val loss: 8.12448, in 0.014s\n",
      "[36/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33360, val loss: 8.12432, in 0.011s\n",
      "[37/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33329, val loss: 8.12422, in 0.013s\n",
      "[38/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33299, val loss: 8.12413, in 0.010s\n",
      "[39/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33264, val loss: 8.12401, in 0.012s\n",
      "[40/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33233, val loss: 8.12392, in 0.012s\n",
      "[41/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33201, val loss: 8.12380, in 0.012s\n",
      "[42/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33170, val loss: 8.12370, in 0.012s\n",
      "[43/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33139, val loss: 8.12362, in 0.011s\n",
      "[44/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33112, val loss: 8.12350, in 0.012s\n",
      "[45/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33083, val loss: 8.12338, in 0.012s\n",
      "[46/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33053, val loss: 8.12331, in 0.011s\n",
      "[47/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33026, val loss: 8.12320, in 0.012s\n",
      "[48/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32999, val loss: 8.12310, in 0.011s\n",
      "[49/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32973, val loss: 8.12295, in 0.012s\n",
      "[50/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32946, val loss: 8.12287, in 0.012s\n",
      "[51/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32919, val loss: 8.12275, in 0.012s\n",
      "[52/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32894, val loss: 8.12263, in 0.012s\n",
      "[53/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32867, val loss: 8.12252, in 0.011s\n",
      "[54/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32841, val loss: 8.12243, in 0.013s\n",
      "[55/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32816, val loss: 8.12231, in 0.012s\n",
      "[56/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32794, val loss: 8.12220, in 0.011s\n",
      "[57/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32768, val loss: 8.12216, in 0.011s\n",
      "[58/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32744, val loss: 8.12203, in 0.012s\n",
      "[59/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32722, val loss: 8.12192, in 0.013s\n",
      "[60/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32695, val loss: 8.12188, in 0.011s\n",
      "[61/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32667, val loss: 8.12184, in 0.013s\n",
      "[62/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32641, val loss: 8.12180, in 0.010s\n",
      "[63/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32619, val loss: 8.12166, in 0.012s\n",
      "[64/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32590, val loss: 8.12166, in 0.012s\n",
      "[65/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32561, val loss: 8.12164, in 0.012s\n",
      "[66/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32533, val loss: 8.12165, in 0.011s\n",
      "[67/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32513, val loss: 8.12155, in 0.011s\n",
      "[68/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32486, val loss: 8.12154, in 0.011s\n",
      "[69/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32463, val loss: 8.12154, in 0.012s\n",
      "[70/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32437, val loss: 8.12153, in 0.011s\n",
      "[71/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32417, val loss: 8.12144, in 0.014s\n",
      "[72/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32392, val loss: 8.12145, in 0.011s\n",
      "[73/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32368, val loss: 8.12144, in 0.011s\n",
      "[74/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32344, val loss: 8.12143, in 0.011s\n",
      "[75/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32324, val loss: 8.12135, in 0.014s\n",
      "[76/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32302, val loss: 8.12136, in 0.012s\n",
      "[77/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32281, val loss: 8.12137, in 0.013s\n",
      "[78/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32259, val loss: 8.12138, in 0.015s\n",
      "[79/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32240, val loss: 8.12131, in 0.012s\n",
      "[80/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32220, val loss: 8.12133, in 0.012s\n",
      "[81/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32197, val loss: 8.12134, in 0.012s\n",
      "[82/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32179, val loss: 8.12128, in 0.012s\n",
      "[83/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32159, val loss: 8.12130, in 0.012s\n",
      "[84/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32140, val loss: 8.12131, in 0.011s\n",
      "[85/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32121, val loss: 8.12133, in 0.014s\n",
      "[86/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32103, val loss: 8.12127, in 0.021s\n",
      "[87/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32082, val loss: 8.12128, in 0.014s\n",
      "[88/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32065, val loss: 8.12120, in 0.016s\n",
      "[89/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32048, val loss: 8.12117, in 0.016s\n",
      "[90/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32029, val loss: 8.12118, in 0.014s\n",
      "[91/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32012, val loss: 8.12111, in 0.016s\n",
      "[92/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31995, val loss: 8.12110, in 0.015s\n",
      "[93/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31979, val loss: 8.12105, in 0.014s\n",
      "[94/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31961, val loss: 8.12108, in 0.012s\n",
      "[95/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31944, val loss: 8.12108, in 0.012s\n",
      "[96/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31929, val loss: 8.12110, in 0.012s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31914, val loss: 8.12104, in 0.012s\n",
      "[98/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31897, val loss: 8.12102, in 0.011s\n",
      "[99/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31882, val loss: 8.12106, in 0.011s\n",
      "[100/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31865, val loss: 8.12104, in 0.013s\n",
      "Fit 100 trees in 1.336 s, (2000 total leaves)\n",
      "Time spent computing histograms: 0.171s\n",
      "Time spent finding best splits:  0.071s\n",
      "Time spent applying splits:      0.309s\n",
      "Time spent predicting:           0.032s\n",
      "Binning 0.005 GB of training data: 0.058 s\n",
      "Binning 0.001 GB of validation data: 0.001 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38679, val loss: 7.81567, in 0.013s\n",
      "[2/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38622, val loss: 7.81530, in 0.012s\n",
      "[3/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38566, val loss: 7.81494, in 0.013s\n",
      "[4/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38511, val loss: 7.81458, in 0.013s\n",
      "[5/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38457, val loss: 7.81424, in 0.015s\n",
      "[6/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38404, val loss: 7.81390, in 0.013s\n",
      "[7/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38353, val loss: 7.81357, in 0.014s\n",
      "[8/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38302, val loss: 7.81325, in 0.013s\n",
      "[9/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38253, val loss: 7.81291, in 0.015s\n",
      "[10/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38205, val loss: 7.81261, in 0.014s\n",
      "[11/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38159, val loss: 7.81229, in 0.015s\n",
      "[12/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38113, val loss: 7.81201, in 0.013s\n",
      "[13/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38067, val loss: 7.81173, in 0.016s\n",
      "[14/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38022, val loss: 7.81143, in 0.013s\n",
      "[15/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37979, val loss: 7.81116, in 0.014s\n",
      "[16/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37936, val loss: 7.81088, in 0.015s\n",
      "[17/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37895, val loss: 7.81063, in 0.016s\n",
      "[18/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37854, val loss: 7.81036, in 0.014s\n",
      "[19/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37814, val loss: 7.81012, in 0.015s\n",
      "[20/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37774, val loss: 7.80988, in 0.016s\n",
      "[21/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37736, val loss: 7.80962, in 0.014s\n",
      "[22/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37698, val loss: 7.80938, in 0.011s\n",
      "[23/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37661, val loss: 7.80914, in 0.012s\n",
      "[24/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37624, val loss: 7.80891, in 0.010s\n",
      "[25/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37586, val loss: 7.80866, in 0.012s\n",
      "[26/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37551, val loss: 7.80847, in 0.013s\n",
      "[27/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37517, val loss: 7.80824, in 0.011s\n",
      "[28/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37482, val loss: 7.80805, in 0.012s\n",
      "[29/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37448, val loss: 7.80786, in 0.011s\n",
      "[30/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37414, val loss: 7.80764, in 0.013s\n",
      "[31/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37382, val loss: 7.80745, in 0.011s\n",
      "[32/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37349, val loss: 7.80728, in 0.019s\n",
      "[33/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37315, val loss: 7.80710, in 0.016s\n",
      "[34/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37284, val loss: 7.80690, in 0.011s\n",
      "[35/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37251, val loss: 7.80673, in 0.012s\n",
      "[36/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37220, val loss: 7.80658, in 0.011s\n",
      "[37/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37188, val loss: 7.80642, in 0.011s\n",
      "[38/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37159, val loss: 7.80627, in 0.012s\n",
      "[39/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37130, val loss: 7.80611, in 0.012s\n",
      "[40/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37100, val loss: 7.80597, in 0.012s\n",
      "[41/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37071, val loss: 7.80581, in 0.011s\n",
      "[42/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37042, val loss: 7.80569, in 0.011s\n",
      "[43/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37015, val loss: 7.80558, in 0.011s\n",
      "[44/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36987, val loss: 7.80544, in 0.011s\n",
      "[45/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36960, val loss: 7.80532, in 0.012s\n",
      "[46/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36934, val loss: 7.80522, in 0.012s\n",
      "[47/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36909, val loss: 7.80507, in 0.012s\n",
      "[48/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36884, val loss: 7.80494, in 0.012s\n",
      "[49/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36858, val loss: 7.80481, in 0.012s\n",
      "[50/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36834, val loss: 7.80468, in 0.010s\n",
      "[51/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36810, val loss: 7.80452, in 0.012s\n",
      "[52/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36786, val loss: 7.80444, in 0.012s\n",
      "[53/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36763, val loss: 7.80428, in 0.011s\n",
      "[54/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36741, val loss: 7.80414, in 0.012s\n",
      "[55/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36718, val loss: 7.80401, in 0.010s\n",
      "[56/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36696, val loss: 7.80385, in 0.012s\n",
      "[57/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36674, val loss: 7.80376, in 0.012s\n",
      "[58/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36652, val loss: 7.80369, in 0.010s\n",
      "[59/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36631, val loss: 7.80363, in 0.011s\n",
      "[60/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36610, val loss: 7.80350, in 0.012s\n",
      "[61/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36589, val loss: 7.80335, in 0.011s\n",
      "[62/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36568, val loss: 7.80326, in 0.011s\n",
      "[63/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36548, val loss: 7.80312, in 0.011s\n",
      "[64/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36526, val loss: 7.80304, in 0.011s\n",
      "[65/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36507, val loss: 7.80293, in 0.011s\n",
      "[66/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36487, val loss: 7.80284, in 0.011s\n",
      "[67/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36465, val loss: 7.80277, in 0.012s\n",
      "[68/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36444, val loss: 7.80273, in 0.011s\n",
      "[69/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36426, val loss: 7.80262, in 0.011s\n",
      "[70/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36405, val loss: 7.80256, in 0.011s\n",
      "[71/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36388, val loss: 7.80246, in 0.011s\n",
      "[72/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36370, val loss: 7.80234, in 0.010s\n",
      "[73/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36351, val loss: 7.80228, in 0.011s\n",
      "[74/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36331, val loss: 7.80226, in 0.009s\n",
      "[75/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36313, val loss: 7.80220, in 0.011s\n",
      "[76/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36294, val loss: 7.80218, in 0.010s\n",
      "[77/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36277, val loss: 7.80209, in 0.010s\n",
      "[78/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36259, val loss: 7.80203, in 0.011s\n",
      "[79/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36242, val loss: 7.80196, in 0.011s\n",
      "[80/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36224, val loss: 7.80191, in 0.011s\n",
      "[81/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36206, val loss: 7.80192, in 0.011s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[82/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36190, val loss: 7.80189, in 0.010s\n",
      "[83/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36175, val loss: 7.80181, in 0.011s\n",
      "[84/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36158, val loss: 7.80180, in 0.010s\n",
      "[85/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36140, val loss: 7.80173, in 0.012s\n",
      "[86/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36125, val loss: 7.80169, in 0.010s\n",
      "[87/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36108, val loss: 7.80166, in 0.012s\n",
      "[88/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36094, val loss: 7.80162, in 0.010s\n",
      "[89/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36078, val loss: 7.80161, in 0.011s\n",
      "[90/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36063, val loss: 7.80163, in 0.010s\n",
      "[91/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36047, val loss: 7.80163, in 0.010s\n",
      "[92/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36032, val loss: 7.80158, in 0.010s\n",
      "[93/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36019, val loss: 7.80151, in 0.011s\n",
      "[94/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36004, val loss: 7.80143, in 0.010s\n",
      "[95/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35988, val loss: 7.80144, in 0.010s\n",
      "[96/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35974, val loss: 7.80145, in 0.010s\n",
      "[97/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35960, val loss: 7.80144, in 0.010s\n",
      "[98/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35945, val loss: 7.80141, in 0.010s\n",
      "[99/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35930, val loss: 7.80143, in 0.010s\n",
      "[100/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35918, val loss: 7.80143, in 0.010s\n",
      "Fit 100 trees in 1.301 s, (2000 total leaves)\n",
      "Time spent computing histograms: 0.163s\n",
      "Time spent finding best splits:  0.067s\n",
      "Time spent applying splits:      0.297s\n",
      "Time spent predicting:           0.029s\n",
      "Binning 0.005 GB of training data: 0.059 s\n",
      "Binning 0.001 GB of validation data: 0.001 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.46180, val loss: 7.24215, in 0.010s\n",
      "[2/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.46116, val loss: 7.24174, in 0.011s\n",
      "[3/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.46053, val loss: 7.24134, in 0.011s\n",
      "[4/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45992, val loss: 7.24095, in 0.011s\n",
      "[5/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45930, val loss: 7.24054, in 0.010s\n",
      "[6/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45871, val loss: 7.24017, in 0.010s\n",
      "[7/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45811, val loss: 7.23978, in 0.010s\n",
      "[8/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45752, val loss: 7.23939, in 0.011s\n",
      "[9/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45697, val loss: 7.23903, in 0.011s\n",
      "[10/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45641, val loss: 7.23871, in 0.010s\n",
      "[11/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45584, val loss: 7.23830, in 0.012s\n",
      "[12/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45532, val loss: 7.23797, in 0.011s\n",
      "[13/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45477, val loss: 7.23761, in 0.012s\n",
      "[14/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45422, val loss: 7.23720, in 0.012s\n",
      "[15/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45372, val loss: 7.23689, in 0.013s\n",
      "[16/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45320, val loss: 7.23657, in 0.014s\n",
      "[17/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45270, val loss: 7.23628, in 0.011s\n",
      "[18/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45221, val loss: 7.23598, in 0.013s\n",
      "[19/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45176, val loss: 7.23576, in 0.013s\n",
      "[20/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45132, val loss: 7.23557, in 0.015s\n",
      "[21/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45085, val loss: 7.23525, in 0.015s\n",
      "[22/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45043, val loss: 7.23506, in 0.015s\n",
      "[23/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45001, val loss: 7.23488, in 0.017s\n",
      "[24/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44956, val loss: 7.23457, in 0.013s\n",
      "[25/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44916, val loss: 7.23441, in 0.015s\n",
      "[26/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44877, val loss: 7.23425, in 0.017s\n",
      "[27/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44835, val loss: 7.23403, in 0.017s\n",
      "[28/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44797, val loss: 7.23388, in 0.015s\n",
      "[29/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44755, val loss: 7.23359, in 0.029s\n",
      "[30/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44719, val loss: 7.23343, in 0.019s\n",
      "[31/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44677, val loss: 7.23310, in 0.027s\n",
      "[32/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44642, val loss: 7.23295, in 0.017s\n",
      "[33/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44603, val loss: 7.23268, in 0.016s\n",
      "[34/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44564, val loss: 7.23247, in 0.017s\n",
      "[35/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44526, val loss: 7.23221, in 0.017s\n",
      "[36/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44490, val loss: 7.23202, in 0.017s\n",
      "[37/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44453, val loss: 7.23174, in 0.015s\n",
      "[38/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44415, val loss: 7.23152, in 0.016s\n",
      "[39/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44380, val loss: 7.23126, in 0.015s\n",
      "[40/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44347, val loss: 7.23110, in 0.012s\n",
      "[41/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44313, val loss: 7.23086, in 0.013s\n",
      "[42/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44279, val loss: 7.23061, in 0.011s\n",
      "[43/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44248, val loss: 7.23053, in 0.011s\n",
      "[44/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44220, val loss: 7.23041, in 0.010s\n",
      "[45/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44187, val loss: 7.23019, in 0.012s\n",
      "[46/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44156, val loss: 7.23000, in 0.010s\n",
      "[47/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44129, val loss: 7.22989, in 0.012s\n",
      "[48/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44099, val loss: 7.22968, in 0.010s\n",
      "[49/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44071, val loss: 7.22962, in 0.011s\n",
      "[50/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44044, val loss: 7.22950, in 0.011s\n",
      "[51/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44017, val loss: 7.22936, in 0.011s\n",
      "[52/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43984, val loss: 7.22932, in 0.010s\n",
      "[53/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43959, val loss: 7.22921, in 0.011s\n",
      "[54/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43928, val loss: 7.22916, in 0.010s\n",
      "[55/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43904, val loss: 7.22906, in 0.010s\n",
      "[56/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43879, val loss: 7.22899, in 0.011s\n",
      "[57/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43855, val loss: 7.22887, in 0.012s\n",
      "[58/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43825, val loss: 7.22882, in 0.010s\n",
      "[59/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43803, val loss: 7.22872, in 0.011s\n",
      "[60/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43779, val loss: 7.22860, in 0.011s\n",
      "[61/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43751, val loss: 7.22857, in 0.011s\n",
      "[62/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43729, val loss: 7.22849, in 0.011s\n",
      "[63/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43706, val loss: 7.22839, in 0.013s\n",
      "[64/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43679, val loss: 7.22829, in 0.013s\n",
      "[65/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43657, val loss: 7.22823, in 0.014s\n",
      "[66/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43633, val loss: 7.22814, in 0.015s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43609, val loss: 7.22811, in 0.015s\n",
      "[68/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43585, val loss: 7.22798, in 0.013s\n",
      "[69/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43559, val loss: 7.22789, in 0.014s\n",
      "[70/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43538, val loss: 7.22790, in 0.014s\n",
      "[71/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43518, val loss: 7.22782, in 0.012s\n",
      "[72/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43494, val loss: 7.22776, in 0.012s\n",
      "[73/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43474, val loss: 7.22774, in 0.014s\n",
      "[74/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43454, val loss: 7.22776, in 0.011s\n",
      "[75/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43432, val loss: 7.22774, in 0.010s\n",
      "[76/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43414, val loss: 7.22768, in 0.011s\n",
      "[77/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43391, val loss: 7.22763, in 0.011s\n",
      "[78/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43372, val loss: 7.22766, in 0.010s\n",
      "[79/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43354, val loss: 7.22765, in 0.012s\n",
      "[80/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43334, val loss: 7.22766, in 0.011s\n",
      "[81/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43316, val loss: 7.22764, in 0.011s\n",
      "[82/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43299, val loss: 7.22763, in 0.011s\n",
      "Fit 82 trees in 1.176 s, (1640 total leaves)\n",
      "Time spent computing histograms: 0.138s\n",
      "Time spent finding best splits:  0.054s\n",
      "Time spent applying splits:      0.273s\n",
      "Time spent predicting:           0.026s\n",
      "Binning 0.005 GB of training data: 0.058 s\n",
      "Binning 0.001 GB of validation data: 0.001 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.51034, val loss: 6.62386, in 0.010s\n",
      "[2/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50977, val loss: 6.62350, in 0.012s\n",
      "[3/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50921, val loss: 6.62316, in 0.012s\n",
      "[4/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50867, val loss: 6.62283, in 0.011s\n",
      "[5/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50813, val loss: 6.62249, in 0.013s\n",
      "[6/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50762, val loss: 6.62217, in 0.012s\n",
      "[7/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50711, val loss: 6.62192, in 0.013s\n",
      "[8/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50661, val loss: 6.62165, in 0.011s\n",
      "[9/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50613, val loss: 6.62137, in 0.011s\n",
      "[10/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50564, val loss: 6.62108, in 0.011s\n",
      "[11/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50518, val loss: 6.62085, in 0.011s\n",
      "[12/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50472, val loss: 6.62060, in 0.012s\n",
      "[13/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50426, val loss: 6.62034, in 0.010s\n",
      "[14/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50382, val loss: 6.62010, in 0.011s\n",
      "[15/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50338, val loss: 6.61984, in 0.012s\n",
      "[16/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50295, val loss: 6.61962, in 0.011s\n",
      "[17/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50253, val loss: 6.61939, in 0.011s\n",
      "[18/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50212, val loss: 6.61921, in 0.013s\n",
      "[19/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50171, val loss: 6.61898, in 0.013s\n",
      "[20/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50131, val loss: 6.61876, in 0.012s\n",
      "[21/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50093, val loss: 6.61855, in 0.012s\n",
      "[22/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50055, val loss: 6.61835, in 0.010s\n",
      "[23/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50016, val loss: 6.61815, in 0.011s\n",
      "[24/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49980, val loss: 6.61794, in 0.012s\n",
      "[25/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49942, val loss: 6.61774, in 0.010s\n",
      "[26/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49907, val loss: 6.61754, in 0.011s\n",
      "[27/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49871, val loss: 6.61737, in 0.012s\n",
      "[28/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49835, val loss: 6.61719, in 0.011s\n",
      "[29/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49801, val loss: 6.61703, in 0.011s\n",
      "[30/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49765, val loss: 6.61683, in 0.011s\n",
      "[31/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49730, val loss: 6.61662, in 0.011s\n",
      "[32/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49697, val loss: 6.61645, in 0.011s\n",
      "[33/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49663, val loss: 6.61628, in 0.012s\n",
      "[34/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49632, val loss: 6.61613, in 0.011s\n",
      "[35/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49599, val loss: 6.61596, in 0.012s\n",
      "[36/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49566, val loss: 6.61579, in 0.011s\n",
      "[37/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49533, val loss: 6.61554, in 0.011s\n",
      "[38/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49504, val loss: 6.61546, in 0.012s\n",
      "[39/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49471, val loss: 6.61529, in 0.012s\n",
      "[40/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49443, val loss: 6.61521, in 0.012s\n",
      "[41/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49412, val loss: 6.61506, in 0.012s\n",
      "[42/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49385, val loss: 6.61500, in 0.012s\n",
      "[43/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49354, val loss: 6.61482, in 0.013s\n",
      "[44/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49328, val loss: 6.61475, in 0.012s\n",
      "[45/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49298, val loss: 6.61457, in 0.011s\n",
      "[46/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49273, val loss: 6.61452, in 0.012s\n",
      "[47/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49245, val loss: 6.61440, in 0.013s\n",
      "[48/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49220, val loss: 6.61434, in 0.011s\n",
      "[49/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49194, val loss: 6.61430, in 0.012s\n",
      "[50/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49169, val loss: 6.61426, in 0.011s\n",
      "[51/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49144, val loss: 6.61418, in 0.013s\n",
      "[52/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49119, val loss: 6.61414, in 0.011s\n",
      "[53/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49095, val loss: 6.61408, in 0.011s\n",
      "[54/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49071, val loss: 6.61405, in 0.011s\n",
      "[55/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49048, val loss: 6.61396, in 0.011s\n",
      "[56/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49023, val loss: 6.61383, in 0.011s\n",
      "[57/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49000, val loss: 6.61379, in 0.013s\n",
      "[58/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48979, val loss: 6.61375, in 0.012s\n",
      "[59/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48956, val loss: 6.61372, in 0.011s\n",
      "[60/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48935, val loss: 6.61368, in 0.012s\n",
      "[61/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48911, val loss: 6.61354, in 0.012s\n",
      "[62/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48890, val loss: 6.61350, in 0.011s\n",
      "[63/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48869, val loss: 6.61349, in 0.011s\n",
      "[64/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48849, val loss: 6.61343, in 0.011s\n",
      "[65/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48830, val loss: 6.61339, in 0.011s\n",
      "[66/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48808, val loss: 6.61326, in 0.012s\n",
      "[67/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48789, val loss: 6.61326, in 0.011s\n",
      "[68/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48767, val loss: 6.61314, in 0.010s\n",
      "[69/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48749, val loss: 6.61313, in 0.011s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48728, val loss: 6.61311, in 0.012s\n",
      "[71/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48704, val loss: 6.61301, in 0.012s\n",
      "[72/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48685, val loss: 6.61294, in 0.011s\n",
      "[73/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48666, val loss: 6.61291, in 0.012s\n",
      "[74/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48646, val loss: 6.61279, in 0.011s\n",
      "[75/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48629, val loss: 6.61277, in 0.012s\n",
      "[76/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48610, val loss: 6.61278, in 0.011s\n",
      "[77/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48587, val loss: 6.61268, in 0.012s\n",
      "[78/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48569, val loss: 6.61263, in 0.012s\n",
      "[79/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48553, val loss: 6.61261, in 0.011s\n",
      "[80/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48531, val loss: 6.61254, in 0.011s\n",
      "[81/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48513, val loss: 6.61244, in 0.011s\n",
      "[82/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48497, val loss: 6.61244, in 0.011s\n",
      "[83/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48478, val loss: 6.61238, in 0.011s\n",
      "[84/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48462, val loss: 6.61239, in 0.012s\n",
      "[85/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48444, val loss: 6.61237, in 0.012s\n",
      "[86/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48426, val loss: 6.61230, in 0.012s\n",
      "[87/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48406, val loss: 6.61225, in 0.011s\n",
      "[88/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48391, val loss: 6.61226, in 0.011s\n",
      "[89/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48373, val loss: 6.61220, in 0.011s\n",
      "[90/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48357, val loss: 6.61218, in 0.010s\n",
      "[91/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48340, val loss: 6.61222, in 0.011s\n",
      "[92/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48323, val loss: 6.61218, in 0.011s\n",
      "[93/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48307, val loss: 6.61218, in 0.012s\n",
      "[94/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48291, val loss: 6.61217, in 0.011s\n",
      "[95/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48275, val loss: 6.61218, in 0.010s\n",
      "[96/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48259, val loss: 6.61215, in 0.011s\n",
      "[97/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48244, val loss: 6.61216, in 0.013s\n",
      "[98/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48229, val loss: 6.61210, in 0.012s\n",
      "[99/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48214, val loss: 6.61205, in 0.012s\n",
      "[100/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48199, val loss: 6.61201, in 0.011s\n",
      "Fit 100 trees in 1.265 s, (2000 total leaves)\n",
      "Time spent computing histograms: 0.158s\n",
      "Time spent finding best splits:  0.063s\n",
      "Time spent applying splits:      0.288s\n",
      "Time spent predicting:           0.029s\n",
      "Binning 0.005 GB of training data: 0.059 s\n",
      "Binning 0.001 GB of validation data: 0.001 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43347, val loss: 6.54896, in 0.011s\n",
      "[2/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43297, val loss: 6.54859, in 0.011s\n",
      "[3/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43248, val loss: 6.54821, in 0.011s\n",
      "[4/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43197, val loss: 6.54792, in 0.010s\n",
      "[5/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43150, val loss: 6.54756, in 0.011s\n",
      "[6/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43101, val loss: 6.54727, in 0.011s\n",
      "[7/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43055, val loss: 6.54695, in 0.011s\n",
      "[8/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43010, val loss: 6.54665, in 0.011s\n",
      "[9/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42963, val loss: 6.54633, in 0.011s\n",
      "[10/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42920, val loss: 6.54603, in 0.010s\n",
      "[11/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42874, val loss: 6.54569, in 0.013s\n",
      "[12/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42833, val loss: 6.54540, in 0.011s\n",
      "[13/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42789, val loss: 6.54509, in 0.011s\n",
      "[14/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42749, val loss: 6.54481, in 0.011s\n",
      "[15/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42709, val loss: 6.54455, in 0.010s\n",
      "[16/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42667, val loss: 6.54424, in 0.012s\n",
      "[17/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42629, val loss: 6.54396, in 0.012s\n",
      "[18/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42589, val loss: 6.54366, in 0.011s\n",
      "[19/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42549, val loss: 6.54339, in 0.012s\n",
      "[20/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42510, val loss: 6.54314, in 0.011s\n",
      "[21/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42471, val loss: 6.54286, in 0.012s\n",
      "[22/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42434, val loss: 6.54261, in 0.012s\n",
      "[23/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42397, val loss: 6.54237, in 0.010s\n",
      "[24/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42361, val loss: 6.54217, in 0.011s\n",
      "[25/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42325, val loss: 6.54192, in 0.012s\n",
      "[26/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42290, val loss: 6.54173, in 0.010s\n",
      "[27/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42256, val loss: 6.54150, in 0.012s\n",
      "[28/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42222, val loss: 6.54127, in 0.011s\n",
      "[29/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42189, val loss: 6.54109, in 0.021s\n",
      "[30/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42156, val loss: 6.54088, in 0.012s\n",
      "[31/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42122, val loss: 6.54066, in 0.012s\n",
      "[32/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42091, val loss: 6.54047, in 0.012s\n",
      "[33/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42060, val loss: 6.54027, in 0.011s\n",
      "[34/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42028, val loss: 6.54005, in 0.011s\n",
      "[35/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41998, val loss: 6.53987, in 0.011s\n",
      "[36/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41968, val loss: 6.53966, in 0.011s\n",
      "[37/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41933, val loss: 6.53952, in 0.011s\n",
      "[38/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41902, val loss: 6.53940, in 0.012s\n",
      "[39/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41873, val loss: 6.53922, in 0.011s\n",
      "[40/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41840, val loss: 6.53909, in 0.012s\n",
      "[41/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41812, val loss: 6.53892, in 0.011s\n",
      "[42/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41782, val loss: 6.53879, in 0.011s\n",
      "[43/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41751, val loss: 6.53864, in 0.011s\n",
      "[44/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41724, val loss: 6.53848, in 0.012s\n",
      "[45/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41697, val loss: 6.53836, in 0.011s\n",
      "[46/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41671, val loss: 6.53821, in 0.011s\n",
      "[47/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41642, val loss: 6.53810, in 0.010s\n",
      "[48/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41615, val loss: 6.53798, in 0.011s\n",
      "[49/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41590, val loss: 6.53787, in 0.012s\n",
      "[50/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41562, val loss: 6.53777, in 0.011s\n",
      "[51/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41537, val loss: 6.53769, in 0.012s\n",
      "[52/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41513, val loss: 6.53762, in 0.010s\n",
      "[53/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41490, val loss: 6.53748, in 0.012s\n",
      "[54/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41464, val loss: 6.53739, in 0.011s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41441, val loss: 6.53727, in 0.011s\n",
      "[56/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41419, val loss: 6.53724, in 0.010s\n",
      "[57/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41396, val loss: 6.53713, in 0.011s\n",
      "[58/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41374, val loss: 6.53709, in 0.011s\n",
      "[59/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41352, val loss: 6.53707, in 0.012s\n",
      "[60/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41331, val loss: 6.53699, in 0.011s\n",
      "[61/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41309, val loss: 6.53689, in 0.011s\n",
      "[62/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41288, val loss: 6.53675, in 0.010s\n",
      "[63/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41268, val loss: 6.53673, in 0.012s\n",
      "[64/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41244, val loss: 6.53664, in 0.011s\n",
      "[65/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41223, val loss: 6.53658, in 0.010s\n",
      "[66/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41202, val loss: 6.53649, in 0.011s\n",
      "[67/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41183, val loss: 6.53649, in 0.012s\n",
      "[68/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41163, val loss: 6.53641, in 0.011s\n",
      "[69/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41143, val loss: 6.53636, in 0.011s\n",
      "[70/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41122, val loss: 6.53631, in 0.010s\n",
      "[71/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41104, val loss: 6.53631, in 0.011s\n",
      "[72/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41086, val loss: 6.53627, in 0.012s\n",
      "[73/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41069, val loss: 6.53626, in 0.011s\n",
      "[74/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41051, val loss: 6.53620, in 0.010s\n",
      "[75/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41033, val loss: 6.53616, in 0.012s\n",
      "[76/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41015, val loss: 6.53608, in 0.011s\n",
      "[77/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40998, val loss: 6.53601, in 0.010s\n",
      "[78/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40978, val loss: 6.53599, in 0.011s\n",
      "[79/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40961, val loss: 6.53599, in 0.011s\n",
      "[80/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40944, val loss: 6.53597, in 0.010s\n",
      "[81/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40927, val loss: 6.53593, in 0.011s\n",
      "[82/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40912, val loss: 6.53593, in 0.012s\n",
      "[83/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40896, val loss: 6.53593, in 0.011s\n",
      "[84/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40880, val loss: 6.53591, in 0.011s\n",
      "[85/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40865, val loss: 6.53590, in 0.011s\n",
      "[86/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40847, val loss: 6.53587, in 0.010s\n",
      "[87/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40833, val loss: 6.53589, in 0.012s\n",
      "[88/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40816, val loss: 6.53585, in 0.010s\n",
      "[89/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40800, val loss: 6.53583, in 0.012s\n",
      "[90/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40786, val loss: 6.53579, in 0.011s\n",
      "[91/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40768, val loss: 6.53580, in 0.010s\n",
      "[92/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40755, val loss: 6.53580, in 0.011s\n",
      "[93/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40741, val loss: 6.53581, in 0.012s\n",
      "[94/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40725, val loss: 6.53581, in 0.010s\n",
      "[95/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40708, val loss: 6.53580, in 0.011s\n",
      "Fit 95 trees in 1.182 s, (1900 total leaves)\n",
      "Time spent computing histograms: 0.144s\n",
      "Time spent finding best splits:  0.058s\n",
      "Time spent applying splits:      0.260s\n",
      "Time spent predicting:           0.026s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    8.2s finished\n"
     ]
    }
   ],
   "source": [
    "scores = cross_validate(estimator = model, \n",
    "                        X = X, \n",
    "                        y = y, \n",
    "                        cv=cv,\n",
    "                        scoring=scoring,\n",
    "                        verbose = verbose,\n",
    "                        return_train_score=True)\n",
    "results[\"baseline_with_id_features\"] = scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2208cb41",
   "metadata": {},
   "source": [
    "### evaluate on baseline with embeddings and id features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c2cfd9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = baseline_feature_names + embedding_feature_names + id_feature_feature_names\n",
    "X,y = dataset[features], dataset[target_col]\n",
    "cv = 5\n",
    "scoring=('r2', 'neg_root_mean_squared_error')\n",
    "verbose = 1\n",
    "model_params = {\n",
    "    \"learning_rate\":0.01,\n",
    "    \"max_iter\":100,\n",
    "    \"categorical_features\" : X.columns.isin(categorical_feature_names),\n",
    "    \"l2_regularization\":0.005,\n",
    "    \"early_stopping\":True,\n",
    "    \"n_iter_no_change\":5,\n",
    "    \"verbose\":1,\n",
    "    \"random_state\":0,\n",
    "    \"max_depth\":5,\n",
    "    \"max_leaf_nodes\":20\n",
    "}\n",
    "model = HistGradientBoostingRegressor(**model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ae5153b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.023 GB of training data: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.411 s\n",
      "Binning 0.003 GB of validation data: 0.006 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34839, val loss: 8.13123, in 0.018s\n",
      "[2/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34771, val loss: 8.13098, in 0.017s\n",
      "[3/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34705, val loss: 8.13074, in 0.016s\n",
      "[4/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34638, val loss: 8.13046, in 0.017s\n",
      "[5/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34575, val loss: 8.13024, in 0.017s\n",
      "[6/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34511, val loss: 8.12997, in 0.016s\n",
      "[7/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34449, val loss: 8.12974, in 0.017s\n",
      "[8/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34389, val loss: 8.12951, in 0.016s\n",
      "[9/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34330, val loss: 8.12928, in 0.018s\n",
      "[10/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34270, val loss: 8.12905, in 0.017s\n",
      "[11/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34213, val loss: 8.12883, in 0.018s\n",
      "[12/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34156, val loss: 8.12857, in 0.017s\n",
      "[13/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34100, val loss: 8.12836, in 0.018s\n",
      "[14/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34046, val loss: 8.12817, in 0.014s\n",
      "[15/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33991, val loss: 8.12792, in 0.017s\n",
      "[16/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33938, val loss: 8.12776, in 0.016s\n",
      "[17/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33885, val loss: 8.12754, in 0.016s\n",
      "[18/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33833, val loss: 8.12731, in 0.017s\n",
      "[19/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33783, val loss: 8.12714, in 0.019s\n",
      "[20/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33733, val loss: 8.12699, in 0.019s\n",
      "[21/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33683, val loss: 8.12675, in 0.018s\n",
      "[22/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33634, val loss: 8.12652, in 0.017s\n",
      "[23/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33587, val loss: 8.12641, in 0.019s\n",
      "[24/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33538, val loss: 8.12626, in 0.017s\n",
      "[25/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33492, val loss: 8.12608, in 0.016s\n",
      "[26/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33444, val loss: 8.12594, in 0.015s\n",
      "[27/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33399, val loss: 8.12576, in 0.016s\n",
      "[28/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33355, val loss: 8.12567, in 0.017s\n",
      "[29/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33312, val loss: 8.12556, in 0.020s\n",
      "[30/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33269, val loss: 8.12541, in 0.020s\n",
      "[31/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33226, val loss: 8.12525, in 0.020s\n",
      "[32/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33184, val loss: 8.12518, in 0.015s\n",
      "[33/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33143, val loss: 8.12508, in 0.018s\n",
      "[34/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33103, val loss: 8.12500, in 0.017s\n",
      "[35/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33062, val loss: 8.12491, in 0.016s\n",
      "[36/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.33022, val loss: 8.12483, in 0.017s\n",
      "[37/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32985, val loss: 8.12475, in 0.029s\n",
      "[38/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32946, val loss: 8.12465, in 0.017s\n",
      "[39/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32907, val loss: 8.12456, in 0.019s\n",
      "[40/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32870, val loss: 8.12445, in 0.017s\n",
      "[41/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32829, val loss: 8.12435, in 0.021s\n",
      "[42/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32793, val loss: 8.12426, in 0.017s\n",
      "[43/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32755, val loss: 8.12414, in 0.018s\n",
      "[44/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32718, val loss: 8.12404, in 0.016s\n",
      "[45/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32679, val loss: 8.12395, in 0.017s\n",
      "[46/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32645, val loss: 8.12391, in 0.018s\n",
      "[47/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32610, val loss: 8.12378, in 0.016s\n",
      "[48/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32573, val loss: 8.12373, in 0.015s\n",
      "[49/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32537, val loss: 8.12365, in 0.018s\n",
      "[50/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32501, val loss: 8.12352, in 0.016s\n",
      "[51/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32465, val loss: 8.12350, in 0.015s\n",
      "[52/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32430, val loss: 8.12339, in 0.017s\n",
      "[53/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32395, val loss: 8.12333, in 0.016s\n",
      "[54/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32363, val loss: 8.12319, in 0.018s\n",
      "[55/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32327, val loss: 8.12307, in 0.017s\n",
      "[56/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32290, val loss: 8.12301, in 0.017s\n",
      "[57/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32255, val loss: 8.12292, in 0.016s\n",
      "[58/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32222, val loss: 8.12283, in 0.015s\n",
      "[59/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32191, val loss: 8.12276, in 0.016s\n",
      "[60/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32160, val loss: 8.12267, in 0.018s\n",
      "[61/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32128, val loss: 8.12259, in 0.015s\n",
      "[62/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32095, val loss: 8.12252, in 0.016s\n",
      "[63/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32064, val loss: 8.12246, in 0.016s\n",
      "[64/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32034, val loss: 8.12241, in 0.015s\n",
      "[65/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.32002, val loss: 8.12234, in 0.017s\n",
      "[66/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31971, val loss: 8.12226, in 0.015s\n",
      "[67/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31940, val loss: 8.12217, in 0.015s\n",
      "[68/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31910, val loss: 8.12209, in 0.014s\n",
      "[69/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31879, val loss: 8.12197, in 0.015s\n",
      "[70/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31851, val loss: 8.12191, in 0.016s\n",
      "[71/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31819, val loss: 8.12189, in 0.017s\n",
      "[72/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31784, val loss: 8.12178, in 0.016s\n",
      "[73/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31756, val loss: 8.12174, in 0.019s\n",
      "[74/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31722, val loss: 8.12163, in 0.018s\n",
      "[75/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31689, val loss: 8.12153, in 0.019s\n",
      "[76/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31657, val loss: 8.12143, in 0.018s\n",
      "[77/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31627, val loss: 8.12144, in 0.019s\n",
      "[78/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31595, val loss: 8.12135, in 0.018s\n",
      "[79/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31565, val loss: 8.12125, in 0.020s\n",
      "[80/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31538, val loss: 8.12115, in 0.021s\n",
      "[81/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31511, val loss: 8.12113, in 0.019s\n",
      "[82/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31481, val loss: 8.12102, in 0.018s\n",
      "[83/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31451, val loss: 8.12092, in 0.020s\n",
      "[84/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31424, val loss: 8.12087, in 0.020s\n",
      "[85/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31394, val loss: 8.12079, in 0.019s\n",
      "[86/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31366, val loss: 8.12070, in 0.019s\n",
      "[87/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31332, val loss: 8.12076, in 0.022s\n",
      "[88/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31303, val loss: 8.12073, in 0.019s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[89/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31275, val loss: 8.12070, in 0.020s\n",
      "[90/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31244, val loss: 8.12065, in 0.017s\n",
      "[91/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31213, val loss: 8.12063, in 0.019s\n",
      "[92/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31184, val loss: 8.12065, in 0.019s\n",
      "[93/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31156, val loss: 8.12063, in 0.015s\n",
      "[94/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31124, val loss: 8.12066, in 0.015s\n",
      "[95/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31101, val loss: 8.12060, in 0.016s\n",
      "[96/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31076, val loss: 8.12059, in 0.014s\n",
      "[97/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31049, val loss: 8.12059, in 0.014s\n",
      "[98/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.31020, val loss: 8.12057, in 0.014s\n",
      "[99/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.30995, val loss: 8.12058, in 0.016s\n",
      "[100/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.30964, val loss: 8.12050, in 0.014s\n",
      "Fit 100 trees in 2.233 s, (2000 total leaves)\n",
      "Time spent computing histograms: 0.400s\n",
      "Time spent finding best splits:  0.119s\n",
      "Time spent applying splits:      0.323s\n",
      "Time spent predicting:           0.043s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.023 GB of training data: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.414 s\n",
      "Binning 0.003 GB of validation data: 0.006 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38666, val loss: 7.81572, in 0.015s\n",
      "[2/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38596, val loss: 7.81540, in 0.014s\n",
      "[3/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38528, val loss: 7.81511, in 0.016s\n",
      "[4/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38461, val loss: 7.81482, in 0.015s\n",
      "[5/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38395, val loss: 7.81458, in 0.015s\n",
      "[6/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38330, val loss: 7.81431, in 0.015s\n",
      "[7/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38267, val loss: 7.81403, in 0.017s\n",
      "[8/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38204, val loss: 7.81378, in 0.015s\n",
      "[9/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38143, val loss: 7.81354, in 0.020s\n",
      "[10/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38082, val loss: 7.81330, in 0.019s\n",
      "[11/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38023, val loss: 7.81306, in 0.022s\n",
      "[12/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37965, val loss: 7.81289, in 0.020s\n",
      "[13/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37906, val loss: 7.81272, in 0.023s\n",
      "[14/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37847, val loss: 7.81246, in 0.025s\n",
      "[15/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37789, val loss: 7.81222, in 0.022s\n",
      "[16/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37732, val loss: 7.81197, in 0.022s\n",
      "[17/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37677, val loss: 7.81175, in 0.021s\n",
      "[18/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37622, val loss: 7.81152, in 0.022s\n",
      "[19/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37568, val loss: 7.81130, in 0.026s\n",
      "[20/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37514, val loss: 7.81115, in 0.023s\n",
      "[21/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37462, val loss: 7.81090, in 0.025s\n",
      "[22/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37411, val loss: 7.81069, in 0.022s\n",
      "[23/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37360, val loss: 7.81050, in 0.022s\n",
      "[24/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37310, val loss: 7.81031, in 0.019s\n",
      "[25/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37259, val loss: 7.81014, in 0.016s\n",
      "[26/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37213, val loss: 7.80997, in 0.016s\n",
      "[27/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37166, val loss: 7.80979, in 0.016s\n",
      "[28/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37118, val loss: 7.80958, in 0.015s\n",
      "[29/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37070, val loss: 7.80946, in 0.014s\n",
      "[30/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.37025, val loss: 7.80929, in 0.013s\n",
      "[31/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36981, val loss: 7.80919, in 0.017s\n",
      "[32/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36936, val loss: 7.80902, in 0.015s\n",
      "[33/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36889, val loss: 7.80888, in 0.014s\n",
      "[34/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36841, val loss: 7.80873, in 0.014s\n",
      "[35/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36800, val loss: 7.80861, in 0.015s\n",
      "[36/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36758, val loss: 7.80845, in 0.016s\n",
      "[37/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36715, val loss: 7.80831, in 0.014s\n",
      "[38/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36674, val loss: 7.80822, in 0.014s\n",
      "[39/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36632, val loss: 7.80815, in 0.015s\n",
      "[40/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36588, val loss: 7.80804, in 0.015s\n",
      "[41/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36548, val loss: 7.80799, in 0.015s\n",
      "[42/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36507, val loss: 7.80786, in 0.015s\n",
      "[43/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36470, val loss: 7.80778, in 0.015s\n",
      "[44/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36427, val loss: 7.80759, in 0.015s\n",
      "[45/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36387, val loss: 7.80749, in 0.015s\n",
      "[46/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36347, val loss: 7.80743, in 0.015s\n",
      "[47/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36306, val loss: 7.80733, in 0.015s\n",
      "[48/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36269, val loss: 7.80728, in 0.014s\n",
      "[49/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36230, val loss: 7.80717, in 0.015s\n",
      "[50/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36192, val loss: 7.80703, in 0.015s\n",
      "[51/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36152, val loss: 7.80692, in 0.015s\n",
      "[52/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36113, val loss: 7.80686, in 0.015s\n",
      "[53/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36076, val loss: 7.80671, in 0.020s\n",
      "[54/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36041, val loss: 7.80662, in 0.018s\n",
      "[55/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.36004, val loss: 7.80655, in 0.017s\n",
      "[56/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35966, val loss: 7.80644, in 0.016s\n",
      "[57/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35932, val loss: 7.80637, in 0.015s\n",
      "[58/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35900, val loss: 7.80622, in 0.017s\n",
      "[59/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35868, val loss: 7.80614, in 0.017s\n",
      "[60/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35838, val loss: 7.80606, in 0.018s\n",
      "[61/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35805, val loss: 7.80605, in 0.016s\n",
      "[62/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35768, val loss: 7.80594, in 0.015s\n",
      "[63/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35736, val loss: 7.80585, in 0.017s\n",
      "[64/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35704, val loss: 7.80586, in 0.018s\n",
      "[65/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35674, val loss: 7.80576, in 0.020s\n",
      "[66/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35644, val loss: 7.80577, in 0.019s\n",
      "[67/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35614, val loss: 7.80572, in 0.019s\n",
      "[68/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35586, val loss: 7.80566, in 0.018s\n",
      "[69/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35556, val loss: 7.80557, in 0.019s\n",
      "[70/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35526, val loss: 7.80558, in 0.016s\n",
      "[71/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35499, val loss: 7.80552, in 0.018s\n",
      "[72/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35470, val loss: 7.80550, in 0.018s\n",
      "[73/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35443, val loss: 7.80546, in 0.019s\n",
      "[74/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35414, val loss: 7.80534, in 0.016s\n",
      "[75/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35384, val loss: 7.80532, in 0.015s\n",
      "[76/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35356, val loss: 7.80529, in 0.019s\n",
      "[77/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35332, val loss: 7.80521, in 0.017s\n",
      "[78/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35304, val loss: 7.80517, in 0.015s\n",
      "[79/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35272, val loss: 7.80519, in 0.015s\n",
      "[80/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35247, val loss: 7.80515, in 0.015s\n",
      "[81/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35216, val loss: 7.80508, in 0.016s\n",
      "[82/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35186, val loss: 7.80509, in 0.015s\n",
      "[83/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35156, val loss: 7.80506, in 0.021s\n",
      "[84/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35125, val loss: 7.80501, in 0.022s\n",
      "[85/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35097, val loss: 7.80494, in 0.020s\n",
      "[86/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35071, val loss: 7.80493, in 0.016s\n",
      "[87/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35043, val loss: 7.80493, in 0.019s\n",
      "[88/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.35021, val loss: 7.80490, in 0.015s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[89/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34990, val loss: 7.80496, in 0.019s\n",
      "[90/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34964, val loss: 7.80493, in 0.014s\n",
      "[91/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34935, val loss: 7.80483, in 0.015s\n",
      "[92/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34910, val loss: 7.80483, in 0.014s\n",
      "[93/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34882, val loss: 7.80475, in 0.014s\n",
      "[94/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34858, val loss: 7.80474, in 0.014s\n",
      "[95/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34826, val loss: 7.80459, in 0.013s\n",
      "[96/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34803, val loss: 7.80460, in 0.014s\n",
      "[97/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34773, val loss: 7.80459, in 0.014s\n",
      "[98/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34742, val loss: 7.80439, in 0.014s\n",
      "[99/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34711, val loss: 7.80432, in 0.014s\n",
      "[100/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34686, val loss: 7.80433, in 0.013s\n",
      "Fit 100 trees in 2.222 s, (2000 total leaves)\n",
      "Time spent computing histograms: 0.415s\n",
      "Time spent finding best splits:  0.115s\n",
      "Time spent applying splits:      0.323s\n",
      "Time spent predicting:           0.030s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.023 GB of training data: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.444 s\n",
      "Binning 0.003 GB of validation data: 0.005 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.46174, val loss: 7.24222, in 0.017s\n",
      "[2/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.46105, val loss: 7.24191, in 0.017s\n",
      "[3/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.46036, val loss: 7.24161, in 0.015s\n",
      "[4/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45968, val loss: 7.24132, in 0.015s\n",
      "[5/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45902, val loss: 7.24103, in 0.015s\n",
      "[6/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45836, val loss: 7.24076, in 0.015s\n",
      "[7/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45769, val loss: 7.24051, in 0.014s\n",
      "[8/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45706, val loss: 7.24024, in 0.015s\n",
      "[9/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45643, val loss: 7.23996, in 0.014s\n",
      "[10/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45580, val loss: 7.23974, in 0.015s\n",
      "[11/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45519, val loss: 7.23946, in 0.015s\n",
      "[12/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45459, val loss: 7.23921, in 0.015s\n",
      "[13/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45400, val loss: 7.23895, in 0.015s\n",
      "[14/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45342, val loss: 7.23876, in 0.014s\n",
      "[15/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45284, val loss: 7.23853, in 0.015s\n",
      "[16/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45227, val loss: 7.23831, in 0.013s\n",
      "[17/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45171, val loss: 7.23807, in 0.016s\n",
      "[18/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45117, val loss: 7.23789, in 0.025s\n",
      "[19/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45062, val loss: 7.23763, in 0.015s\n",
      "[20/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45007, val loss: 7.23744, in 0.015s\n",
      "[21/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44954, val loss: 7.23718, in 0.015s\n",
      "[22/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44899, val loss: 7.23697, in 0.013s\n",
      "[23/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44846, val loss: 7.23687, in 0.018s\n",
      "[24/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44797, val loss: 7.23667, in 0.018s\n",
      "[25/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44749, val loss: 7.23644, in 0.018s\n",
      "[26/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44697, val loss: 7.23629, in 0.017s\n",
      "[27/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44650, val loss: 7.23610, in 0.020s\n",
      "[28/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44598, val loss: 7.23591, in 0.017s\n",
      "[29/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44547, val loss: 7.23584, in 0.016s\n",
      "[30/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44501, val loss: 7.23564, in 0.018s\n",
      "[31/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44451, val loss: 7.23563, in 0.017s\n",
      "[32/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44408, val loss: 7.23540, in 0.018s\n",
      "[33/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44363, val loss: 7.23524, in 0.017s\n",
      "[34/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44321, val loss: 7.23503, in 0.017s\n",
      "[35/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44275, val loss: 7.23488, in 0.017s\n",
      "[36/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44231, val loss: 7.23472, in 0.017s\n",
      "[37/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44191, val loss: 7.23457, in 0.016s\n",
      "[38/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44146, val loss: 7.23446, in 0.016s\n",
      "[39/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44107, val loss: 7.23431, in 0.015s\n",
      "[40/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44064, val loss: 7.23419, in 0.014s\n",
      "[41/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.44021, val loss: 7.23407, in 0.014s\n",
      "[42/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43984, val loss: 7.23397, in 0.014s\n",
      "[43/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43941, val loss: 7.23395, in 0.015s\n",
      "[44/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43905, val loss: 7.23385, in 0.015s\n",
      "[45/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43866, val loss: 7.23371, in 0.014s\n",
      "[46/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43831, val loss: 7.23359, in 0.014s\n",
      "[47/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43795, val loss: 7.23353, in 0.014s\n",
      "[48/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43755, val loss: 7.23342, in 0.014s\n",
      "[49/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43717, val loss: 7.23338, in 0.015s\n",
      "[50/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43678, val loss: 7.23327, in 0.014s\n",
      "[51/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43646, val loss: 7.23317, in 0.015s\n",
      "[52/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43610, val loss: 7.23307, in 0.014s\n",
      "[53/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43578, val loss: 7.23299, in 0.016s\n",
      "[54/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43541, val loss: 7.23293, in 0.014s\n",
      "[55/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43507, val loss: 7.23287, in 0.014s\n",
      "[56/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43465, val loss: 7.23280, in 0.014s\n",
      "[57/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43424, val loss: 7.23276, in 0.016s\n",
      "[58/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43389, val loss: 7.23271, in 0.014s\n",
      "[59/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43349, val loss: 7.23270, in 0.015s\n",
      "[60/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43315, val loss: 7.23266, in 0.014s\n",
      "[61/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43276, val loss: 7.23260, in 0.016s\n",
      "[62/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43237, val loss: 7.23261, in 0.015s\n",
      "[63/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43208, val loss: 7.23248, in 0.015s\n",
      "[64/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43170, val loss: 7.23244, in 0.014s\n",
      "[65/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43138, val loss: 7.23241, in 0.015s\n",
      "[66/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43102, val loss: 7.23242, in 0.015s\n",
      "[67/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43062, val loss: 7.23223, in 0.014s\n",
      "[68/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43031, val loss: 7.23220, in 0.014s\n",
      "[69/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42996, val loss: 7.23217, in 0.016s\n",
      "[70/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42963, val loss: 7.23213, in 0.015s\n",
      "[71/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42933, val loss: 7.23211, in 0.014s\n",
      "[72/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42901, val loss: 7.23208, in 0.013s\n",
      "[73/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42868, val loss: 7.23210, in 0.015s\n",
      "[74/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42837, val loss: 7.23204, in 0.014s\n",
      "[75/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42808, val loss: 7.23204, in 0.014s\n",
      "[76/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42778, val loss: 7.23198, in 0.016s\n",
      "[77/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42744, val loss: 7.23201, in 0.016s\n",
      "[78/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42715, val loss: 7.23195, in 0.015s\n",
      "[79/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42685, val loss: 7.23192, in 0.015s\n",
      "[80/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42656, val loss: 7.23187, in 0.014s\n",
      "[81/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42619, val loss: 7.23172, in 0.014s\n",
      "[82/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42589, val loss: 7.23176, in 0.014s\n",
      "[83/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42561, val loss: 7.23174, in 0.015s\n",
      "[84/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42527, val loss: 7.23166, in 0.015s\n",
      "[85/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42498, val loss: 7.23163, in 0.014s\n",
      "[86/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42464, val loss: 7.23148, in 0.014s\n",
      "[87/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42432, val loss: 7.23141, in 0.015s\n",
      "[88/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42400, val loss: 7.23134, in 0.015s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[89/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42371, val loss: 7.23133, in 0.017s\n",
      "[90/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42342, val loss: 7.23128, in 0.015s\n",
      "[91/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42315, val loss: 7.23126, in 0.015s\n",
      "[92/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42289, val loss: 7.23124, in 0.014s\n",
      "[93/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42262, val loss: 7.23128, in 0.013s\n",
      "[94/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42231, val loss: 7.23128, in 0.014s\n",
      "[95/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42203, val loss: 7.23128, in 0.015s\n",
      "[96/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42174, val loss: 7.23125, in 0.014s\n",
      "[97/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42148, val loss: 7.23129, in 0.014s\n",
      "Fit 97 trees in 2.039 s, (1940 total leaves)\n",
      "Time spent computing histograms: 0.343s\n",
      "Time spent finding best splits:  0.105s\n",
      "Time spent applying splits:      0.278s\n",
      "Time spent predicting:           0.028s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.023 GB of training data: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.406 s\n",
      "Binning 0.003 GB of validation data: 0.005 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.51020, val loss: 6.62383, in 0.015s\n",
      "[2/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50949, val loss: 6.62350, in 0.016s\n",
      "[3/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50881, val loss: 6.62317, in 0.014s\n",
      "[4/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50813, val loss: 6.62287, in 0.014s\n",
      "[5/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50747, val loss: 6.62253, in 0.014s\n",
      "[6/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50682, val loss: 6.62221, in 0.016s\n",
      "[7/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50621, val loss: 6.62199, in 0.015s\n",
      "[8/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50562, val loss: 6.62168, in 0.013s\n",
      "[9/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50499, val loss: 6.62138, in 0.013s\n",
      "[10/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50437, val loss: 6.62114, in 0.016s\n",
      "[11/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50379, val loss: 6.62091, in 0.016s\n",
      "[12/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50321, val loss: 6.62059, in 0.015s\n",
      "[13/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50266, val loss: 6.62030, in 0.014s\n",
      "[14/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50207, val loss: 6.62005, in 0.015s\n",
      "[15/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50153, val loss: 6.61977, in 0.015s\n",
      "[16/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50100, val loss: 6.61962, in 0.015s\n",
      "[17/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50041, val loss: 6.61939, in 0.015s\n",
      "[18/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49990, val loss: 6.61920, in 0.013s\n",
      "[19/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49940, val loss: 6.61900, in 0.016s\n",
      "[20/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49886, val loss: 6.61876, in 0.015s\n",
      "[21/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49837, val loss: 6.61858, in 0.014s\n",
      "[22/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49788, val loss: 6.61833, in 0.014s\n",
      "[23/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49737, val loss: 6.61811, in 0.015s\n",
      "[24/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49684, val loss: 6.61788, in 0.015s\n",
      "[25/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49637, val loss: 6.61778, in 0.015s\n",
      "[26/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49585, val loss: 6.61759, in 0.014s\n",
      "[27/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49540, val loss: 6.61741, in 0.015s\n",
      "[28/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49492, val loss: 6.61721, in 0.015s\n",
      "[29/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49447, val loss: 6.61707, in 0.016s\n",
      "[30/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49400, val loss: 6.61682, in 0.015s\n",
      "[31/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49357, val loss: 6.61669, in 0.015s\n",
      "[32/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49308, val loss: 6.61651, in 0.015s\n",
      "[33/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49262, val loss: 6.61638, in 0.014s\n",
      "[34/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49220, val loss: 6.61620, in 0.015s\n",
      "[35/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49176, val loss: 6.61604, in 0.015s\n",
      "[36/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49133, val loss: 6.61594, in 0.014s\n",
      "[37/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49087, val loss: 6.61581, in 0.015s\n",
      "[38/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49041, val loss: 6.61565, in 0.014s\n",
      "[39/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.49000, val loss: 6.61546, in 0.015s\n",
      "[40/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48958, val loss: 6.61531, in 0.015s\n",
      "[41/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48918, val loss: 6.61518, in 0.016s\n",
      "[42/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48876, val loss: 6.61508, in 0.014s\n",
      "[43/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48835, val loss: 6.61483, in 0.015s\n",
      "[44/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48794, val loss: 6.61463, in 0.015s\n",
      "[45/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48753, val loss: 6.61449, in 0.015s\n",
      "[46/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48716, val loss: 6.61442, in 0.014s\n",
      "[47/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48676, val loss: 6.61422, in 0.016s\n",
      "[48/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48635, val loss: 6.61407, in 0.015s\n",
      "[49/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48593, val loss: 6.61395, in 0.015s\n",
      "[50/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48553, val loss: 6.61387, in 0.014s\n",
      "[51/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48509, val loss: 6.61376, in 0.014s\n",
      "[52/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48469, val loss: 6.61358, in 0.014s\n",
      "[53/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48432, val loss: 6.61343, in 0.015s\n",
      "[54/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48395, val loss: 6.61336, in 0.015s\n",
      "[55/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48353, val loss: 6.61329, in 0.015s\n",
      "[56/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48315, val loss: 6.61313, in 0.014s\n",
      "[57/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48282, val loss: 6.61305, in 0.015s\n",
      "[58/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48248, val loss: 6.61294, in 0.017s\n",
      "[59/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48214, val loss: 6.61287, in 0.016s\n",
      "[60/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48175, val loss: 6.61273, in 0.015s\n",
      "[61/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48143, val loss: 6.61263, in 0.015s\n",
      "[62/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48108, val loss: 6.61248, in 0.013s\n",
      "[63/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48076, val loss: 6.61242, in 0.013s\n",
      "[64/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48037, val loss: 6.61236, in 0.016s\n",
      "[65/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.48005, val loss: 6.61226, in 0.015s\n",
      "[66/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.47974, val loss: 6.61219, in 0.015s\n",
      "[67/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.47939, val loss: 6.61210, in 0.015s\n",
      "[68/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.47905, val loss: 6.61202, in 0.015s\n",
      "[69/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.47872, val loss: 6.61196, in 0.015s\n",
      "[70/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.47840, val loss: 6.61193, in 0.014s\n",
      "[71/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.47803, val loss: 6.61188, in 0.015s\n",
      "[72/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.47773, val loss: 6.61179, in 0.013s\n",
      "[73/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.47743, val loss: 6.61171, in 0.017s\n",
      "[74/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.47713, val loss: 6.61164, in 0.014s\n",
      "[75/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.47680, val loss: 6.61162, in 0.014s\n",
      "[76/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.47645, val loss: 6.61160, in 0.013s\n",
      "[77/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.47617, val loss: 6.61153, in 0.014s\n",
      "[78/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.47584, val loss: 6.61143, in 0.014s\n",
      "[79/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.47553, val loss: 6.61139, in 0.013s\n",
      "[80/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.47523, val loss: 6.61136, in 0.014s\n",
      "[81/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.47492, val loss: 6.61128, in 0.014s\n",
      "[82/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.47460, val loss: 6.61127, in 0.014s\n",
      "[83/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.47432, val loss: 6.61124, in 0.014s\n",
      "[84/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.47400, val loss: 6.61121, in 0.013s\n",
      "[85/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.47369, val loss: 6.61110, in 0.014s\n",
      "[86/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.47341, val loss: 6.61106, in 0.013s\n",
      "[87/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.47315, val loss: 6.61099, in 0.014s\n",
      "[88/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.47291, val loss: 6.61098, in 0.014s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[89/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.47262, val loss: 6.61098, in 0.013s\n",
      "[90/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.47232, val loss: 6.61087, in 0.013s\n",
      "[91/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.47202, val loss: 6.61089, in 0.015s\n",
      "[92/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.47172, val loss: 6.61089, in 0.014s\n",
      "[93/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.47145, val loss: 6.61087, in 0.015s\n",
      "[94/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.47117, val loss: 6.61085, in 0.012s\n",
      "[95/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.47089, val loss: 6.61081, in 0.014s\n",
      "[96/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.47063, val loss: 6.61074, in 0.014s\n",
      "[97/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.47034, val loss: 6.61064, in 0.015s\n",
      "[98/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.47005, val loss: 6.61054, in 0.014s\n",
      "[99/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.46979, val loss: 6.61056, in 0.014s\n",
      "[100/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.46954, val loss: 6.61049, in 0.014s\n",
      "Fit 100 trees in 1.972 s, (2000 total leaves)\n",
      "Time spent computing histograms: 0.340s\n",
      "Time spent finding best splits:  0.099s\n",
      "Time spent applying splits:      0.270s\n",
      "Time spent predicting:           0.027s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.023 GB of training data: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.473 s\n",
      "Binning 0.003 GB of validation data: 0.007 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43333, val loss: 6.54895, in 0.021s\n",
      "[2/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43270, val loss: 6.54858, in 0.017s\n",
      "[3/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43206, val loss: 6.54823, in 0.019s\n",
      "[4/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43145, val loss: 6.54787, in 0.018s\n",
      "[5/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43082, val loss: 6.54751, in 0.018s\n",
      "[6/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43022, val loss: 6.54711, in 0.016s\n",
      "[7/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42961, val loss: 6.54672, in 0.018s\n",
      "[8/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42905, val loss: 6.54641, in 0.014s\n",
      "[9/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42847, val loss: 6.54607, in 0.015s\n",
      "[10/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42792, val loss: 6.54582, in 0.013s\n",
      "[11/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42740, val loss: 6.54559, in 0.018s\n",
      "[12/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42683, val loss: 6.54530, in 0.015s\n",
      "[13/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42630, val loss: 6.54497, in 0.015s\n",
      "[14/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42580, val loss: 6.54475, in 0.015s\n",
      "[15/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42526, val loss: 6.54447, in 0.015s\n",
      "[16/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42476, val loss: 6.54419, in 0.013s\n",
      "[17/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42422, val loss: 6.54394, in 0.014s\n",
      "[18/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42374, val loss: 6.54373, in 0.015s\n",
      "[19/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42328, val loss: 6.54355, in 0.015s\n",
      "[20/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42277, val loss: 6.54333, in 0.014s\n",
      "[21/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42229, val loss: 6.54310, in 0.015s\n",
      "[22/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42180, val loss: 6.54279, in 0.014s\n",
      "[23/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42131, val loss: 6.54258, in 0.015s\n",
      "[24/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42083, val loss: 6.54238, in 0.015s\n",
      "[25/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42038, val loss: 6.54219, in 0.016s\n",
      "[26/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41991, val loss: 6.54195, in 0.015s\n",
      "[27/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41945, val loss: 6.54176, in 0.015s\n",
      "[28/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41901, val loss: 6.54157, in 0.014s\n",
      "[29/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41855, val loss: 6.54141, in 0.015s\n",
      "[30/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41810, val loss: 6.54124, in 0.016s\n",
      "[31/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41767, val loss: 6.54107, in 0.016s\n",
      "[32/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41725, val loss: 6.54089, in 0.016s\n",
      "[33/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41683, val loss: 6.54068, in 0.016s\n",
      "[34/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41642, val loss: 6.54052, in 0.017s\n",
      "[35/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41600, val loss: 6.54028, in 0.017s\n",
      "[36/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41560, val loss: 6.54016, in 0.017s\n",
      "[37/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41518, val loss: 6.54006, in 0.019s\n",
      "[38/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41480, val loss: 6.53993, in 0.017s\n",
      "[39/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41440, val loss: 6.53973, in 0.019s\n",
      "[40/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41400, val loss: 6.53960, in 0.020s\n",
      "[41/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41363, val loss: 6.53939, in 0.019s\n",
      "[42/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41325, val loss: 6.53919, in 0.018s\n",
      "[43/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41289, val loss: 6.53914, in 0.021s\n",
      "[44/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41252, val loss: 6.53893, in 0.019s\n",
      "[45/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41218, val loss: 6.53879, in 0.017s\n",
      "[46/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41180, val loss: 6.53869, in 0.018s\n",
      "[47/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41145, val loss: 6.53860, in 0.016s\n",
      "[48/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41110, val loss: 6.53845, in 0.017s\n",
      "[49/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41075, val loss: 6.53834, in 0.020s\n",
      "[50/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41043, val loss: 6.53822, in 0.017s\n",
      "[51/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41010, val loss: 6.53803, in 0.017s\n",
      "[52/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40973, val loss: 6.53793, in 0.016s\n",
      "[53/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40941, val loss: 6.53782, in 0.016s\n",
      "[54/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40901, val loss: 6.53771, in 0.015s\n",
      "[55/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40868, val loss: 6.53765, in 0.015s\n",
      "[56/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40838, val loss: 6.53748, in 0.015s\n",
      "[57/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40806, val loss: 6.53742, in 0.016s\n",
      "[58/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40775, val loss: 6.53738, in 0.015s\n",
      "[59/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40743, val loss: 6.53730, in 0.015s\n",
      "[60/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40711, val loss: 6.53720, in 0.015s\n",
      "[61/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40679, val loss: 6.53708, in 0.015s\n",
      "[62/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40645, val loss: 6.53697, in 0.015s\n",
      "[63/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40615, val loss: 6.53695, in 0.015s\n",
      "[64/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40585, val loss: 6.53677, in 0.015s\n",
      "[65/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40552, val loss: 6.53670, in 0.014s\n",
      "[66/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40523, val loss: 6.53657, in 0.015s\n",
      "[67/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40493, val loss: 6.53659, in 0.014s\n",
      "[68/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40466, val loss: 6.53648, in 0.016s\n",
      "[69/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40436, val loss: 6.53649, in 0.015s\n",
      "[70/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40401, val loss: 6.53641, in 0.015s\n",
      "[71/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40373, val loss: 6.53632, in 0.016s\n",
      "[72/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40346, val loss: 6.53618, in 0.015s\n",
      "[73/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40315, val loss: 6.53610, in 0.014s\n",
      "[74/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40289, val loss: 6.53598, in 0.015s\n",
      "[75/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40260, val loss: 6.53593, in 0.015s\n",
      "[76/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40233, val loss: 6.53597, in 0.015s\n",
      "[77/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40207, val loss: 6.53586, in 0.015s\n",
      "[78/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40175, val loss: 6.53578, in 0.013s\n",
      "[79/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40147, val loss: 6.53571, in 0.014s\n",
      "[80/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40123, val loss: 6.53560, in 0.016s\n",
      "[81/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40092, val loss: 6.53548, in 0.015s\n",
      "[82/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40062, val loss: 6.53533, in 0.013s\n",
      "[83/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40034, val loss: 6.53524, in 0.015s\n",
      "[84/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.40009, val loss: 6.53522, in 0.014s\n",
      "[85/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.39980, val loss: 6.53508, in 0.017s\n",
      "[86/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.39953, val loss: 6.53497, in 0.016s\n",
      "[87/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.39925, val loss: 6.53483, in 0.014s\n",
      "[88/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.39898, val loss: 6.53478, in 0.015s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[89/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.39871, val loss: 6.53473, in 0.015s\n",
      "[90/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.39844, val loss: 6.53462, in 0.016s\n",
      "[91/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.39817, val loss: 6.53449, in 0.015s\n",
      "[92/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.39791, val loss: 6.53440, in 0.016s\n",
      "[93/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.39767, val loss: 6.53431, in 0.014s\n",
      "[94/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.39738, val loss: 6.53426, in 0.013s\n",
      "[95/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.39712, val loss: 6.53428, in 0.015s\n",
      "[96/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.39688, val loss: 6.53419, in 0.014s\n",
      "[97/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.39661, val loss: 6.53412, in 0.015s\n",
      "[98/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.39637, val loss: 6.53400, in 0.015s\n",
      "[99/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.39612, val loss: 6.53393, in 0.014s\n",
      "[100/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.39589, val loss: 6.53385, in 0.015s\n",
      "Fit 100 trees in 2.160 s, (2000 total leaves)\n",
      "Time spent computing histograms: 0.376s\n",
      "Time spent finding best splits:  0.107s\n",
      "Time spent applying splits:      0.296s\n",
      "Time spent predicting:           0.028s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   12.9s finished\n"
     ]
    }
   ],
   "source": [
    "scores = cross_validate(estimator = model, \n",
    "                        X = X, \n",
    "                        y = y, \n",
    "                        cv=cv,\n",
    "                        scoring=scoring,\n",
    "                        verbose = verbose,\n",
    "                        return_train_score=True)\n",
    "results[\"baseline_with_embeddings_and_id_features\"] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2dad6fc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id_column': 'merchant_id',\n",
       " 'type': 'baseline',\n",
       " 'train_r2': 0.0001655841013616044,\n",
       " 'test_r2': 0.00013871442920936338,\n",
       " 'train_root_mean_squared_error': 3.8501609494819595,\n",
       " 'test_root_mean_squared_error': 3.85005310803518}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_output(\"baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f12e65b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id_column': 'merchant_id',\n",
       " 'type': 'baseline_with_embeddings',\n",
       " 'train_r2': 0.0008160651309833567,\n",
       " 'test_r2': 0.00018512965985195695,\n",
       " 'train_root_mean_squared_error': 3.8489068981038246,\n",
       " 'test_root_mean_squared_error': 3.849965290329459}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_output(\"baseline_with_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f4892c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id_column': 'merchant_id',\n",
       " 'type': 'baseline_with_id_features',\n",
       " 'train_r2': 0.0036681666974903715,\n",
       " 'test_r2': 0.002314528415001793,\n",
       " 'train_root_mean_squared_error': 3.843410644738846,\n",
       " 'test_root_mean_squared_error': 3.8458591635475896}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_output(\"baseline_with_id_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "40e5694a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id_column': 'merchant_id',\n",
       " 'type': 'baseline_with_embeddings_and_id_features',\n",
       " 'train_r2': 0.005033211502217294,\n",
       " 'test_r2': 0.0024150607265743585,\n",
       " 'train_root_mean_squared_error': 3.8407769639864924,\n",
       " 'test_root_mean_squared_error': 3.8456642051204923}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_output(\"baseline_with_embeddings_and_id_features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a38a064",
   "metadata": {},
   "source": [
    "### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "afaa6941",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "import csv\n",
    "\n",
    "def make_output(key):\n",
    "    output = {}\n",
    "    output[\"id_column\"] = target_id_column\n",
    "    output[\"type\"] = key\n",
    "    output[\"train_r2\"] = mean(results[key][\"train_r2\"])\n",
    "    output[\"test_r2\"] = mean(results[key][\"test_r2\"])\n",
    "    output[\"train_root_mean_squared_error\"] = -1*mean(results[key][\"train_neg_root_mean_squared_error\"])\n",
    "    output[\"test_root_mean_squared_error\"] = -1*mean(results[key][\"test_neg_root_mean_squared_error\"])\n",
    "    return output\n",
    "def save(output):\n",
    "    path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CZ4041 - Machine Learning\\Team Project\\results\\node2vec_embeddings.csv\"\n",
    "    with open(path, 'a', newline='') as csv_file:\n",
    "        dict_object = csv.DictWriter(csv_file, fieldnames=list(output.keys())) \n",
    "        dict_object.writerow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0ef9ee14",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(make_output(\"baseline\"))\n",
    "save(make_output(\"baseline_with_embeddings\"))\n",
    "save(make_output(\"baseline_with_id_features\"))\n",
    "save(make_output(\"baseline_with_embeddings_and_id_features\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65e5003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100d9e44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40303ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a67e0c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c860f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c502276",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fd3b85bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ecedb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d03c18dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PCA(n_components=2)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1db82b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced = pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "66696574",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import choice\n",
    "indices = choice(range(len(reduced)), 10000)\n",
    "subset_reduced = reduced[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "42cd4673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='tsne_1', ylabel='tsne_2'>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert do DataFrame and plot\n",
    "temp_df = pd.DataFrame({'tsne_1': subset_reduced[:,0],\n",
    "                               'tsne_2': subset_reduced[:,1]})\n",
    "fig, ax = plt.subplots(1)\n",
    "sns.scatterplot(x='tsne_1', y='tsne_2', data=temp_df, ax=ax,s=10)\n",
    "# lim = (tsne_result.min()-5, tsne_result.max()+5)\n",
    "# ax.set_xlim(lim)\n",
    "# ax.set_ylim(lim)\n",
    "# ax.set_aspect('equal')\n",
    "# ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d15225ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get id columns\n",
    "def get_id_data():\n",
    "    # read\n",
    "    merchants = pd.read_csv(merchants_path, usecols = feature_names['merchants']['id'])#, nrows = 100000) \n",
    "    new_transactions = pd.read_csv(new_transactions_path, usecols = feature_names['transactions']['id'])#, nrows = 100000)\n",
    "    hist_transactions = pd.read_csv(historical_transactions_path, usecols = feature_names['transactions']['id'])#, nrows = 100000)\n",
    "    # process\n",
    "    # remove duplicate merchant_id - which there are\n",
    "    merchants = merchants[~merchants.merchant_id.duplicated()]  \n",
    "    # concat historical and new transactions - they have the same columns\n",
    "    id_columns = pd.concat([hist_transactions, new_transactions], axis = 0)\n",
    "    # fill missing merchant_id with the most frequent one \n",
    "    id_columns['merchant_id'] = id_columns['merchant_id'].fillna('M_ID_00a6ca8a8a')\n",
    "    # merge transactions data with merchant information - merchant information has an additional \"merchant_group_id\" column\n",
    "    id_columns = id_columns.merge(merchants[[\"merchant_id\",\"merchant_group_id\"]], how = \"left\", on = \"merchant_id\")\n",
    "    del new_transactions, hist_transactions, merchants\n",
    "    # convert these columns to edge list \n",
    "    to_process_cols = ['city_id', 'merchant_category_id', 'state_id','subsector_id', 'merchant_group_id']\n",
    "    for c in to_process_cols:\n",
    "        id_columns[c] = f\"{c}_\" + id_columns[c].astype(str)\n",
    "    return id_columns\n",
    "# id_columns = get_id_data()\n",
    "# path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CZ4041 - Machine Learning\\Team Project\\data\\id_columns_processed.csv\"\n",
    "# id_columns.to_csv(path, index = False)\n",
    "# id_columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
