{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5df1f015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "import pandas as pd\n",
    "# import networkx as nx\n",
    "# from numpy import std\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec4ff59",
   "metadata": {},
   "source": [
    "### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9133f9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "merch_cols = ['merchant_id', 'numerical_2',\n",
    "               'most_recent_sales_range', 'most_recent_purchases_range',\n",
    "               'avg_sales_lag3', 'avg_purchases_lag3', 'active_months_lag3',\n",
    "               'avg_sales_lag6', 'avg_purchases_lag6', 'active_months_lag6',\n",
    "               'avg_sales_lag12', 'avg_purchases_lag12', 'active_months_lag12',\n",
    "               'category_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3eae589",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_train = pd.read_csv(train_path, usecols = [\"card_id\"])\n",
    "users_test = pd.read_csv(test_path, usecols = [\"card_id\"])\n",
    "# users = pd.concat([users_train, users_train], axis = 0).card_id     # all user_ids\n",
    "merchants = pd.read_csv(merchants_path, usecols = merch_cols)\n",
    "merchants = merchants.drop_duplicates(subset = \"merchant_id\")\n",
    "hist_trans = pd.read_csv(historical_transactions_path, usecols = [\"card_id\", \"merchant_id\"])\n",
    "new_trans = pd.read_csv(new_transactions_path, usecols = [\"card_id\", \"merchant_id\"])\n",
    "# trans = pd.concat([hist_trans, new_trans], axis = 0)                  # all_transactions\n",
    "# data = merchants.merge(trans, how = \"inner\", on = \"merchant_id\")    # all merchants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6f8facc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [col for col in merchants.columns if col in feature_names['merchants']['categoric']] # count, mode, \n",
    "numeric_features = [col for col in merchants.columns if col in feature_names['merchants']['numeric']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12be908e",
   "metadata": {},
   "source": [
    "# Engineer Categoric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1fd75e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_cat_features(df):\n",
    "    df = df.copy()\n",
    "    sales_range_mapping = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4}\n",
    "    category_4_mapping = {\"N\":0, \"Y\":1}\n",
    "    df[\"most_recent_sales_range\"]  = df[\"most_recent_sales_range\"].map(sales_range_mapping)\n",
    "    df[\"most_recent_purchases_range\"]  = df[\"most_recent_purchases_range\"].map(sales_range_mapping)\n",
    "    df[\"category_4\"]  = df[\"category_4\"].map(category_4_mapping)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "73e77cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cat_features(gb, cat_feature):\n",
    "    count = gb[cat_feature].value_counts().unstack()\n",
    "    frac = np.divide(count, count.sum(axis = 1).values.reshape(-1,1))\n",
    "    count.columns = count.columns.name +'_' +count.columns.astype('str')+ '_count'\n",
    "    frac.columns = frac.columns.name +'_' +frac.columns.astype('str')+ '_frac'\n",
    "    return count, frac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398c6863",
   "metadata": {},
   "source": [
    "### Compute merchant categoric features (hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "42cae3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby\n",
    "tmp = encode_cat_features(merchants)\n",
    "tmp = hist_trans.merge(tmp, how = \"left\", on = \"merchant_id\")\n",
    "gb = tmp.groupby(\"card_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5be84ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute \n",
    "features = pd.DataFrame()\n",
    "count, frac = generate_cat_features(gb, \"category_4\")\n",
    "features = pd.concat([features,frac,count], axis = 1)\n",
    "count, frac = generate_cat_features(gb, \"most_recent_sales_range\")\n",
    "features = pd.concat([features,frac,count], axis = 1)\n",
    "count, frac = generate_cat_features(gb, \"most_recent_purchases_range\")\n",
    "features = pd.concat([features,frac,count], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "932f4e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "features.columns = \"old_\"+features.columns\n",
    "features = features.reset_index()\n",
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CZ4041 - Machine Learning\\Team Project\\data\\merchant_cat_features_old.pkl\"\n",
    "features.to_pickle(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d34e30",
   "metadata": {},
   "source": [
    "### Compute merchant categoric features (new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "14ae5a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby\n",
    "tmp = encode_cat_features(merchants)\n",
    "tmp = new_trans.merge(tmp, how = \"left\", on = \"merchant_id\")\n",
    "gb = tmp.groupby(\"card_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6f3f1acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute \n",
    "features = pd.DataFrame()\n",
    "count, frac = generate_cat_features(gb, \"category_4\")\n",
    "features = pd.concat([features,frac,count], axis = 1)\n",
    "count, frac = generate_cat_features(gb, \"most_recent_sales_range\")\n",
    "features = pd.concat([features,frac,count], axis = 1)\n",
    "count, frac = generate_cat_features(gb, \"most_recent_purchases_range\")\n",
    "features = pd.concat([features,frac,count], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b4c27e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "features.columns = \"new_\"+features.columns\n",
    "features = features.reset_index()\n",
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CZ4041 - Machine Learning\\Team Project\\data\\merchant_cat_features_new.pkl\"\n",
    "features.to_pickle(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d27d269",
   "metadata": {},
   "source": [
    "# Engineer Numeric Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3dccef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NAs with median\n",
    "for col,count in merchants.isna().sum().items():\n",
    "    if col in numeric_features and count>0:\n",
    "        merchants[col] = merchants[col].fillna(merchants[col].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb29951",
   "metadata": {},
   "source": [
    "### compute merchant numeric features (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f8b22a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\AppData\\Local\\Temp\\ipykernel_13852\\2755041165.py:4: FutureWarning: ['merchant_id', 'most_recent_sales_range', 'most_recent_purchases_range', 'category_4'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
      "  gb = tmp.groupby('card_id').agg(['mean','min','max','var','skew'])\n"
     ]
    }
   ],
   "source": [
    "# merge\n",
    "tmp = hist_trans.merge(merchants, how = \"left\", on = \"merchant_id\")\n",
    "# groupby and aggregate numeric features\n",
    "gb = tmp.groupby('card_id').agg(['mean','min','max','var','skew'])\n",
    "# rename cols\n",
    "gb.columns = [f\"{col}_{agg_function}\" for col, agg_function in gb.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ea6e4c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "gb.columns = \"old_\"+gb.columns\n",
    "gb = gb.reset_index(drop = True)\n",
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CZ4041 - Machine Learning\\Team Project\\data\\merchant_numeric_features_old.pkl\"\n",
    "gb.to_pickle(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b1c09b",
   "metadata": {},
   "source": [
    "### compute merchant numeric features (new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7775948c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\AppData\\Local\\Temp\\ipykernel_13852\\1317266104.py:4: FutureWarning: ['merchant_id', 'most_recent_sales_range', 'most_recent_purchases_range', 'category_4'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
      "  gb = tmp.groupby('card_id').agg(['mean','min','max','var','skew'])\n"
     ]
    }
   ],
   "source": [
    "# merge\n",
    "tmp = new_trans.merge(merchants, how = \"left\", on = \"merchant_id\")\n",
    "# groupby and aggregate numeric features\n",
    "gb = tmp.groupby('card_id').agg(['mean','min','max','var','skew'])\n",
    "# rename cols\n",
    "gb.columns = [f\"{col}_{agg_function}\" for col, agg_function in gb.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e6ad234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "# gb.columns = \"new_\"+gb.columns\n",
    "gb = gb.reset_index()\n",
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CZ4041 - Machine Learning\\Team Project\\data\\merchant_numeric_features_new.pkl\"\n",
    "gb.to_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf2c3e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8c05899",
   "metadata": {},
   "source": [
    "# Merge and save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2beeff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CZ4041 - Machine Learning\\Team Project\\data\\full_train2.pkl\"\n",
    "train = pd.read_pickle(path)\n",
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CZ4041 - Machine Learning\\Team Project\\data\\full_test2.pkl\"\n",
    "test = pd.read_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3cd84f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CZ4041 - Machine Learning\\Team Project\\data\\merchant_cat_features_old.pkl\",\n",
    "    r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CZ4041 - Machine Learning\\Team Project\\data\\merchant_cat_features_new.pkl\",\n",
    "    r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CZ4041 - Machine Learning\\Team Project\\data\\merchant_numeric_features_old.pkl\",\n",
    "    r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CZ4041 - Machine Learning\\Team Project\\data\\merchant_numeric_features_new.pkl\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8379a6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = train.copy()\n",
    "for path in paths:\n",
    "    features = pd.read_pickle(path)\n",
    "    new_train = new_train.merge(features, how = \"left\", on = \"card_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1743ae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = test.copy()\n",
    "for path in paths:\n",
    "    features = pd.read_pickle(path)\n",
    "    new_test = new_test.merge(features, how = \"left\", on = \"card_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d74e3a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CZ4041 - Machine Learning\\Team Project\\data\\full_train2.pkl\"\n",
    "new_train.to_pickle(path)\n",
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CZ4041 - Machine Learning\\Team Project\\data\\full_test2.pkl\"\n",
    "new_test.to_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c851d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce888502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e568dbd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38c955d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdf5094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute degree_centrality_subgroup, mean_degree_subgroup, min_degree_subgroup, max_degree_subgroup, std_degree_subgroup\n",
    "def compute_subgraph_info(card_id, interest_col, counts):\n",
    "    # \"state_id\"s related to the card_id\n",
    "    related_nodes = data[data.card_id == card_id][interest_col].unique()\n",
    "    subgroup_counts = [counts[node] for node in related_nodes]\n",
    "    total_nodes = sum(subgroup_counts)\n",
    "    degree_centrality = len(related_nodes)/total_nodes\n",
    "    average_degrees = total_nodes/len(related_nodes)\n",
    "    min_group = min(subgroup_counts)\n",
    "    max_group = max(subgroup_counts)\n",
    "    std_group = std(subgroup_counts)\n",
    "    return {\"degree_centrality_subgroup\":degree_centrality,\n",
    "            \"mean_degree_subgroup\":average_degrees, \n",
    "            \"min_degree_subgroup\":min_group, \n",
    "            \"max_degree_subgroup\":max_group,\n",
    "            \"std_degree_subgroup\":std_group}\n",
    "\n",
    "\n",
    "# def generate_id_subgraphs(interest_col):\n",
    "#     # number of merchants for each \"state_id\"\n",
    "#     counts = data[interest_col].value_counts()\n",
    "#     # \"state_id\" subgraphs\n",
    "#     G = {}\n",
    "#     for node,count in counts.items(): \n",
    "#         G[node] = nx.Graph()\n",
    "#         G[node].add_edges_from([(node,f\"{node}_{i}\") for i in range(count)])\n",
    "#     return G\n",
    "# def generate_user_subgraph(card_id, interest_col, id_subgraphs):\n",
    "#     # \"state_id\"s related to the card_id\n",
    "#     related_nodes = data[data.card_id == card_id][interest_col].unique()\n",
    "#     # add \"state_id\"s related to the user\n",
    "#     user_subgraph = nx.Graph()\n",
    "#     user_subgraph.add_edges_from([(card_id, node) for node in related_nodes])\n",
    "#     # merge with relavant id subgraphs\n",
    "#     for node in related_nodes:\n",
    "#         user_subgraph = nx.compose(user_subgraph, id_subgraphs[node])\n",
    "#     return user_subgraph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp",
   "language": "python",
   "name": "dp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
