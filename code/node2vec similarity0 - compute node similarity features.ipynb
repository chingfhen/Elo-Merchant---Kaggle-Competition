{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8865017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nodevectors\n",
    "from numpy import dot\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bbb8af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'merchant_id': 'node2vec_card_id_merchant_id.zip',\n",
       " 'merchant_group_id': 'node2vec_card_id_merchant_group_id.zip',\n",
       " 'merchant_category_id': 'node2vec_card_id_merchant_category_id.zip',\n",
       " 'subsector_id': 'node2vec_card_id_subsector_id.zip',\n",
       " 'city_id': 'node2vec_card_id_city_id.zip',\n",
       " 'state_id': 'node2vec_card_id_state_id.zip'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_cols = ['merchant_id', 'merchant_group_id', 'merchant_category_id','subsector_id', 'city_id', 'state_id']\n",
    "paths = ['node2vec_card_id_merchant_id.zip', 'node2vec_card_id_merchant_group_id.zip', 'node2vec_card_id_merchant_category_id.zip','node2vec_card_id_subsector_id.zip', 'node2vec_card_id_city_id.zip','node2vec_card_id_state_id.zip']\n",
    "node2vec_dir = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CZ4041 - Machine Learning\\Team Project\\model\"\n",
    "os.chdir(node2vec_dir)\n",
    "node2vec_paths = dict(zip(id_cols,paths))\n",
    "node2vec_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6483c717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_path(target_id, directory = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CZ4041 - Machine Learning\\Team Project\\data\\edgelist for node2vec\"):\n",
    "    return os.path.join(directory, f\"card_id_{target_id}.csv\")\n",
    "def get_jsonsave_path(target_id, directory = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CZ4041 - Machine Learning\\Team Project\\data\\node2vec similarities\"):\n",
    "    return os.path.join(directory, f\"{target_id}_similarities.json\")\n",
    "def get_picklesave_path(target_id, directory = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CZ4041 - Machine Learning\\Team Project\\data\\node2vec similarities\"):\n",
    "    return os.path.join(directory, f\"{target_id}_similarity_features.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99642eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "compute node similarity and append to json\n",
    "\"\"\"\n",
    "def process(id1,id2, target_id):\n",
    "    add_score(id1, get_score(id1,id2), target_id)\n",
    "\"\"\"\n",
    "wrapped in process\n",
    "\"\"\"\n",
    "def add_score(card_id, score, target_id):\n",
    "    # global - similarity_score\n",
    "    similarity_score[f\"{target_id}_similarities\"][card_id].append(score)\n",
    "def get_score(id1,id2):\n",
    "    # global - node2vec.model\n",
    "    return dot(node2vec.model[id1],node2vec.model[id2])\n",
    "\n",
    "\"\"\"\n",
    "Computes min,max,sum and mean of similarity scores\n",
    "\"\"\"\n",
    "def compute_similarity_features(card_id: str, similarity_score:list, target_id: str):\n",
    "    return card_id, min(similarity_score), max(similarity_score), sum(similarity_score), np.mean(similarity_score), np.std(similarity_score)\n",
    "#     return {\n",
    "#         \"card_id\":card_id,\n",
    "#         f\"{target_id}_similarity_min\":min(similarity_score),\n",
    "#         f\"{target_id}_similarity_max\":max(similarity_score),\n",
    "#         f\"{target_id}_similarity_sum\":sum(similarity_score),\n",
    "#         f\"{target_id}_similarity_mean\":np.mean(similarity_score)\n",
    "#     }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1013c1",
   "metadata": {},
   "source": [
    "### compute for similarity features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a145f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On merchant_id\n",
      "Loading node2vec model..\n",
      "Loading edgelist..\n",
      "Computing similarities..\n",
      "Computing similarity features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 325540/325540 [00:13<00:00, 24062.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving..\n",
      "On merchant_group_id\n",
      "Loading node2vec model..\n",
      "Loading edgelist..\n",
      "Computing similarities..\n",
      "Computing similarity features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 325540/325540 [00:12<00:00, 26522.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving..\n",
      "On merchant_category_id\n",
      "Loading node2vec model..\n",
      "Loading edgelist..\n",
      "Computing similarities..\n",
      "Computing similarity features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 325540/325540 [00:12<00:00, 25341.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving..\n",
      "On subsector_id\n",
      "Loading node2vec model..\n",
      "Loading edgelist..\n",
      "Computing similarities..\n",
      "Computing similarity features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 325540/325540 [00:10<00:00, 30216.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving..\n",
      "On city_id\n",
      "Loading node2vec model..\n",
      "Loading edgelist..\n",
      "Computing similarities..\n",
      "Computing similarity features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 325540/325540 [00:10<00:00, 31895.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving..\n",
      "On state_id\n",
      "Loading node2vec model..\n",
      "Loading edgelist..\n",
      "Computing similarities..\n",
      "Computing similarity features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 325540/325540 [00:10<00:00, 32080.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving..\n"
     ]
    }
   ],
   "source": [
    "for target_id_feature in [\"merchant_id\",'merchant_group_id', 'merchant_category_id','subsector_id', 'city_id', 'state_id']:\n",
    "    \n",
    "    print(f\"On {target_id_feature}\")\n",
    "    similarity_score = {\n",
    "        f\"{target_id_feature}_similarities\":defaultdict(list)\n",
    "    }\n",
    "    print(\"Loading node2vec model..\")\n",
    "    node2vec = nodevectors.GGVec.load(node2vec_paths[target_id_feature])\n",
    "    print(\"Loading edgelist..\")\n",
    "    path = get_edge_path(target_id_feature)\n",
    "    edges = pd.read_csv(path, header = None, names = [\"card_id\",target_id_feature])\n",
    "    print(\"Computing similarities..\")\n",
    "    edges.apply(lambda row: process(row[\"card_id\"], row[target_id_feature], target_id_feature), axis = 1)\n",
    "    print(\"Computing similarity features\")\n",
    "    similarity_features = []\n",
    "    for card_id, simi in tqdm(similarity_score[f\"{target_id_feature}_similarities\"].items()):\n",
    "        scores = compute_similarity_features(card_id, simi, target_id_feature)\n",
    "        similarity_features.append(scores)\n",
    "    print(\"saving..\")\n",
    "    output = pd.DataFrame(similarity_features, columns = [\"card_id\", f\"{target_id_feature}_similarity_min\",f\"{target_id_feature}_similarity_max\",f\"{target_id_feature}_similarity_sum\",f\"{target_id_feature}_similarity_mean\",f\"{target_id_feature}_similarity_std\"])\n",
    "    path = get_picklesave_path(target_id_feature)\n",
    "    output.to_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e810de6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebf5a47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75e71437",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# path = get_jsonsave_path(target_id_feature)\n",
    "# with open(path, \"w\") as f:\n",
    "#     json.dump(similarity_score, f, indent=4)\n",
    "# path = get_jsonsave_path(target_id_feature)\n",
    "# with open(path, \"r\") as f:\n",
    "#     similarity_score = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1ce78b44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
