{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90634bf5",
   "metadata": {},
   "source": [
    "# ABOUT: \n",
    "- this code evaluates the node2vec embeddings on all node2vec embeddings generated\n",
    "- findings: \n",
    "    - using card_id embeddings appear to cause overfitting\n",
    "        \n",
    "- details:       \n",
    "    - i.e compared to baseline, performance on training set is better but performance on validation set is worse\n",
    "    - baseline - using just feature_2 as feature\n",
    "    - model used is Histogram Gradient boosting\n",
    "    - metrics used are r2 and rmse\n",
    "    - 3 fold cross validated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "469228eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import nodevectors\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07657160",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_id_column = \"city_id\"\n",
    "node2vec_path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CZ4041 - Machine Learning\\Team Project\\model\\node2vec_card_id_city_id.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aee90f24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>city_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>city_id_88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>city_id_88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>city_id_88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>city_id_88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>city_id_88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id     city_id\n",
       "0  C_ID_4e6213e9bc  city_id_88\n",
       "1  C_ID_4e6213e9bc  city_id_88\n",
       "2  C_ID_4e6213e9bc  city_id_88\n",
       "3  C_ID_4e6213e9bc  city_id_88\n",
       "4  C_ID_4e6213e9bc  city_id_88"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CZ4041 - Machine Learning\\Team Project\\data\\id_columns_processed.csv\"\n",
    "id_columns = pd.read_csv(path, nrows = None, usecols = [\"card_id\", target_id_column])\n",
    "id_columns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8e37e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.820283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>1</td>\n",
       "      <td>0.392913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>2</td>\n",
       "      <td>0.688056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_186d6a6901</td>\n",
       "      <td>3</td>\n",
       "      <td>0.142495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_cdbd2c0db2</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.159749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id  feature_2    target\n",
       "0  C_ID_92a2005557          2 -0.820283\n",
       "1  C_ID_3d0044924f          1  0.392913\n",
       "2  C_ID_d639edf6cd          2  0.688056\n",
       "3  C_ID_186d6a6901          3  0.142495\n",
       "4  C_ID_cdbd2c0db2          3 -0.159749"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load train target variable\n",
    "train_file = pd.read_csv(train_path, usecols = [\"card_id\",\"target\", \"feature_2\"])\n",
    "train_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95744be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_00007093c1</td>\n",
       "      <td>-0.106716</td>\n",
       "      <td>-0.089236</td>\n",
       "      <td>0.113657</td>\n",
       "      <td>-0.123730</td>\n",
       "      <td>0.014258</td>\n",
       "      <td>0.113594</td>\n",
       "      <td>-0.176164</td>\n",
       "      <td>0.083533</td>\n",
       "      <td>-0.039410</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077418</td>\n",
       "      <td>-0.050492</td>\n",
       "      <td>-0.135790</td>\n",
       "      <td>0.169363</td>\n",
       "      <td>-0.117154</td>\n",
       "      <td>0.197989</td>\n",
       "      <td>-0.074490</td>\n",
       "      <td>-0.074387</td>\n",
       "      <td>-0.155933</td>\n",
       "      <td>-0.153348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_0001238066</td>\n",
       "      <td>0.157534</td>\n",
       "      <td>-0.101552</td>\n",
       "      <td>0.174173</td>\n",
       "      <td>0.231312</td>\n",
       "      <td>-0.318610</td>\n",
       "      <td>-0.159484</td>\n",
       "      <td>-0.116667</td>\n",
       "      <td>0.105384</td>\n",
       "      <td>0.174811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.308444</td>\n",
       "      <td>-0.225374</td>\n",
       "      <td>-0.182541</td>\n",
       "      <td>-0.128666</td>\n",
       "      <td>-0.039411</td>\n",
       "      <td>0.061187</td>\n",
       "      <td>0.025898</td>\n",
       "      <td>-0.296355</td>\n",
       "      <td>0.015855</td>\n",
       "      <td>-0.031663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_0001506ef0</td>\n",
       "      <td>-0.141772</td>\n",
       "      <td>0.120108</td>\n",
       "      <td>0.139707</td>\n",
       "      <td>-0.089195</td>\n",
       "      <td>0.121194</td>\n",
       "      <td>0.059623</td>\n",
       "      <td>-0.160276</td>\n",
       "      <td>-0.025165</td>\n",
       "      <td>-0.221492</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040747</td>\n",
       "      <td>0.059382</td>\n",
       "      <td>-0.030425</td>\n",
       "      <td>-0.194672</td>\n",
       "      <td>-0.021321</td>\n",
       "      <td>-0.060224</td>\n",
       "      <td>0.097151</td>\n",
       "      <td>0.063103</td>\n",
       "      <td>0.037582</td>\n",
       "      <td>-0.026990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_0001793786</td>\n",
       "      <td>-0.039819</td>\n",
       "      <td>-0.187320</td>\n",
       "      <td>0.003942</td>\n",
       "      <td>0.128835</td>\n",
       "      <td>0.125397</td>\n",
       "      <td>0.168516</td>\n",
       "      <td>0.125239</td>\n",
       "      <td>0.128109</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093655</td>\n",
       "      <td>-0.131937</td>\n",
       "      <td>0.243757</td>\n",
       "      <td>-0.015062</td>\n",
       "      <td>0.030878</td>\n",
       "      <td>0.143987</td>\n",
       "      <td>-0.276977</td>\n",
       "      <td>0.055190</td>\n",
       "      <td>-0.084917</td>\n",
       "      <td>-0.077475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_000183fdda</td>\n",
       "      <td>-0.061255</td>\n",
       "      <td>-0.012943</td>\n",
       "      <td>-0.168752</td>\n",
       "      <td>0.159792</td>\n",
       "      <td>-0.254140</td>\n",
       "      <td>0.138611</td>\n",
       "      <td>0.280408</td>\n",
       "      <td>-0.057751</td>\n",
       "      <td>-0.052864</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112484</td>\n",
       "      <td>-0.260600</td>\n",
       "      <td>0.229047</td>\n",
       "      <td>-0.016090</td>\n",
       "      <td>-0.019483</td>\n",
       "      <td>-0.002663</td>\n",
       "      <td>-0.011464</td>\n",
       "      <td>0.131821</td>\n",
       "      <td>0.124212</td>\n",
       "      <td>-0.095945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325843</th>\n",
       "      <td>city_id_92</td>\n",
       "      <td>0.828420</td>\n",
       "      <td>0.472418</td>\n",
       "      <td>-0.370669</td>\n",
       "      <td>-0.262726</td>\n",
       "      <td>-0.663897</td>\n",
       "      <td>-0.650594</td>\n",
       "      <td>-0.170845</td>\n",
       "      <td>-0.401652</td>\n",
       "      <td>-0.158569</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.630482</td>\n",
       "      <td>-0.588893</td>\n",
       "      <td>-0.453237</td>\n",
       "      <td>0.084014</td>\n",
       "      <td>-0.588800</td>\n",
       "      <td>-0.306644</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.217924</td>\n",
       "      <td>0.335679</td>\n",
       "      <td>0.578960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325844</th>\n",
       "      <td>city_id_94</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.001960</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>-0.000796</td>\n",
       "      <td>-0.000426</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001277</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>-0.000769</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>-0.001088</td>\n",
       "      <td>-0.000144</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>-0.002154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325845</th>\n",
       "      <td>city_id_96</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>-0.000166</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>-0.001587</td>\n",
       "      <td>-0.000349</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.001348</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000283</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.001060</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>-0.001065</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.000701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325846</th>\n",
       "      <td>city_id_97</td>\n",
       "      <td>-0.000647</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>-0.001357</td>\n",
       "      <td>0.002225</td>\n",
       "      <td>-0.000659</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000751</td>\n",
       "      <td>0.001632</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>0.001337</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>-0.000294</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325847</th>\n",
       "      <td>city_id_98</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>-0.000289</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>-0.000817</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001754</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>-0.001296</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>-0.000629</td>\n",
       "      <td>0.002330</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>-0.000528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>325848 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  index         0         1         2         3         4  \\\n",
       "0       C_ID_00007093c1 -0.106716 -0.089236  0.113657 -0.123730  0.014258   \n",
       "1       C_ID_0001238066  0.157534 -0.101552  0.174173  0.231312 -0.318610   \n",
       "2       C_ID_0001506ef0 -0.141772  0.120108  0.139707 -0.089195  0.121194   \n",
       "3       C_ID_0001793786 -0.039819 -0.187320  0.003942  0.128835  0.125397   \n",
       "4       C_ID_000183fdda -0.061255 -0.012943 -0.168752  0.159792 -0.254140   \n",
       "...                 ...       ...       ...       ...       ...       ...   \n",
       "325843       city_id_92  0.828420  0.472418 -0.370669 -0.262726 -0.663897   \n",
       "325844       city_id_94  0.001069  0.001242  0.000663  0.001960  0.001424   \n",
       "325845       city_id_96  0.000590 -0.000178  0.001212 -0.000166  0.000708   \n",
       "325846       city_id_97 -0.000647  0.000120  0.000260 -0.000200  0.000127   \n",
       "325847       city_id_98  0.002439 -0.000289  0.000743  0.000629  0.000653   \n",
       "\n",
       "               5         6         7         8  ...        22        23  \\\n",
       "0       0.113594 -0.176164  0.083533 -0.039410  ... -0.077418 -0.050492   \n",
       "1      -0.159484 -0.116667  0.105384  0.174811  ...  0.308444 -0.225374   \n",
       "2       0.059623 -0.160276 -0.025165 -0.221492  ... -0.040747  0.059382   \n",
       "3       0.168516  0.125239  0.128109  0.035853  ... -0.093655 -0.131937   \n",
       "4       0.138611  0.280408 -0.057751 -0.052864  ... -0.112484 -0.260600   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "325843 -0.650594 -0.170845 -0.401652 -0.158569  ... -0.630482 -0.588893   \n",
       "325844  0.001180 -0.000796 -0.000426  0.000822  ... -0.001277  0.000871   \n",
       "325845 -0.001587 -0.000349  0.000135  0.001348  ... -0.000283  0.000279   \n",
       "325846  0.000299 -0.001357  0.002225 -0.000659  ... -0.000751  0.001632   \n",
       "325847 -0.000817  0.001172  0.000667  0.000577  ... -0.001754  0.000082   \n",
       "\n",
       "              24        25        26        27        28        29        30  \\\n",
       "0      -0.135790  0.169363 -0.117154  0.197989 -0.074490 -0.074387 -0.155933   \n",
       "1      -0.182541 -0.128666 -0.039411  0.061187  0.025898 -0.296355  0.015855   \n",
       "2      -0.030425 -0.194672 -0.021321 -0.060224  0.097151  0.063103  0.037582   \n",
       "3       0.243757 -0.015062  0.030878  0.143987 -0.276977  0.055190 -0.084917   \n",
       "4       0.229047 -0.016090 -0.019483 -0.002663 -0.011464  0.131821  0.124212   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "325843 -0.453237  0.084014 -0.588800 -0.306644  0.003675  0.217924  0.335679   \n",
       "325844 -0.000769  0.000146  0.001048  0.000038 -0.001088 -0.000144  0.000550   \n",
       "325845  0.001060  0.000751 -0.001065  0.001509  0.000648  0.000361  0.000809   \n",
       "325846  0.001176  0.001696  0.001337  0.001670 -0.000294  0.000038  0.000105   \n",
       "325847 -0.001296  0.000504 -0.000629  0.002330 -0.000014  0.000361  0.000513   \n",
       "\n",
       "              31  \n",
       "0      -0.153348  \n",
       "1      -0.031663  \n",
       "2      -0.026990  \n",
       "3      -0.077475  \n",
       "4      -0.095945  \n",
       "...          ...  \n",
       "325843  0.578960  \n",
       "325844 -0.002154  \n",
       "325845  0.000701  \n",
       "325846  0.000450  \n",
       "325847 -0.000528  \n",
       "\n",
       "[325848 rows x 33 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load trained node2vec\n",
    "node2vec = nodevectors.GGVec.load(node2vec_path)\n",
    "# convert embeddings to dataframe\n",
    "node2vec_embeddings = pd.DataFrame.from_dict(node2vec.model, orient = \"index\")\n",
    "node2vec_embeddings = node2vec_embeddings.reset_index()\n",
    "node2vec_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93a38660",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# group and aggregate the id embeddings (e.g city_id embeddings) by the \"card_id\"\n",
    "node2vec_embeddings = id_columns.merge(node2vec_embeddings, how = \"left\", left_on = \"card_id\", right_on = \"index\")\n",
    "node2vec_embeddings = node2vec_embeddings.drop(\"index\", axis = 1)\n",
    "node2vec_embeddings = node2vec_embeddings.groupby(\"card_id\").mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b52db86d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.820283</td>\n",
       "      <td>0.069153</td>\n",
       "      <td>0.051837</td>\n",
       "      <td>-0.000265</td>\n",
       "      <td>-0.028155</td>\n",
       "      <td>0.049382</td>\n",
       "      <td>-0.085005</td>\n",
       "      <td>0.119039</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046368</td>\n",
       "      <td>0.124118</td>\n",
       "      <td>-0.197271</td>\n",
       "      <td>0.135623</td>\n",
       "      <td>-0.123432</td>\n",
       "      <td>0.013720</td>\n",
       "      <td>-0.008437</td>\n",
       "      <td>-0.055381</td>\n",
       "      <td>0.085001</td>\n",
       "      <td>-0.009585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>1</td>\n",
       "      <td>0.392913</td>\n",
       "      <td>0.079955</td>\n",
       "      <td>-0.000385</td>\n",
       "      <td>0.192025</td>\n",
       "      <td>0.037655</td>\n",
       "      <td>-0.024281</td>\n",
       "      <td>0.010080</td>\n",
       "      <td>0.101211</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.137529</td>\n",
       "      <td>-0.049119</td>\n",
       "      <td>-0.012980</td>\n",
       "      <td>-0.020049</td>\n",
       "      <td>0.184259</td>\n",
       "      <td>0.104667</td>\n",
       "      <td>-0.161247</td>\n",
       "      <td>-0.063553</td>\n",
       "      <td>-0.007475</td>\n",
       "      <td>-0.055708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>2</td>\n",
       "      <td>0.688056</td>\n",
       "      <td>-0.149637</td>\n",
       "      <td>-0.076601</td>\n",
       "      <td>-0.065510</td>\n",
       "      <td>-0.031559</td>\n",
       "      <td>-0.079825</td>\n",
       "      <td>0.068283</td>\n",
       "      <td>-0.012328</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042642</td>\n",
       "      <td>0.148946</td>\n",
       "      <td>0.171022</td>\n",
       "      <td>-0.113394</td>\n",
       "      <td>-0.062607</td>\n",
       "      <td>-0.109001</td>\n",
       "      <td>-0.034621</td>\n",
       "      <td>0.080301</td>\n",
       "      <td>0.031115</td>\n",
       "      <td>-0.114331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_186d6a6901</td>\n",
       "      <td>3</td>\n",
       "      <td>0.142495</td>\n",
       "      <td>-0.017425</td>\n",
       "      <td>-0.020500</td>\n",
       "      <td>-0.051019</td>\n",
       "      <td>0.085914</td>\n",
       "      <td>0.034674</td>\n",
       "      <td>-0.103122</td>\n",
       "      <td>-0.101948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058944</td>\n",
       "      <td>-0.018131</td>\n",
       "      <td>0.090689</td>\n",
       "      <td>-0.065021</td>\n",
       "      <td>0.164142</td>\n",
       "      <td>0.004360</td>\n",
       "      <td>-0.174505</td>\n",
       "      <td>0.147133</td>\n",
       "      <td>-0.088404</td>\n",
       "      <td>0.118497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_cdbd2c0db2</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.159749</td>\n",
       "      <td>0.076518</td>\n",
       "      <td>-0.063663</td>\n",
       "      <td>-0.059358</td>\n",
       "      <td>-0.002621</td>\n",
       "      <td>-0.102248</td>\n",
       "      <td>-0.011622</td>\n",
       "      <td>0.147796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088880</td>\n",
       "      <td>-0.034169</td>\n",
       "      <td>0.028208</td>\n",
       "      <td>0.160501</td>\n",
       "      <td>0.104513</td>\n",
       "      <td>0.114578</td>\n",
       "      <td>0.037847</td>\n",
       "      <td>0.122616</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>0.061013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id  feature_2    target         0         1         2  \\\n",
       "0  C_ID_92a2005557          2 -0.820283  0.069153  0.051837 -0.000265   \n",
       "1  C_ID_3d0044924f          1  0.392913  0.079955 -0.000385  0.192025   \n",
       "2  C_ID_d639edf6cd          2  0.688056 -0.149637 -0.076601 -0.065510   \n",
       "3  C_ID_186d6a6901          3  0.142495 -0.017425 -0.020500 -0.051019   \n",
       "4  C_ID_cdbd2c0db2          3 -0.159749  0.076518 -0.063663 -0.059358   \n",
       "\n",
       "          3         4         5         6  ...        22        23        24  \\\n",
       "0 -0.028155  0.049382 -0.085005  0.119039  ... -0.046368  0.124118 -0.197271   \n",
       "1  0.037655 -0.024281  0.010080  0.101211  ... -0.137529 -0.049119 -0.012980   \n",
       "2 -0.031559 -0.079825  0.068283 -0.012328  ... -0.042642  0.148946  0.171022   \n",
       "3  0.085914  0.034674 -0.103122 -0.101948  ...  0.058944 -0.018131  0.090689   \n",
       "4 -0.002621 -0.102248 -0.011622  0.147796  ...  0.088880 -0.034169  0.028208   \n",
       "\n",
       "         25        26        27        28        29        30        31  \n",
       "0  0.135623 -0.123432  0.013720 -0.008437 -0.055381  0.085001 -0.009585  \n",
       "1 -0.020049  0.184259  0.104667 -0.161247 -0.063553 -0.007475 -0.055708  \n",
       "2 -0.113394 -0.062607 -0.109001 -0.034621  0.080301  0.031115 -0.114331  \n",
       "3 -0.065021  0.164142  0.004360 -0.174505  0.147133 -0.088404  0.118497  \n",
       "4  0.160501  0.104513  0.114578  0.037847  0.122616  0.012048  0.061013  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge id embeddings with train.csv \n",
    "dataset = train_file.merge(node2vec_embeddings, on = \"card_id\", how = \"left\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7042380e",
   "metadata": {},
   "source": [
    "## Evaluate effectiveness of card_id embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b0d7e7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define columns for training\n",
    "train_cols_a = [\"feature_2\"]\n",
    "train_cols_b = [\"feature_2\"] + list(range(32))\n",
    "target_col = \"target\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80db3796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5575dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_cols_a\n",
    "X,y = dataset[features], dataset[target_col]\n",
    "cv = 5\n",
    "scoring=('r2', 'neg_root_mean_squared_error')\n",
    "verbose = 1\n",
    "model_params = {\n",
    "    \"learning_rate\":0.05,\n",
    "    \"max_iter\":100,\n",
    "    \"categorical_features\" : X.columns.isin([\"feature_2\"]),\n",
    "    \"l2_regularization\":0.005,\n",
    "    \"early_stopping\":True,\n",
    "    \"n_iter_no_change\":5,\n",
    "    \"verbose\":1,\n",
    "    \"random_state\":0,\n",
    "    \"max_depth\":5\n",
    "}\n",
    "model = HistGradientBoostingRegressor(**model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "471b06ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.001 GB of training data: 0.052 s\n",
      "Binning 0.000 GB of validation data: 0.002 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34887, val loss: 8.13147, in 0.019s\n",
      "[2/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34869, val loss: 8.13144, in 0.013s\n",
      "[3/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34852, val loss: 8.13142, in 0.007s\n",
      "[4/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34836, val loss: 8.13141, in 0.007s\n",
      "[5/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34823, val loss: 8.13141, in 0.007s\n",
      "[6/100] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tree, 3 leaves, max depth = 2, train loss: 7.34810, val loss: 8.13141, in 0.007s\n",
      "[7/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34799, val loss: 8.13143, in 0.007s\n",
      "[8/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34789, val loss: 8.13144, in 0.008s\n",
      "[9/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34780, val loss: 8.13146, in 0.007s\n",
      "[10/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.34771, val loss: 8.13148, in 0.007s\n",
      "Fit 10 trees in 0.197 s, (30 total leaves)\n",
      "Time spent computing histograms: 0.006s\n",
      "Time spent finding best splits:  0.002s\n",
      "Time spent applying splits:      0.011s\n",
      "Time spent predicting:           0.004s\n",
      "Binning 0.001 GB of training data: 0.001 s\n",
      "Binning 0.000 GB of validation data: 0.000 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.38719, val loss: 7.81604, in 0.006s\n",
      "[2/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.38702, val loss: 7.81603, in 0.007s\n",
      "[3/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.38687, val loss: 7.81603, in 0.006s\n",
      "[4/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.38673, val loss: 7.81604, in 0.008s\n",
      "[5/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.38661, val loss: 7.81605, in 0.007s\n",
      "[6/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.38650, val loss: 7.81607, in 0.007s\n",
      "[7/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.38640, val loss: 7.81609, in 0.008s\n",
      "Fit 7 trees in 0.081 s, (21 total leaves)\n",
      "Time spent computing histograms: 0.004s\n",
      "Time spent finding best splits:  0.002s\n",
      "Time spent applying splits:      0.009s\n",
      "Time spent predicting:           0.001s\n",
      "Binning 0.001 GB of training data: 0.001 s\n",
      "Binning 0.000 GB of validation data: 0.001 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46224, val loss: 7.24243, in 0.006s\n",
      "[2/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46206, val loss: 7.24231, in 0.007s\n",
      "[3/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46189, val loss: 7.24220, in 0.007s\n",
      "[4/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46174, val loss: 7.24211, in 0.008s\n",
      "[5/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46161, val loss: 7.24203, in 0.008s\n",
      "[6/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46148, val loss: 7.24196, in 0.007s\n",
      "[7/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46137, val loss: 7.24190, in 0.007s\n",
      "[8/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46127, val loss: 7.24185, in 0.007s\n",
      "[9/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46118, val loss: 7.24180, in 0.007s\n",
      "[10/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46110, val loss: 7.24176, in 0.007s\n",
      "[11/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46103, val loss: 7.24173, in 0.008s\n",
      "[12/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46096, val loss: 7.24170, in 0.008s\n",
      "[13/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46090, val loss: 7.24168, in 0.008s\n",
      "[14/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46085, val loss: 7.24166, in 0.008s\n",
      "[15/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46080, val loss: 7.24165, in 0.007s\n",
      "[16/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46075, val loss: 7.24163, in 0.008s\n",
      "[17/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46071, val loss: 7.24162, in 0.008s\n",
      "[18/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46068, val loss: 7.24162, in 0.008s\n",
      "[19/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46065, val loss: 7.24161, in 0.007s\n",
      "[20/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46062, val loss: 7.24161, in 0.007s\n",
      "[21/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46059, val loss: 7.24161, in 0.008s\n",
      "[22/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46057, val loss: 7.24161, in 0.007s\n",
      "[23/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46054, val loss: 7.24161, in 0.008s\n",
      "[24/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46052, val loss: 7.24161, in 0.008s\n",
      "[25/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46051, val loss: 7.24161, in 0.007s\n",
      "[26/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46049, val loss: 7.24161, in 0.007s\n",
      "[27/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.46048, val loss: 7.24162, in 0.007s\n",
      "Fit 27 trees in 0.234 s, (81 total leaves)\n",
      "Time spent computing histograms: 0.016s\n",
      "Time spent finding best splits:  0.004s\n",
      "Time spent applying splits:      0.029s\n",
      "Time spent predicting:           0.006s\n",
      "Binning 0.001 GB of training data: 0.001 s\n",
      "Binning 0.000 GB of validation data: 0.000 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51071, val loss: 6.62410, in 0.005s\n",
      "[2/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51054, val loss: 6.62399, in 0.007s\n",
      "[3/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51039, val loss: 6.62389, in 0.008s\n",
      "[4/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51025, val loss: 6.62381, in 0.007s\n",
      "[5/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51012, val loss: 6.62374, in 0.008s\n",
      "[6/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.51001, val loss: 6.62368, in 0.008s\n",
      "[7/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50991, val loss: 6.62362, in 0.008s\n",
      "[8/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50981, val loss: 6.62358, in 0.008s\n",
      "[9/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50973, val loss: 6.62354, in 0.009s\n",
      "[10/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50966, val loss: 6.62350, in 0.008s\n",
      "[11/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50959, val loss: 6.62348, in 0.008s\n",
      "[12/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50953, val loss: 6.62345, in 0.008s\n",
      "[13/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50947, val loss: 6.62343, in 0.008s\n",
      "[14/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50942, val loss: 6.62342, in 0.008s\n",
      "[15/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50938, val loss: 6.62340, in 0.009s\n",
      "[16/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50934, val loss: 6.62339, in 0.008s\n",
      "[17/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50930, val loss: 6.62339, in 0.007s\n",
      "[18/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50927, val loss: 6.62338, in 0.008s\n",
      "[19/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50924, val loss: 6.62338, in 0.007s\n",
      "[20/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50921, val loss: 6.62337, in 0.010s\n",
      "[21/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50919, val loss: 6.62337, in 0.008s\n",
      "[22/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50916, val loss: 6.62337, in 0.008s\n",
      "[23/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50914, val loss: 6.62338, in 0.008s\n",
      "[24/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50913, val loss: 6.62338, in 0.006s\n",
      "[25/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50911, val loss: 6.62338, in 0.009s\n",
      "[26/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.50909, val loss: 6.62339, in 0.008s\n",
      "Fit 26 trees in 0.237 s, (78 total leaves)\n",
      "Time spent computing histograms: 0.018s\n",
      "Time spent finding best splits:  0.005s\n",
      "Time spent applying splits:      0.034s\n",
      "Time spent predicting:           0.007s\n",
      "Binning 0.001 GB of training data: 0.002 s\n",
      "Binning 0.000 GB of validation data: 0.001 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43383, val loss: 6.54907, in 0.006s\n",
      "[2/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43368, val loss: 6.54883, in 0.006s\n",
      "[3/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43355, val loss: 6.54861, in 0.006s\n",
      "[4/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43344, val loss: 6.54840, in 0.007s\n",
      "[5/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43333, val loss: 6.54821, in 0.006s\n",
      "[6/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43324, val loss: 6.54804, in 0.006s\n",
      "[7/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43315, val loss: 6.54788, in 0.007s\n",
      "[8/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43307, val loss: 6.54773, in 0.007s\n",
      "[9/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43300, val loss: 6.54759, in 0.007s\n",
      "[10/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43294, val loss: 6.54746, in 0.007s\n",
      "[11/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43288, val loss: 6.54734, in 0.007s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43283, val loss: 6.54723, in 0.006s\n",
      "[13/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43279, val loss: 6.54713, in 0.006s\n",
      "[14/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43274, val loss: 6.54703, in 0.007s\n",
      "[15/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43271, val loss: 6.54695, in 0.006s\n",
      "[16/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43267, val loss: 6.54686, in 0.007s\n",
      "[17/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43264, val loss: 6.54679, in 0.008s\n",
      "[18/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43261, val loss: 6.54672, in 0.007s\n",
      "[19/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43259, val loss: 6.54665, in 0.006s\n",
      "[20/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43257, val loss: 6.54659, in 0.006s\n",
      "[21/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43255, val loss: 6.54653, in 0.007s\n",
      "[22/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43253, val loss: 6.54648, in 0.007s\n",
      "[23/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43251, val loss: 6.54643, in 0.007s\n",
      "[24/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43250, val loss: 6.54638, in 0.007s\n",
      "[25/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43248, val loss: 6.54634, in 0.007s\n",
      "[26/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43247, val loss: 6.54630, in 0.007s\n",
      "[27/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43246, val loss: 6.54626, in 0.007s\n",
      "[28/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43245, val loss: 6.54622, in 0.007s\n",
      "[29/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43244, val loss: 6.54619, in 0.006s\n",
      "[30/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43243, val loss: 6.54616, in 0.006s\n",
      "[31/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43242, val loss: 6.54613, in 0.006s\n",
      "[32/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43242, val loss: 6.54610, in 0.006s\n",
      "[33/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43241, val loss: 6.54607, in 0.007s\n",
      "[34/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43241, val loss: 6.54605, in 0.006s\n",
      "[35/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43240, val loss: 6.54603, in 0.007s\n",
      "[36/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43240, val loss: 6.54600, in 0.006s\n",
      "[37/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43239, val loss: 6.54598, in 0.007s\n",
      "[38/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43239, val loss: 6.54597, in 0.006s\n",
      "[39/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43239, val loss: 6.54595, in 0.006s\n",
      "[40/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43238, val loss: 6.54593, in 0.006s\n",
      "[41/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43238, val loss: 6.54591, in 0.007s\n",
      "[42/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43238, val loss: 6.54590, in 0.007s\n",
      "[43/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43238, val loss: 6.54589, in 0.007s\n",
      "[44/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43237, val loss: 6.54587, in 0.006s\n",
      "[45/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43237, val loss: 6.54586, in 0.006s\n",
      "[46/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43237, val loss: 6.54585, in 0.007s\n",
      "[47/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43237, val loss: 6.54584, in 0.007s\n",
      "[48/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43237, val loss: 6.54583, in 0.006s\n",
      "[49/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43237, val loss: 6.54582, in 0.007s\n",
      "[50/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43237, val loss: 6.54581, in 0.006s\n",
      "[51/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43237, val loss: 6.54580, in 0.007s\n",
      "[52/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54579, in 0.007s\n",
      "[53/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54578, in 0.015s\n",
      "[54/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54577, in 0.008s\n",
      "[55/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54577, in 0.007s\n",
      "[56/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54576, in 0.006s\n",
      "[57/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54575, in 0.007s\n",
      "[58/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54575, in 0.007s\n",
      "[59/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54574, in 0.007s\n",
      "[60/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54574, in 0.005s\n",
      "[61/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54573, in 0.007s\n",
      "[62/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54573, in 0.006s\n",
      "[63/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54572, in 0.007s\n",
      "[64/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54572, in 0.006s\n",
      "[65/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54571, in 0.006s\n",
      "[66/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54571, in 0.007s\n",
      "[67/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54571, in 0.007s\n",
      "[68/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54570, in 0.006s\n",
      "[69/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54570, in 0.006s\n",
      "[70/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54570, in 0.006s\n",
      "[71/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54569, in 0.007s\n",
      "[72/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54569, in 0.007s\n",
      "[73/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54569, in 0.006s\n",
      "[74/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54568, in 0.006s\n",
      "[75/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54568, in 0.007s\n",
      "[76/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54568, in 0.007s\n",
      "[77/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54568, in 0.007s\n",
      "[78/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54568, in 0.006s\n",
      "[79/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54567, in 0.006s\n",
      "[80/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54567, in 0.007s\n",
      "[81/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54567, in 0.007s\n",
      "[82/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54567, in 0.007s\n",
      "[83/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54567, in 0.006s\n",
      "[84/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54567, in 0.006s\n",
      "[85/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54566, in 0.007s\n",
      "[86/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54566, in 0.007s\n",
      "[87/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54566, in 0.007s\n",
      "[88/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54566, in 0.007s\n",
      "[89/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54566, in 0.007s\n",
      "[90/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54566, in 0.007s\n",
      "[91/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54566, in 0.007s\n",
      "[92/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54566, in 0.007s\n",
      "[93/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54566, in 0.007s\n",
      "[94/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54565, in 0.006s\n",
      "[95/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54565, in 0.006s\n",
      "[96/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54565, in 0.006s\n",
      "[97/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54565, in 0.007s\n",
      "[98/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54565, in 0.006s\n",
      "[99/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54565, in 0.007s\n",
      "[100/100] 1 tree, 3 leaves, max depth = 2, train loss: 7.43236, val loss: 6.54565, in 0.006s\n",
      "Fit 100 trees in 0.711 s, (300 total leaves)\n",
      "Time spent computing histograms: 0.059s\n",
      "Time spent finding best splits:  0.015s\n",
      "Time spent applying splits:      0.107s\n",
      "Time spent predicting:           0.022s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.3s finished\n"
     ]
    }
   ],
   "source": [
    "scores = cross_validate(estimator = model, \n",
    "                        X = X, \n",
    "                        y = y, \n",
    "                        cv=cv,\n",
    "                        scoring=scoring,\n",
    "                        verbose = verbose,\n",
    "                        return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e16c6b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "results[\"no_embeddings\"] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4cff7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_cols_b\n",
    "X,y = dataset[features], dataset[target_col]\n",
    "cv = 5\n",
    "scoring=('r2', 'neg_root_mean_squared_error')\n",
    "verbose = 1\n",
    "model_params = {\n",
    "    \"learning_rate\":0.01,\n",
    "    \"max_iter\":100,\n",
    "    \"categorical_features\" : X.columns.isin([\"feature_2\"]),\n",
    "    \"l2_regularization\":0.005,\n",
    "    \"early_stopping\":True,\n",
    "    \"n_iter_no_change\":5,\n",
    "    \"verbose\":1,\n",
    "    \"random_state\":0,\n",
    "    \"max_depth\":5,\n",
    "    \"max_leaf_nodes\":20\n",
    "}\n",
    "model = HistGradientBoostingRegressor(**model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7ea9ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.038 GB of training data: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.680 s\n",
      "Binning 0.004 GB of validation data: 0.009 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34879, val loss: 8.13150, in 0.019s\n",
      "[2/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34850, val loss: 8.13150, in 0.020s\n",
      "[3/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34811, val loss: 8.13150, in 0.016s\n",
      "[4/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34772, val loss: 8.13150, in 0.019s\n",
      "[5/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34728, val loss: 8.13150, in 0.019s\n",
      "[6/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.34691, val loss: 8.13151, in 0.018s\n",
      "Fit 6 trees in 0.907 s, (120 total leaves)\n",
      "Time spent computing histograms: 0.030s\n",
      "Time spent finding best splits:  0.008s\n",
      "Time spent applying splits:      0.017s\n",
      "Time spent predicting:           0.002s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.038 GB of training data: 0.838 s\n",
      "Binning 0.004 GB of validation data: 0.012 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38711, val loss: 7.81606, in 0.018s\n",
      "[2/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38685, val loss: 7.81607, in 0.018s\n",
      "[3/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38660, val loss: 7.81608, in 0.020s\n",
      "[4/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38635, val loss: 7.81609, in 0.018s\n",
      "[5/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.38611, val loss: 7.81611, in 0.019s\n",
      "Fit 5 trees in 1.070 s, (100 total leaves)\n",
      "Time spent computing histograms: 0.024s\n",
      "Time spent finding best splits:  0.006s\n",
      "Time spent applying splits:      0.016s\n",
      "Time spent predicting:           0.002s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.038 GB of training data: 0.786 s\n",
      "Binning 0.004 GB of validation data: 0.010 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.46209, val loss: 7.24253, in 0.018s\n",
      "[2/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.46174, val loss: 7.24249, in 0.019s\n",
      "[3/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.46139, val loss: 7.24249, in 0.019s\n",
      "[4/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.46106, val loss: 7.24247, in 0.017s\n",
      "[5/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.46071, val loss: 7.24246, in 0.022s\n",
      "[6/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.46035, val loss: 7.24240, in 0.020s\n",
      "[7/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.46000, val loss: 7.24231, in 0.019s\n",
      "[8/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45964, val loss: 7.24226, in 0.019s\n",
      "[9/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45930, val loss: 7.24218, in 0.016s\n",
      "[10/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45896, val loss: 7.24213, in 0.021s\n",
      "[11/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45863, val loss: 7.24205, in 0.020s\n",
      "[12/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45829, val loss: 7.24202, in 0.019s\n",
      "[13/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45797, val loss: 7.24195, in 0.017s\n",
      "[14/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45765, val loss: 7.24195, in 0.020s\n",
      "[15/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45736, val loss: 7.24189, in 0.021s\n",
      "[16/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45709, val loss: 7.24190, in 0.025s\n",
      "[17/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45680, val loss: 7.24189, in 0.023s\n",
      "[18/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45654, val loss: 7.24186, in 0.024s\n",
      "[19/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45625, val loss: 7.24192, in 0.020s\n",
      "[20/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45597, val loss: 7.24187, in 0.021s\n",
      "[21/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45574, val loss: 7.24191, in 0.023s\n",
      "[22/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45548, val loss: 7.24188, in 0.022s\n",
      "[23/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.45523, val loss: 7.24195, in 0.024s\n",
      "Fit 23 trees in 1.413 s, (460 total leaves)\n",
      "Time spent computing histograms: 0.136s\n",
      "Time spent finding best splits:  0.033s\n",
      "Time spent applying splits:      0.075s\n",
      "Time spent predicting:           0.010s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.038 GB of training data: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.842 s\n",
      "Binning 0.004 GB of validation data: 0.013 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.51062, val loss: 6.62424, in 0.022s\n",
      "[2/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.51034, val loss: 6.62427, in 0.022s\n",
      "[3/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.51007, val loss: 6.62429, in 0.021s\n",
      "[4/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50981, val loss: 6.62432, in 0.020s\n",
      "[5/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.50948, val loss: 6.62434, in 0.020s\n",
      "Fit 5 trees in 1.104 s, (100 total leaves)\n",
      "Time spent computing histograms: 0.031s\n",
      "Time spent finding best splits:  0.008s\n",
      "Time spent applying splits:      0.018s\n",
      "Time spent predicting:           0.002s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.038 GB of training data: 0.823 s\n",
      "Binning 0.004 GB of validation data: 0.017 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43357, val loss: 6.54927, in 0.022s\n",
      "[2/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43317, val loss: 6.54920, in 0.022s\n",
      "[3/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43278, val loss: 6.54915, in 0.019s\n",
      "[4/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43239, val loss: 6.54910, in 0.018s\n",
      "[5/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43201, val loss: 6.54907, in 0.022s\n",
      "[6/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43167, val loss: 6.54903, in 0.019s\n",
      "[7/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43131, val loss: 6.54901, in 0.021s\n",
      "[8/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43099, val loss: 6.54895, in 0.018s\n",
      "[9/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43067, val loss: 6.54884, in 0.022s\n",
      "[10/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43035, val loss: 6.54887, in 0.020s\n",
      "[11/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.43003, val loss: 6.54884, in 0.023s\n",
      "[12/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42972, val loss: 6.54879, in 0.019s\n",
      "[13/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42943, val loss: 6.54875, in 0.022s\n",
      "[14/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42912, val loss: 6.54872, in 0.018s\n",
      "[15/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42881, val loss: 6.54862, in 0.021s\n",
      "[16/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42856, val loss: 6.54854, in 0.019s\n",
      "[17/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42831, val loss: 6.54846, in 0.024s\n",
      "[18/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42806, val loss: 6.54838, in 0.019s\n",
      "[19/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42779, val loss: 6.54834, in 0.020s\n",
      "[20/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42748, val loss: 6.54832, in 0.018s\n",
      "[21/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42724, val loss: 6.54829, in 0.020s\n",
      "[22/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42700, val loss: 6.54821, in 0.017s\n",
      "[23/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42675, val loss: 6.54820, in 0.021s\n",
      "[24/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42649, val loss: 6.54819, in 0.022s\n",
      "[25/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42626, val loss: 6.54815, in 0.021s\n",
      "[26/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42601, val loss: 6.54812, in 0.019s\n",
      "[27/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42573, val loss: 6.54809, in 0.017s\n",
      "[28/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42551, val loss: 6.54806, in 0.020s\n",
      "[29/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42526, val loss: 6.54805, in 0.020s\n",
      "[30/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42504, val loss: 6.54799, in 0.021s\n",
      "[31/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42480, val loss: 6.54797, in 0.021s\n",
      "[32/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42455, val loss: 6.54795, in 0.019s\n",
      "[33/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42432, val loss: 6.54791, in 0.022s\n",
      "[34/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42402, val loss: 6.54789, in 0.022s\n",
      "[35/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42381, val loss: 6.54787, in 0.018s\n",
      "[36/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42360, val loss: 6.54782, in 0.022s\n",
      "[37/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42332, val loss: 6.54779, in 0.019s\n",
      "[38/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42309, val loss: 6.54781, in 0.018s\n",
      "[39/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42284, val loss: 6.54774, in 0.019s\n",
      "[40/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42263, val loss: 6.54766, in 0.019s\n",
      "[41/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42239, val loss: 6.54765, in 0.020s\n",
      "[42/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42212, val loss: 6.54759, in 0.017s\n",
      "[43/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42183, val loss: 6.54754, in 0.021s\n",
      "[44/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42156, val loss: 6.54751, in 0.019s\n",
      "[45/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42130, val loss: 6.54752, in 0.019s\n",
      "[46/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42099, val loss: 6.54748, in 0.021s\n",
      "[47/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42073, val loss: 6.54745, in 0.019s\n",
      "[48/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42044, val loss: 6.54744, in 0.019s\n",
      "[49/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.42018, val loss: 6.54742, in 0.031s\n",
      "[50/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41992, val loss: 6.54740, in 0.020s\n",
      "[51/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41963, val loss: 6.54738, in 0.020s\n",
      "[52/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41934, val loss: 6.54736, in 0.018s\n",
      "[53/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41908, val loss: 6.54737, in 0.020s\n",
      "[54/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41883, val loss: 6.54736, in 0.019s\n",
      "[55/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41855, val loss: 6.54737, in 0.020s\n",
      "[56/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41829, val loss: 6.54734, in 0.021s\n",
      "[57/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41804, val loss: 6.54736, in 0.018s\n",
      "[58/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41777, val loss: 6.54737, in 0.020s\n",
      "[59/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41746, val loss: 6.54736, in 0.019s\n",
      "[60/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41719, val loss: 6.54738, in 0.016s\n",
      "[61/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41691, val loss: 6.54734, in 0.018s\n",
      "[62/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41666, val loss: 6.54731, in 0.015s\n",
      "[63/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41641, val loss: 6.54733, in 0.017s\n",
      "[64/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41614, val loss: 6.54731, in 0.016s\n",
      "[65/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41590, val loss: 6.54726, in 0.017s\n",
      "[66/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41563, val loss: 6.54725, in 0.017s\n",
      "[67/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41535, val loss: 6.54723, in 0.018s\n",
      "[68/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41503, val loss: 6.54723, in 0.015s\n",
      "[69/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41479, val loss: 6.54721, in 0.020s\n",
      "[70/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41448, val loss: 6.54714, in 0.020s\n",
      "[71/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41420, val loss: 6.54711, in 0.019s\n",
      "[72/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41390, val loss: 6.54705, in 0.020s\n",
      "[73/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41362, val loss: 6.54707, in 0.020s\n",
      "[74/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41336, val loss: 6.54707, in 0.019s\n",
      "[75/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41312, val loss: 6.54713, in 0.020s\n",
      "[76/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41285, val loss: 6.54713, in 0.021s\n",
      "[77/100] 1 tree, 20 leaves, max depth = 5, train loss: 7.41259, val loss: 6.54716, in 0.018s\n",
      "Fit 77 trees in 2.492 s, (1540 total leaves)\n",
      "Time spent computing histograms: 0.400s\n",
      "Time spent finding best splits:  0.112s\n",
      "Time spent applying splits:      0.252s\n",
      "Time spent predicting:           0.026s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tanch\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    8.1s finished\n"
     ]
    }
   ],
   "source": [
    "scores = cross_validate(estimator = model, \n",
    "                        X = X, \n",
    "                        y = y, \n",
    "                        cv=cv,\n",
    "                        scoring=scoring,\n",
    "                        verbose = verbose,\n",
    "                        return_train_score=True)\n",
    "results[\"with_embeddings\"] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ac4d0efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.8499928269358166\n",
      "-3.850094014784659\n",
      "-3.850309282642139\n",
      "-3.848901897453035\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "print(mean(results['no_embeddings'][\"test_neg_root_mean_squared_error\"]))\n",
    "print(mean(results['no_embeddings'][\"train_neg_root_mean_squared_error\"]))\n",
    "print(mean(results['with_embeddings'][\"test_neg_root_mean_squared_error\"]))\n",
    "print(mean(results['with_embeddings'][\"train_neg_root_mean_squared_error\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01d3536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8e0469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd58fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e914eca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342a6d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf499a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc74aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8e21f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get id columns\n",
    "def get_id_data():\n",
    "    # read\n",
    "    merchants = pd.read_csv(merchants_path, usecols = feature_names['merchants']['id'])#, nrows = 100000) \n",
    "    new_transactions = pd.read_csv(new_transactions_path, usecols = feature_names['transactions']['id'])#, nrows = 100000)\n",
    "    hist_transactions = pd.read_csv(historical_transactions_path, usecols = feature_names['transactions']['id'])#, nrows = 100000)\n",
    "    # process\n",
    "    # remove duplicate merchant_id - which there are\n",
    "    merchants = merchants[~merchants.merchant_id.duplicated()]  \n",
    "    # concat historical and new transactions - they have the same columns\n",
    "    id_columns = pd.concat([hist_transactions, new_transactions], axis = 0)\n",
    "    # fill missing merchant_id with the most frequent one \n",
    "    id_columns['merchant_id'] = id_columns['merchant_id'].fillna('M_ID_00a6ca8a8a')\n",
    "    # merge transactions data with merchant information - merchant information has an additional \"merchant_group_id\" column\n",
    "    id_columns = id_columns.merge(merchants[[\"merchant_id\",\"merchant_group_id\"]], how = \"left\", on = \"merchant_id\")\n",
    "    del new_transactions, hist_transactions, merchants\n",
    "    # convert these columns to edge list \n",
    "    to_process_cols = ['city_id', 'merchant_category_id', 'state_id','subsector_id', 'merchant_group_id']\n",
    "    for c in to_process_cols:\n",
    "        id_columns[c] = f\"{c}_\" + id_columns[c].astype(str)\n",
    "    return id_columns\n",
    "# id_columns = get_id_data()\n",
    "# path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\Semester 1\\CZ4041 - Machine Learning\\Team Project\\data\\id_columns_processed.csv\"\n",
    "# id_columns.to_csv(path, index = False)\n",
    "# id_columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
